{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the home of quantum mechanics \u00b6 This site exists to enhance the distribution of course information and content for the measurement component of KYA321: Quantum Mechanics . All official communication will be though MyLO 1 . An entangled photon source for satellite-based quantum communication , developed by the Fraunhofer Institute for Applied Optics and Precision Engineering . As part of this course, we will investigate what it means to make a measurement of a quantum system. We shall develop tools, techniques, and machinery for modelling measurements, and look at real-world quantum systems and their applications. Course expectations: my expectations of you Quantum mechanics is tough! And this isn't (necessarily) hyperbole: physics is often put in the \"hard\" basket for a number of reasons, not least due to it being seen as irrelevant or mathematically challenging. Whilst the mathematics can indeed by spicy, once can develop coping mechanisms for this, and at its heart physics is usually intuitive: the apple falls from the tree, like charges repel, and so on. At first glance, quantum mechanics can present very differently, and is rarely accused of being intuitive. There are delights are to be had, but like most truly rewarding endeavours, said delights do not come for free. In undertaking this course, it is expected that: You will view the video content before any scheduled face-to-face sessions Prescribed problems and reading will be undertaken before any face-to-face sessions You will attend all face-to-face sessions, and actively contribute to discussions and problem solving If you are experiencing difficulties, that you will get in contact as soon as is reasonably possible Course objectives The purpose of the measurements and applications component of the quanutm course is to provide an overview of quantum mechanics, demystifying some of the foundational theory and providing a toolkit for studying both old and new problems. At the conclusion of your journey, you should: Be familiar with the building blocks of quantum mechanical analysis: state vectors, operators and measurement, and time evolution Be versed in various aspects of interpretations of quantum mechanics: what does it mean to make a measurement? What is entaglement? Why are the EPR paradox, Bell's inequalities, and Schr\u00f6dinger's Cat interesting? Have studied quantum applications, from MRI machines to truly secure communications Have had some fun! Course expectations: my promises to you Rightly, you should have expectations of me. It is my intention that: I will work to communicate my understanding and insight in the course material I will actively seek input to steer and shape the content discussed, and develop relevant resources I will be available for consultation and discussion I will do my best to cultivate a safe and open forum for discussion If you think that I am not fulfilling my commitments, or if you have other comments, I would hope that you are comfortable conveying your concerns and/or comments to me, either directly or anonymously. It is my genuine desire to help you navigate learning new concepts and ideas, and I want to do this to the best of my ability, and feedback is the best way to ensure this endeavour proceeds as smoothly as possible. For the curious traveller, MyLO is The University of Tasmania's learning management system, based on Brightspace as developed D2L. \u21a9","title":"Home"},{"location":"#welcome-to-the-home-of-quantum-mechanics","text":"This site exists to enhance the distribution of course information and content for the measurement component of KYA321: Quantum Mechanics . All official communication will be though MyLO 1 . An entangled photon source for satellite-based quantum communication , developed by the Fraunhofer Institute for Applied Optics and Precision Engineering . As part of this course, we will investigate what it means to make a measurement of a quantum system. We shall develop tools, techniques, and machinery for modelling measurements, and look at real-world quantum systems and their applications. Course expectations: my expectations of you Quantum mechanics is tough! And this isn't (necessarily) hyperbole: physics is often put in the \"hard\" basket for a number of reasons, not least due to it being seen as irrelevant or mathematically challenging. Whilst the mathematics can indeed by spicy, once can develop coping mechanisms for this, and at its heart physics is usually intuitive: the apple falls from the tree, like charges repel, and so on. At first glance, quantum mechanics can present very differently, and is rarely accused of being intuitive. There are delights are to be had, but like most truly rewarding endeavours, said delights do not come for free. In undertaking this course, it is expected that: You will view the video content before any scheduled face-to-face sessions Prescribed problems and reading will be undertaken before any face-to-face sessions You will attend all face-to-face sessions, and actively contribute to discussions and problem solving If you are experiencing difficulties, that you will get in contact as soon as is reasonably possible Course objectives The purpose of the measurements and applications component of the quanutm course is to provide an overview of quantum mechanics, demystifying some of the foundational theory and providing a toolkit for studying both old and new problems. At the conclusion of your journey, you should: Be familiar with the building blocks of quantum mechanical analysis: state vectors, operators and measurement, and time evolution Be versed in various aspects of interpretations of quantum mechanics: what does it mean to make a measurement? What is entaglement? Why are the EPR paradox, Bell's inequalities, and Schr\u00f6dinger's Cat interesting? Have studied quantum applications, from MRI machines to truly secure communications Have had some fun! Course expectations: my promises to you Rightly, you should have expectations of me. It is my intention that: I will work to communicate my understanding and insight in the course material I will actively seek input to steer and shape the content discussed, and develop relevant resources I will be available for consultation and discussion I will do my best to cultivate a safe and open forum for discussion If you think that I am not fulfilling my commitments, or if you have other comments, I would hope that you are comfortable conveying your concerns and/or comments to me, either directly or anonymously. It is my genuine desire to help you navigate learning new concepts and ideas, and I want to do this to the best of my ability, and feedback is the best way to ensure this endeavour proceeds as smoothly as possible. For the curious traveller, MyLO is The University of Tasmania's learning management system, based on Brightspace as developed D2L. \u21a9","title":"Welcome to the home of quantum mechanics"},{"location":"Lost/","text":"Placeholder \u00b6 Empty page This page is a placeholder: the treasure you seek is in another castle Unbaked The content here is still very much under development. Please come back soon! Introduction \u00b6 Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Text reference The material covered here is discussed in section(s) \\(\\S\\) of The Oxford Solid State Basics Computational content The Jupyter notebook associated with this section can be accessed by clicking the icon below: Thermal expansion \u00b6 While the quadratic approximation of the interatomic potential is certainly the most important, the anharmonic term \\(\\kappa_3(r-a)^3/6\\) also has physical significance. Let us examine its role visually by comparing the harmonic and the third order approximations in the plot below. Notice that the second-order approximation is symmetric around the minimum while the third-order term is not. r = np . linspace ( - 2 , 2.5 , 750 ) a = 0 b = 0 c = 1 d = - 0.2 U_quadratic = a + b * r + c * r ** 2 U_cubic = a + b * r + c * r ** 2 + d * r ** 3 r_min = - 2 r_max = 2.5 U_min = - 0.2 U_max = 4 E_t_min = 0.4 E_t_max = 3.5 N_values = 20 l_width = 1.5 N_active = 0 # Create figure fig = go . Figure () def U_c ( r ): return a + b * r + c * r ** 2 + d * r ** 3 def line ( E_t ): right = min ( np . roots ([ c , b , a - E_t ])) roots = np . roots ([ d , c , b , a - E_t ]) roots = np . real ( roots [ np . isreal ( roots )]) roots . sort () left = roots [ 1 ] return [ left , right ] def avg_pos_cubic ( E_t ): Z = integrate . simps ( np . exp ( - U_cubic / E_t ), r ) r_avg = integrate . simps ( r * np . exp ( - U_cubic / E_t ), r ) x = r_avg / Z return x # Add traces, one for each slider step for E_t in np . linspace ( E_t_min , E_t_max , N_values ): avg = avg_pos_cubic ( E_t ) fig . add_trace ( go . Scatter ( visible = False , x = r , y = U_quadratic , mode = 'lines' , line_color = 'blue' , name = \"Quadratic potential\" , )) fig . add_trace ( go . Scatter ( visible = False , x = r , y = U_cubic , mode = 'lines' , line_color = 'red' , name = \"Cubic potential\" , )) fig . add_trace ( go . Scatter ( visible = False , x = line ( E_t ), y = [ E_t , E_t ], mode = 'lines' , line_color = 'black' , name = r 'Thermal energy level' )) fig . add_trace ( go . Scatter ( visible = False , x = [ 0 , 0 ], y = [ 0 , E_t ], mode = 'lines' , line_color = 'blue' , line_dash = 'dot' , name = r '$\\langle r \\rangle$ for the quadratic potential' )) fig . add_trace ( go . Scatter ( visible = False , x = [ avg , avg ], y = [ U_c ( avg ), E_t ], mode = 'lines' , line_color = 'red' , line_dash = 'dot' , name = r '$\\langle r \\rangle$ for the cubic potential' )) # Initial starting image N_trace = int ( len ( fig . data ) / N_values ) # Number of traces added per step for j in range ( N_trace ): fig . data [ N_active * N_trace + j ] . visible = True # Creation of the aditional images steps = [] for i in range ( int ( len ( fig . data ) / N_trace )): step = dict ( method = \"restyle\" , args = [{ \"visible\" : [ False ] * len ( fig . data )}], value = str ( 0.1 * ( i + 1 )) ) for j in range ( N_trace ): step [ \"args\" ][ 0 ][ \"visible\" ][ N_trace * i + j ] = True # Toggle i'th trace to \"visible\" steps . append ( step ) # Creating the slider sliders = [ dict ( tickcolor = 'White' , font_color = 'White' , currentvalue_font_color = 'Black' , active = N_active , name = r 'Thermal Energy' , font_size = 16 , currentvalue = { \"prefix\" : r 'Thermal Energy k_B T: ' }, pad = { \"t\" : 50 }, steps = steps , )] # Updating the images for each step fig . update_layout ( sliders = sliders , showlegend = True , plot_bgcolor = 'rgb(254, 254, 254)' , width = 700 , height = 580 , xaxis = dict ( range = [ r_min , r_max ], visible = True , showticklabels = True , showline = True , linewidth = l_width , linecolor = 'black' , gridcolor = 'white' , tickfont = dict ( size = 16 )), yaxis = dict ( range = [ U_min , U_max ], visible = True , showticklabels = True , showline = True , linewidth = l_width , linecolor = 'black' , gridcolor = 'white' , tickfont = dict ( size = 16 )), title = { 'text' : r 'Thermal expansion of cubic potential' , 'y' : 0.9 , 'x' : 0.45 , 'xanchor' : 'center' , 'yanchor' : 'top' }, xaxis_title = r '$r$' , yaxis_title = r '$U [k_b T]$' , ) # Edit slider labels and adding text next to the horizontal bar indicating T_E for i in range ( N_values ): fig [ 'layout' ][ 'sliders' ][ 0 ][ 'steps' ][ i ][ 'label' ] = ' %.1f ' % (( E_t_max - E_t_min ) * i / ( N_values - 1 ) + E_t_min ) # Showing the figure plt . plot ( fig ) fig . show () The asymmetry due to nonzero \\(\\kappa_3\\) slows the growth of the potential when the interatomic distance increases. On the other hand, when the interatomic distance decreases, the asymmetry accelerates the growth of the potential. Therefore, stretching the material is more energetically favorable than contracting it. As a result, thermal excitations increase the interatomic distance. This gives us a simple model of thermal expansion . Van der Waals bond \u00b6 While we focus on the mechanisms of covalent bonding, let us also review another bond type. A Van der Waals bond originates from an attraction between the dipole moments of two atoms. Suppose we have two atoms separated by an interatomic distance \\(r\\) . If one atom has a dipole moment \\(\\mathbf{p_1}\\) , it creates an electric field \\[ \\mathbf{E} = \\frac{\\mathbf{p_1}}{4\\pi \\varepsilon_0 r^3} \\] at the position of the other atom. The other atom then develops a dipole moment \\(\\mathbf{p_2} = \\chi \\mathbf{E}\\) with \\(\\chi\\) the polarizability of the atom. The potential energy between between the two dipoles is \\begin{align} U(r) &= \\frac{-|\\mathbf{p_1}||\\mathbf{p_2}|}{4\\pi\\varepsilon_0 r^3}\\\\ &= \\frac{-|\\mathbf{p_1}| \\chi \\mathbf{E}}{4\\pi\\varepsilon_0 r^3}\\\\ &= \\frac{-|\\mathbf{p_1}|^2 \\chi}{(4\\pi\\varepsilon_0 r^3)^2}\\\\ &\\propto \\frac{1}{r^6}. \\end{align} The dipole attraction is much weaker than the covalent bonds but drops slower with increasing distance. How does the strength of a covalent bond scale with distance? The strength of the bond is determined by the interatomic hopping integral \\(-t = \\langle 1 | H | 2 \\rangle\\) . Since the wavefunction of a bound electron typically decays exponentially, so does the overlap integral. Although the Van der Waals force is weak, it is the only force when there are no chemically active electrons or when the atoms are too far apart to form covalent bonds. Therefore, there are materials where Van der Waals interactions are the dominant interactions. An example of such a material is graphite. The Van der Waals bonds in graphite hold layers of covalently bonded carbon atoms together: (image source: Wikipedia ) Looking ahead: multiple atoms \u00b6 So far we have only considered the interatomic interactions between diatomic systems. However, our aim is to understand electrons and phonons in solids containing \\(N\\to\\infty\\) atoms. Let us see what happens when we consider more than two atoms. Phonons \u00b6 In order to understand phonons better, we need to understand how a vibrational motion in a solid arises. To that end, we model an array of atoms that are connected by springs with a spring constant \\(\\kappa\\) . Our plan: Consider only a harmonic potential acting between the atoms ( \\(\\kappa\\) is constant) Write down equations of motion Compute normal modes For simplicity we consider 1D motion, and let us start with a chain of 3 atoms: # Defining constants y_max = 6 max_m = 3 # Off set for the new masses deviation_arr = [ + 2 , - 2 , - 3.5 ] def plot_spring ( x1 , x2 , y , annotation = r '$\\kappa$' ): L = ( x2 - x1 ) width , nturns = 1 , 10 N = 1000 pad = 200 # Make the spring, unit scale (0 to 1) x_spring = np . linspace ( 0 , L , N ) # distance along the spring y_spring = np . zeros ( N ) y_spring [ pad : - pad ] = width * np . sin ( 2 * np . pi * nturns * x_spring [ pad : - pad ] / L ) x_plot , y_plot = np . vstack (( x_spring , y_spring )) # And offset it x_plot += x1 y_plot += y ax . plot ( x_plot , y_plot , c = 'k' ) ax . annotate ( annotation , (( x2 + x1 ) / 2 , y + 2 ), fontsize = 40 ) def plot_mass ( x , y , annotation = r '$m$' ): mass = Circle (( x , y ), .5 , fc = 'k' ) ax . add_patch ( mass ) ax . annotate ( annotation , ( x - .5 , y + 2 ), fontsize = 30 ) def make_plot ( u , deviation_arr , max_masses = 3 ): # plotting initial masses plot_mass ( 0 , 0 ) plot_mass ( 0 + deviation_arr [ 0 ], u , annotation = '' ) # Plot initial dotted lines pyplot . plot (( 0 , 0 ), ( 0 , u - 2.5 ), 'k--' ) pyplot . plot (( deviation_arr [ 0 ], deviation_arr [ 0 ]), ( u , u - 2.5 ), 'k--' ) # pyplot.plot((0, deviation_arr[0]), (u-2.5, u-2.5), 'k--') pyplot . arrow ( 0 , u - 2.5 , deviation_arr [ 0 ] - .5 , 0 , fc = \"k\" , ec = \"k\" , head_width = .25 , head_length = .5 ) # Annotate the deviations annot_arr = [ r '$u_1$' , r '$u_2$' , r '$u_3$' ] off_set = - 1 ax . annotate ( annot_arr [ 0 ], ( deviation_arr [ 0 ] / 2 + off_set + .4 , u - 3 + off_set ), fontsize = 30 ) # Annotate large arrow containing the interatomic distance pyplot . arrow ( 0 , u / 3 , 9 , 0 , fc = \"k\" , ec = \"k\" , head_width = .5 , head_length = 1 ) ax . annotate ( r '$a$' , ( 5 , u / 3 + off_set ), fontsize = 30 ) # Plotting other masses and springs for j in range ( max_masses - 1 ): # Equilibrium plot plot_spring ( 10 * j , 10 * ( j + 1 ), 0 ) plot_mass ( 10 * ( j + 1 ), 0 ) # Plot containing deviations from it's equilibrium plot_spring ( 10 * j + deviation_arr [ j ], 10 * ( j + 1 ) + deviation_arr [ j + 1 ], u , annotation = '' ) plot_mass ( 10 * ( j + 1 ) + deviation_arr [ j + 1 ], u , annotation = '' ) # Plot dotted lines pyplot . plot (( 10 * ( j + 1 ), 10 * ( j + 1 )), ( 0 , u - 2.5 ), 'k--' ) pyplot . plot (( 10 * ( j + 1 ) + deviation_arr [ j + 1 ], 10 * ( j + 1 ) + deviation_arr [ j + 1 ]), ( u , u - 2.5 ), 'k--' ) # pyplot.plot((10*(j+1), 10*(j+1)+deviation_arr[j+1]), (u-2.5, u-2.5), 'k--') pyplot . arrow ( 10 * ( j + 1 ), u - 2.5 , ( deviation_arr [ j + 1 ] + .5 ), 0 , fc = \"k\" , ec = \"k\" , head_width = .25 , head_length = .5 ) # Annotations ax . annotate ( annot_arr [ j + 1 ], ( 10 * ( j + 1 ) + deviation_arr [ j + 1 ] / 2 + off_set + .4 , u - 3 + off_set ), fontsize = 30 ) # Initializing figure fig , ax = pyplot . subplots ( figsize = ( 10 , 7 )) pyplot . axis ( 'off' ) ax . set_xlim (( - 1 , 10 * ( max_m - 1 ) + 1 )) ax . set_ylim (( - y_max - 4.5 , y_max - 2.5 )) # Plottig system make_plot ( - y_max , deviation_arr , max_m ); fig . show () Let us denote the deviation of atom \\(i\\) from its equilibrium position by \\(u_i\\) . Newton's equations of motion for this system are then given by \\[ \\begin{aligned} m \\ddot{u}_1 &= - \\kappa (u_1 - u_2) \\\\ m \\ddot{u}_2 &= - \\kappa (u_2 - u_1) - \\kappa (u_2 - u_3) \\\\ m \\ddot{u}_3 &= - \\kappa (u_3 - u_2). \\end{aligned}, \\] We write this system of equations in matrix form \\[ m \\ddot{\\mathbf{u}} = -\\kappa \\begin{pmatrix} 1 & -1 & 0\\\\ -1 & 2 & -1\\\\ 0 & -1 & 1 \\end{pmatrix}\\mathbf{u} \\] We are interested in phonons, patterns of motion that are periodic and have a fixed frequency \\(\\omega\\) . Hence we guess that the motion of the atoms is \\[ \\mathbf{u}(t) = \\mathbf{u}_0 e^{i\\omega t}. \\] We substitute our guess into the equations of motion to yield an eigenvalue problem: \\[ \\omega^2 \\mathbf{u}_0 = \\frac{\\kappa}{m} \\begin{pmatrix} 1 & -1 & 0\\\\ -1 & 2 & -1\\\\ 0 & -1 & 1 \\end{pmatrix}\\mathbf{u}_0. \\] The solutions to the eigenvalue problem are phonon modes. Electrons \u00b6 We just looked at how a chain of atoms moves. Let us now look at how the electrons of those atoms behave. To that end, we consider a 3 atom chain without any motion. In order to understand how electrons behave, we use the LCAO model. The LCAO model generalizes in a very simple way. Let us consider the wavefunction: \\vert \\psi\\rangle = \\varphi_1 |1\\rangle + \\varphi_2 |2\\rangle + \\varphi_3 |3\\rangle. Because the three atoms are identical, the onsite energy is the same on all atoms \\(\\langle 1|H|1 \\rangle = \\langle2|H|2 \\rangle = \\langle3|H|3 \\rangle = E_0\\) . Furthermore, we assume hopping only between the nearest neighbors and assume that it is real valued: \\(\\langle1|H|2\\rangle = \\langle2|H|3\\rangle = -t\\) . We also assume that the orbitals are orthogonal to eachother. Just as we did in the previous lecture, we use the Schr\u00f6dinger equation \\(H |\\psi\\rangle = E |\\psi\\rangle\\) to set up a system of equations: \\[ \\begin{align} E \\varphi_1 &= E_0 \\varphi_1 - t \\varphi_2\\\\ E \\varphi_2 &= E_0 \\varphi_2 - t \\varphi_1 - t \\varphi_3\\\\ E \\varphi_3 &= E_0 \\varphi_3 -t \\varphi_2. \\end{align} \\] Again, we write this in a matrix form: \\[ E \\begin{pmatrix} \\varphi_1 \\\\ \\varphi_2 \\\\ \\varphi_3 \\end{pmatrix} = \\begin{pmatrix} E_0 & -t & 0 \\\\ -t & E_0 & -t \\\\ 0 & -t & E_0 \\end{pmatrix} \\begin{pmatrix} \\varphi_1 \\\\ \\varphi_2 \\\\ \\varphi_3. \\end{pmatrix} \\] Numerical test \u00b6 Diagonalizing large matrices is unwieldy, but let's try and check it numerically to see if we notice a trend. Let us first model 3 atoms on a chain. The eigenfrequencies of the 3 atoms are: [0.0 1.0 1.732050] def DOS_finite_phonon_chain ( n ): rhs = 2 * np . eye ( n ) - np . eye ( n , k = 1 ) - np . eye ( n , k =- 1 ) rhs [ 0 , 0 ] -= 1 rhs [ - 1 , - 1 ] -= 1 pyplot . figure () pyplot . hist ( np . sqrt ( np . abs ( np . linalg . eigvalsh ( rhs ))), bins = 30 ) pyplot . xlabel ( \"$\\omega$\" ) pyplot . ylabel ( \"Number of eigenfrequencies\" ) DOS_finite_phonon_chain ( 3 ) The eigenenergies of the 3 orbitals are: [-1.41421356 0.0 1.41421356] def DOS_finite_electron_chain ( n ): rhs = 2 * np . eye ( n , k = 0 ) - np . eye ( n , k = 1 ) - np . eye ( n , k = - 1 ) pyplot . figure () pyplot . hist ( np . linalg . eigvalsh ( rhs ), bins = 30 ) pyplot . xlabel ( \"$E$\" ) pyplot . ylabel ( \"Number of eigenenergies\" ) DOS_finite_electron_chain ( 3 ) However, 3 atoms are far too few to model an actual solid. Hence, we need 'many more' atoms. From 3 atoms to 300 \u00b6 Phonon modes of the many atom chain are shown below. DOS_finite_phonon_chain ( 300 ) We observe that when \\(\\omega\\) is small, we have a constant DOS. This is in line with what we saw in the Debye model. There the DOS of a 1D system was constant! However, when the frequencies are higher, the DOS is not constant anymore. A plot of electron energies in the many atom chain is shown below. DOS_finite_electron_chain ( 300 ) The numerical results once again agree with the models we developed earlier. In the Sommerfeld free electron model, the DOS in 1D is proportional to \\(\\frac{1}{\\sqrt{E}}\\) . The above histogram also reflects this proportionality for small energies \\(E\\) . However, when \\(E\\) is higher, we observe a significant deviation from the \\(\\frac{1}{\\sqrt{E}}\\) behavior. In both cases, we find that our models agree with the numerical results whenever frequencies/energies are small. When the frequencies/energies are high, we find that there is a significant deviation from the Debye/Sommerfeld models. The nature of this deviation is the subject of the next lecture! Conclusions \u00b6 The DOS of phonons used in the Debye model is justified by modeling the atoms as particles on a chain connected by a spring in the small \\(\\omega\\) limit. The DOS of electrons in the Sommerfeld model is justified by modeling electrons as particles that can hop between atoms in the small \\(E\\) limit. Exercises \u00b6 Preliminary provocations \u00b6 What does the LCAO matrix in the lecture notes look like if we also consider a next nearest-neighbour hopping \\(-\\tilde{t}\\) ? What does the LCAO matrix look like if we consider six atoms instead of three? You may assume that each atom has a single orbital, onsite energy \\(E_0\\) and the hopping between neighbouring atoms \\(-t\\) . How do you determine which part of the interatomic potential is attractive and which is repulsive? You may assume that the interatomic potential is only a function of the interatomic distance \\(r\\) . Exercise 1: Linear triatomic molecule \u00b6 Consider carbon dioxide (C0 \\(_2\\) ) which is a linear triatomic molecule shown below ??? info \"source\" By Jasek FH. - Own work, [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/3.0 \"Creative Commons Attribution-Share Alike 3.0\"), [Link](https://commons.wikimedia.org/w/index.php?curid=2875238) How many normal modes does this molecule have assuming motion in only 1D? How many normal modes does it have if the atoms can move in all three dimensions? For simplicity, we only consider 1D motion of the atoms. Write down Newton's equations of motion for the atoms, you may assume that the spring constant is the same for both bonds. Consider a symmetric mode, for which the displacements of the oxygen atoms are equal in magnitude and have an opposite direction. Find the eigenfrequency of this mode. Now consider the antisymmetric mode when both of the oxygen atoms move in phase and have the same displacement. Find the ratio between the displacements of the carbon and oxygen atoms. Make sure that the center of mass of the molecule is at rest. Compute the eigenfrequency of the antisymmetric mode. Hint Compare your answers with Wikipedia . From Diatomic solids Exercise 2: the Peierls transition \u00b6 In the previous lecture, we have derived the electronic band structure of an 1D, equally spaced atomic chain. Such chains, however, are in fact not stable and the equal spacing will be distorted. This is also known as the Peierls transition . The spacing of the distorted chain alternates between two different distances and this also causes the hopping energy to alternate between \\(t_1\\) and \\(t_2\\) . We further set the onsite energies of the atoms to \\(\\epsilon\\) . The situation is depicted in the figure below. Due to the alternating hopping energies, we must treat two consecutive atoms as two different orbitals ( \\(|n,1\u27e9\\) and \\(|n,2 \u27e9\\) in the figure) from the same unit cell. The corresponding LCAO of this chain is given by \\left|\\Psi \\right\\rangle = \\sum_n \\left(\\phi_n \\left| n,1 \\right\\rangle + \\psi_n \\left| n,2 \\right\\rangle\\right) As usual, we assume that all these atomic orbitals are orthogonal to each other. Indicate the length of the unit cell \\(a\\) in the figure. Using the Schr\u00f6dinger equation, write the equations of motion of the electrons. Hint To this end, find expressions for \\(E \\left< n,1 \\vert \\Psi \\right> = \\left< n,1 \\right| H \\left|\\Psi \\right>\\) and \\(E \\left< n,2 \\vert \\Psi \\right> = \\left< n,2 \\right| H \\left|\\Psi \\right>\\) . Using the trial solutions \\(\\phi_n = \\phi_0 e^{ikna}\\) and \\(\\psi_n = \\psi_0 e^{ikna}\\) , show that the Sch\u00f6dinger equation can be written in matrix form: \\( \\(\\begin{pmatrix} \\epsilon & t_1 + t_2 e^{-i k a} \\\\ t_1 + t_2 e^{i k a} & \\epsilon \\end{pmatrix} \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix} = E \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix}.\\) \\) Derive the dispersion relation of this Hamiltonian. Does it look like the figure of the band structure shown on the Wikipedia page ? Does it reduce to the 1D, equally spaced atomic chain if \\(t_1 = t_2\\) ? Find an expression of the group velocity \\(v(k)\\) and effective mass \\(m^*(k)\\) of both bands. Derive an expression for the density of states \\(g(E)\\) of the entire band structure and make a plot of it. Does your result makes sense when considering the band structure? Tight binding \u00b6 Group velocity, effective mass, density of states \u00b6 (here we only discuss electrons; for phonons everything is the same except for replacing \\(E = \\hbar \\omega\\) ) Let us think what happens if we apply an external electric field to the crystal: x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 ) + .2 * ( x - 1.5 )) ax . plot ( x , .2 * ( x - 0.25 ), '--' ) ax . set_ylim ( - .7 , .5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ - .05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) The full Hamiltonian of the system is H = \\frac{p^2}{2m} + U_\\textrm{atomic}(x) + e \\mathcal{E} x, where \\(U_\\textrm{atomic}\\) is the potential created by the nuclei, and \\(\\mathcal{E}\\) the electric field. A typical electric field is much smaller than the interatomic potential, and therefore we can start by obtaining the dispersion relation \\(E(k)\\) without electric field (by applying the LCAO method), and then solve H = E(k) + e\\mathcal{E}x. To derive how particles with an arbitrary dispersion relation move, we recall the Hamilton's equations for particle velocity \\(v\\) and force \\(F\\) : \\[\\begin{aligned} v \\equiv \\frac{dr}{dt} &= \\frac{\\partial H(p, r)}{\\partial p}\\\\ F \\equiv \\frac{dp}{dt} &= -\\frac{\\partial H(p, r)}{\\partial r}. \\end{aligned}\\] Substituting \\(p = \\hbar k\\) into the first equation we arrive to the expression for the electron group velocity \\(v \\equiv \\hbar^{-1}\\partial E/\\partial k\\) . From the second equation we obtain that the force acting on electron in a band stays \\(-e\\mathcal{E}\\) , which in turn gives results in the acceleration \\frac{dv}{dt} = \\frac{\u2202v}{\u2202p}\\frac{dp}{dt} = F/m. Comparing this expression with \\(dv/dt = F/m\\) , we arrive to the effective mass : m^* \\equiv \\left(\\frac{\u2202v}{\u2202p}\\right)^{-1} = \\left(\\frac{\u2202\u00b2E}{\u2202p\u00b2}\\right)^{-1} = \u0127\u00b2\\left(\\frac{\u2202\u00b2E}{\u2202k\u00b2}\\right)^{-1}. The group velocity describes how quickly electrons with a certain \\(k\\) -vector move, while the effective mass describes how hard they are to accelerate by applying external force. By using the dispersion relation we derived earlier, we obtain the effective mass like this: pyplot . figure ( figsize = ( 8 , 5 )) k = np . linspace ( - pi , pi , 300 ) meff = 1 / np . cos ( k ) color = list ( matplotlib . rcParams [ 'axes.prop_cycle' ])[ 0 ][ 'color' ] pyplot . plot ( k [ meff > 0 ], meff [ meff > 0 ], c = color ) pyplot . plot ( k [ meff < 0 ], meff [ meff < 0 ], c = color ) pyplot . ylim ( - 5 , 5 ) pyplot . xlabel ( '$ka$' ); pyplot . ylabel ( '$m^*$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , 0 , r '$\\pi$' ]); Notice that the effective mass can be negative, which implies the electrons accelerate in the direction opposite to the applied force. Density of states \u00b6 The DOS is the number of states per unit energy. In 1D we have \\( \\(g(E) = \\frac{L}{2\\pi}\\sum |dk/dE| = \\frac{L}{2\\pi}\\sum |v|^{-1}\\) \\) The sum goes over all possible values of \\(k\\) and spin which have the same energy \\(E\\) . If we are working in two or more dimensions, we must integrate over the values of \\(k\\) with the same energy. Also take note that for energies below \\(E_0 - 2t\\) or above \\(E_0 + 2t\\) , there are no values of \\(k\\) with that energy, so there is nothing to sum over. Once again, starting from E = E_0 - 2t \\cos(ka), we get ka = \\pm\\arccos[(E - E_0) / 2t], and |v| ^{-1} = \\left|\\frac{dk}{dE} \\right| = \\frac{1}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. You can get to this result immediately if you remember the derivative of arccosine. Otherwise you need to go the long way: compute \\(dE/dk\\) as a function of \\(k\\) , express \\(k\\) through \\(E\\) as we did above, and take the inverse. We now add together the contributions of the positive and the negative momenta as well both spin orientations, and arrive to the density of states g(E) = \\frac{L}{2\\pi}\\frac{4}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. A quick check: when the energy is close to the bottom of the band, \\(E = E_0 - 2t + \\delta E\\) , we get \\(g(E) \\propto \\delta E^{-1/2}\\) , as we expect in 1D. The process of calculating the DOS at a given energy \\(E\\) of a spin-independent Hamiltonian is done systematically with the following steps: At a given energy \\(E\\) , determine all of the values of \\(k\\) which correspond to that \\(E\\) using the dispersion relation. Compute \\(\\rvert dk / dE \\rvert\\) . Do this either by writing \\(k\\) as a (multi-valued) function of \\(E\\) and differentiating, or by computing \\((dE / dk)^{-1}\\) . Sum or integrate \\(dk / dE\\) over the allowed values of \\(k\\) found in 1 and multiply by any degeneracies (spin/polarization). Multiply by spin degeneracy. If the Hamiltonian depends on spin, then there is no spin degeneracy and the spin number \\(s\\) must be treated in the same way as \\(k\\) .","title":"Placeholder"},{"location":"Lost/#placeholder","text":"Empty page This page is a placeholder: the treasure you seek is in another castle Unbaked The content here is still very much under development. Please come back soon!","title":"Placeholder"},{"location":"Lost/#introduction","text":"Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Text reference The material covered here is discussed in section(s) \\(\\S\\) of The Oxford Solid State Basics Computational content The Jupyter notebook associated with this section can be accessed by clicking the icon below:","title":"Introduction"},{"location":"Lost/#thermal-expansion","text":"While the quadratic approximation of the interatomic potential is certainly the most important, the anharmonic term \\(\\kappa_3(r-a)^3/6\\) also has physical significance. Let us examine its role visually by comparing the harmonic and the third order approximations in the plot below. Notice that the second-order approximation is symmetric around the minimum while the third-order term is not. r = np . linspace ( - 2 , 2.5 , 750 ) a = 0 b = 0 c = 1 d = - 0.2 U_quadratic = a + b * r + c * r ** 2 U_cubic = a + b * r + c * r ** 2 + d * r ** 3 r_min = - 2 r_max = 2.5 U_min = - 0.2 U_max = 4 E_t_min = 0.4 E_t_max = 3.5 N_values = 20 l_width = 1.5 N_active = 0 # Create figure fig = go . Figure () def U_c ( r ): return a + b * r + c * r ** 2 + d * r ** 3 def line ( E_t ): right = min ( np . roots ([ c , b , a - E_t ])) roots = np . roots ([ d , c , b , a - E_t ]) roots = np . real ( roots [ np . isreal ( roots )]) roots . sort () left = roots [ 1 ] return [ left , right ] def avg_pos_cubic ( E_t ): Z = integrate . simps ( np . exp ( - U_cubic / E_t ), r ) r_avg = integrate . simps ( r * np . exp ( - U_cubic / E_t ), r ) x = r_avg / Z return x # Add traces, one for each slider step for E_t in np . linspace ( E_t_min , E_t_max , N_values ): avg = avg_pos_cubic ( E_t ) fig . add_trace ( go . Scatter ( visible = False , x = r , y = U_quadratic , mode = 'lines' , line_color = 'blue' , name = \"Quadratic potential\" , )) fig . add_trace ( go . Scatter ( visible = False , x = r , y = U_cubic , mode = 'lines' , line_color = 'red' , name = \"Cubic potential\" , )) fig . add_trace ( go . Scatter ( visible = False , x = line ( E_t ), y = [ E_t , E_t ], mode = 'lines' , line_color = 'black' , name = r 'Thermal energy level' )) fig . add_trace ( go . Scatter ( visible = False , x = [ 0 , 0 ], y = [ 0 , E_t ], mode = 'lines' , line_color = 'blue' , line_dash = 'dot' , name = r '$\\langle r \\rangle$ for the quadratic potential' )) fig . add_trace ( go . Scatter ( visible = False , x = [ avg , avg ], y = [ U_c ( avg ), E_t ], mode = 'lines' , line_color = 'red' , line_dash = 'dot' , name = r '$\\langle r \\rangle$ for the cubic potential' )) # Initial starting image N_trace = int ( len ( fig . data ) / N_values ) # Number of traces added per step for j in range ( N_trace ): fig . data [ N_active * N_trace + j ] . visible = True # Creation of the aditional images steps = [] for i in range ( int ( len ( fig . data ) / N_trace )): step = dict ( method = \"restyle\" , args = [{ \"visible\" : [ False ] * len ( fig . data )}], value = str ( 0.1 * ( i + 1 )) ) for j in range ( N_trace ): step [ \"args\" ][ 0 ][ \"visible\" ][ N_trace * i + j ] = True # Toggle i'th trace to \"visible\" steps . append ( step ) # Creating the slider sliders = [ dict ( tickcolor = 'White' , font_color = 'White' , currentvalue_font_color = 'Black' , active = N_active , name = r 'Thermal Energy' , font_size = 16 , currentvalue = { \"prefix\" : r 'Thermal Energy k_B T: ' }, pad = { \"t\" : 50 }, steps = steps , )] # Updating the images for each step fig . update_layout ( sliders = sliders , showlegend = True , plot_bgcolor = 'rgb(254, 254, 254)' , width = 700 , height = 580 , xaxis = dict ( range = [ r_min , r_max ], visible = True , showticklabels = True , showline = True , linewidth = l_width , linecolor = 'black' , gridcolor = 'white' , tickfont = dict ( size = 16 )), yaxis = dict ( range = [ U_min , U_max ], visible = True , showticklabels = True , showline = True , linewidth = l_width , linecolor = 'black' , gridcolor = 'white' , tickfont = dict ( size = 16 )), title = { 'text' : r 'Thermal expansion of cubic potential' , 'y' : 0.9 , 'x' : 0.45 , 'xanchor' : 'center' , 'yanchor' : 'top' }, xaxis_title = r '$r$' , yaxis_title = r '$U [k_b T]$' , ) # Edit slider labels and adding text next to the horizontal bar indicating T_E for i in range ( N_values ): fig [ 'layout' ][ 'sliders' ][ 0 ][ 'steps' ][ i ][ 'label' ] = ' %.1f ' % (( E_t_max - E_t_min ) * i / ( N_values - 1 ) + E_t_min ) # Showing the figure plt . plot ( fig ) fig . show () The asymmetry due to nonzero \\(\\kappa_3\\) slows the growth of the potential when the interatomic distance increases. On the other hand, when the interatomic distance decreases, the asymmetry accelerates the growth of the potential. Therefore, stretching the material is more energetically favorable than contracting it. As a result, thermal excitations increase the interatomic distance. This gives us a simple model of thermal expansion .","title":"Thermal expansion"},{"location":"Lost/#van-der-waals-bond","text":"While we focus on the mechanisms of covalent bonding, let us also review another bond type. A Van der Waals bond originates from an attraction between the dipole moments of two atoms. Suppose we have two atoms separated by an interatomic distance \\(r\\) . If one atom has a dipole moment \\(\\mathbf{p_1}\\) , it creates an electric field \\[ \\mathbf{E} = \\frac{\\mathbf{p_1}}{4\\pi \\varepsilon_0 r^3} \\] at the position of the other atom. The other atom then develops a dipole moment \\(\\mathbf{p_2} = \\chi \\mathbf{E}\\) with \\(\\chi\\) the polarizability of the atom. The potential energy between between the two dipoles is \\begin{align} U(r) &= \\frac{-|\\mathbf{p_1}||\\mathbf{p_2}|}{4\\pi\\varepsilon_0 r^3}\\\\ &= \\frac{-|\\mathbf{p_1}| \\chi \\mathbf{E}}{4\\pi\\varepsilon_0 r^3}\\\\ &= \\frac{-|\\mathbf{p_1}|^2 \\chi}{(4\\pi\\varepsilon_0 r^3)^2}\\\\ &\\propto \\frac{1}{r^6}. \\end{align} The dipole attraction is much weaker than the covalent bonds but drops slower with increasing distance. How does the strength of a covalent bond scale with distance? The strength of the bond is determined by the interatomic hopping integral \\(-t = \\langle 1 | H | 2 \\rangle\\) . Since the wavefunction of a bound electron typically decays exponentially, so does the overlap integral. Although the Van der Waals force is weak, it is the only force when there are no chemically active electrons or when the atoms are too far apart to form covalent bonds. Therefore, there are materials where Van der Waals interactions are the dominant interactions. An example of such a material is graphite. The Van der Waals bonds in graphite hold layers of covalently bonded carbon atoms together: (image source: Wikipedia )","title":"Van der Waals bond"},{"location":"Lost/#looking-ahead-multiple-atoms","text":"So far we have only considered the interatomic interactions between diatomic systems. However, our aim is to understand electrons and phonons in solids containing \\(N\\to\\infty\\) atoms. Let us see what happens when we consider more than two atoms.","title":"Looking ahead: multiple atoms"},{"location":"Lost/#phonons","text":"In order to understand phonons better, we need to understand how a vibrational motion in a solid arises. To that end, we model an array of atoms that are connected by springs with a spring constant \\(\\kappa\\) . Our plan: Consider only a harmonic potential acting between the atoms ( \\(\\kappa\\) is constant) Write down equations of motion Compute normal modes For simplicity we consider 1D motion, and let us start with a chain of 3 atoms: # Defining constants y_max = 6 max_m = 3 # Off set for the new masses deviation_arr = [ + 2 , - 2 , - 3.5 ] def plot_spring ( x1 , x2 , y , annotation = r '$\\kappa$' ): L = ( x2 - x1 ) width , nturns = 1 , 10 N = 1000 pad = 200 # Make the spring, unit scale (0 to 1) x_spring = np . linspace ( 0 , L , N ) # distance along the spring y_spring = np . zeros ( N ) y_spring [ pad : - pad ] = width * np . sin ( 2 * np . pi * nturns * x_spring [ pad : - pad ] / L ) x_plot , y_plot = np . vstack (( x_spring , y_spring )) # And offset it x_plot += x1 y_plot += y ax . plot ( x_plot , y_plot , c = 'k' ) ax . annotate ( annotation , (( x2 + x1 ) / 2 , y + 2 ), fontsize = 40 ) def plot_mass ( x , y , annotation = r '$m$' ): mass = Circle (( x , y ), .5 , fc = 'k' ) ax . add_patch ( mass ) ax . annotate ( annotation , ( x - .5 , y + 2 ), fontsize = 30 ) def make_plot ( u , deviation_arr , max_masses = 3 ): # plotting initial masses plot_mass ( 0 , 0 ) plot_mass ( 0 + deviation_arr [ 0 ], u , annotation = '' ) # Plot initial dotted lines pyplot . plot (( 0 , 0 ), ( 0 , u - 2.5 ), 'k--' ) pyplot . plot (( deviation_arr [ 0 ], deviation_arr [ 0 ]), ( u , u - 2.5 ), 'k--' ) # pyplot.plot((0, deviation_arr[0]), (u-2.5, u-2.5), 'k--') pyplot . arrow ( 0 , u - 2.5 , deviation_arr [ 0 ] - .5 , 0 , fc = \"k\" , ec = \"k\" , head_width = .25 , head_length = .5 ) # Annotate the deviations annot_arr = [ r '$u_1$' , r '$u_2$' , r '$u_3$' ] off_set = - 1 ax . annotate ( annot_arr [ 0 ], ( deviation_arr [ 0 ] / 2 + off_set + .4 , u - 3 + off_set ), fontsize = 30 ) # Annotate large arrow containing the interatomic distance pyplot . arrow ( 0 , u / 3 , 9 , 0 , fc = \"k\" , ec = \"k\" , head_width = .5 , head_length = 1 ) ax . annotate ( r '$a$' , ( 5 , u / 3 + off_set ), fontsize = 30 ) # Plotting other masses and springs for j in range ( max_masses - 1 ): # Equilibrium plot plot_spring ( 10 * j , 10 * ( j + 1 ), 0 ) plot_mass ( 10 * ( j + 1 ), 0 ) # Plot containing deviations from it's equilibrium plot_spring ( 10 * j + deviation_arr [ j ], 10 * ( j + 1 ) + deviation_arr [ j + 1 ], u , annotation = '' ) plot_mass ( 10 * ( j + 1 ) + deviation_arr [ j + 1 ], u , annotation = '' ) # Plot dotted lines pyplot . plot (( 10 * ( j + 1 ), 10 * ( j + 1 )), ( 0 , u - 2.5 ), 'k--' ) pyplot . plot (( 10 * ( j + 1 ) + deviation_arr [ j + 1 ], 10 * ( j + 1 ) + deviation_arr [ j + 1 ]), ( u , u - 2.5 ), 'k--' ) # pyplot.plot((10*(j+1), 10*(j+1)+deviation_arr[j+1]), (u-2.5, u-2.5), 'k--') pyplot . arrow ( 10 * ( j + 1 ), u - 2.5 , ( deviation_arr [ j + 1 ] + .5 ), 0 , fc = \"k\" , ec = \"k\" , head_width = .25 , head_length = .5 ) # Annotations ax . annotate ( annot_arr [ j + 1 ], ( 10 * ( j + 1 ) + deviation_arr [ j + 1 ] / 2 + off_set + .4 , u - 3 + off_set ), fontsize = 30 ) # Initializing figure fig , ax = pyplot . subplots ( figsize = ( 10 , 7 )) pyplot . axis ( 'off' ) ax . set_xlim (( - 1 , 10 * ( max_m - 1 ) + 1 )) ax . set_ylim (( - y_max - 4.5 , y_max - 2.5 )) # Plottig system make_plot ( - y_max , deviation_arr , max_m ); fig . show () Let us denote the deviation of atom \\(i\\) from its equilibrium position by \\(u_i\\) . Newton's equations of motion for this system are then given by \\[ \\begin{aligned} m \\ddot{u}_1 &= - \\kappa (u_1 - u_2) \\\\ m \\ddot{u}_2 &= - \\kappa (u_2 - u_1) - \\kappa (u_2 - u_3) \\\\ m \\ddot{u}_3 &= - \\kappa (u_3 - u_2). \\end{aligned}, \\] We write this system of equations in matrix form \\[ m \\ddot{\\mathbf{u}} = -\\kappa \\begin{pmatrix} 1 & -1 & 0\\\\ -1 & 2 & -1\\\\ 0 & -1 & 1 \\end{pmatrix}\\mathbf{u} \\] We are interested in phonons, patterns of motion that are periodic and have a fixed frequency \\(\\omega\\) . Hence we guess that the motion of the atoms is \\[ \\mathbf{u}(t) = \\mathbf{u}_0 e^{i\\omega t}. \\] We substitute our guess into the equations of motion to yield an eigenvalue problem: \\[ \\omega^2 \\mathbf{u}_0 = \\frac{\\kappa}{m} \\begin{pmatrix} 1 & -1 & 0\\\\ -1 & 2 & -1\\\\ 0 & -1 & 1 \\end{pmatrix}\\mathbf{u}_0. \\] The solutions to the eigenvalue problem are phonon modes.","title":"Phonons"},{"location":"Lost/#electrons","text":"We just looked at how a chain of atoms moves. Let us now look at how the electrons of those atoms behave. To that end, we consider a 3 atom chain without any motion. In order to understand how electrons behave, we use the LCAO model. The LCAO model generalizes in a very simple way. Let us consider the wavefunction: \\vert \\psi\\rangle = \\varphi_1 |1\\rangle + \\varphi_2 |2\\rangle + \\varphi_3 |3\\rangle. Because the three atoms are identical, the onsite energy is the same on all atoms \\(\\langle 1|H|1 \\rangle = \\langle2|H|2 \\rangle = \\langle3|H|3 \\rangle = E_0\\) . Furthermore, we assume hopping only between the nearest neighbors and assume that it is real valued: \\(\\langle1|H|2\\rangle = \\langle2|H|3\\rangle = -t\\) . We also assume that the orbitals are orthogonal to eachother. Just as we did in the previous lecture, we use the Schr\u00f6dinger equation \\(H |\\psi\\rangle = E |\\psi\\rangle\\) to set up a system of equations: \\[ \\begin{align} E \\varphi_1 &= E_0 \\varphi_1 - t \\varphi_2\\\\ E \\varphi_2 &= E_0 \\varphi_2 - t \\varphi_1 - t \\varphi_3\\\\ E \\varphi_3 &= E_0 \\varphi_3 -t \\varphi_2. \\end{align} \\] Again, we write this in a matrix form: \\[ E \\begin{pmatrix} \\varphi_1 \\\\ \\varphi_2 \\\\ \\varphi_3 \\end{pmatrix} = \\begin{pmatrix} E_0 & -t & 0 \\\\ -t & E_0 & -t \\\\ 0 & -t & E_0 \\end{pmatrix} \\begin{pmatrix} \\varphi_1 \\\\ \\varphi_2 \\\\ \\varphi_3. \\end{pmatrix} \\]","title":"Electrons"},{"location":"Lost/#numerical-test","text":"Diagonalizing large matrices is unwieldy, but let's try and check it numerically to see if we notice a trend. Let us first model 3 atoms on a chain. The eigenfrequencies of the 3 atoms are: [0.0 1.0 1.732050] def DOS_finite_phonon_chain ( n ): rhs = 2 * np . eye ( n ) - np . eye ( n , k = 1 ) - np . eye ( n , k =- 1 ) rhs [ 0 , 0 ] -= 1 rhs [ - 1 , - 1 ] -= 1 pyplot . figure () pyplot . hist ( np . sqrt ( np . abs ( np . linalg . eigvalsh ( rhs ))), bins = 30 ) pyplot . xlabel ( \"$\\omega$\" ) pyplot . ylabel ( \"Number of eigenfrequencies\" ) DOS_finite_phonon_chain ( 3 ) The eigenenergies of the 3 orbitals are: [-1.41421356 0.0 1.41421356] def DOS_finite_electron_chain ( n ): rhs = 2 * np . eye ( n , k = 0 ) - np . eye ( n , k = 1 ) - np . eye ( n , k = - 1 ) pyplot . figure () pyplot . hist ( np . linalg . eigvalsh ( rhs ), bins = 30 ) pyplot . xlabel ( \"$E$\" ) pyplot . ylabel ( \"Number of eigenenergies\" ) DOS_finite_electron_chain ( 3 ) However, 3 atoms are far too few to model an actual solid. Hence, we need 'many more' atoms.","title":"Numerical test"},{"location":"Lost/#from-3-atoms-to-300","text":"Phonon modes of the many atom chain are shown below. DOS_finite_phonon_chain ( 300 ) We observe that when \\(\\omega\\) is small, we have a constant DOS. This is in line with what we saw in the Debye model. There the DOS of a 1D system was constant! However, when the frequencies are higher, the DOS is not constant anymore. A plot of electron energies in the many atom chain is shown below. DOS_finite_electron_chain ( 300 ) The numerical results once again agree with the models we developed earlier. In the Sommerfeld free electron model, the DOS in 1D is proportional to \\(\\frac{1}{\\sqrt{E}}\\) . The above histogram also reflects this proportionality for small energies \\(E\\) . However, when \\(E\\) is higher, we observe a significant deviation from the \\(\\frac{1}{\\sqrt{E}}\\) behavior. In both cases, we find that our models agree with the numerical results whenever frequencies/energies are small. When the frequencies/energies are high, we find that there is a significant deviation from the Debye/Sommerfeld models. The nature of this deviation is the subject of the next lecture!","title":"From 3 atoms to 300"},{"location":"Lost/#conclusions","text":"The DOS of phonons used in the Debye model is justified by modeling the atoms as particles on a chain connected by a spring in the small \\(\\omega\\) limit. The DOS of electrons in the Sommerfeld model is justified by modeling electrons as particles that can hop between atoms in the small \\(E\\) limit.","title":"Conclusions"},{"location":"Lost/#exercises","text":"","title":"Exercises"},{"location":"Lost/#preliminary-provocations","text":"What does the LCAO matrix in the lecture notes look like if we also consider a next nearest-neighbour hopping \\(-\\tilde{t}\\) ? What does the LCAO matrix look like if we consider six atoms instead of three? You may assume that each atom has a single orbital, onsite energy \\(E_0\\) and the hopping between neighbouring atoms \\(-t\\) . How do you determine which part of the interatomic potential is attractive and which is repulsive? You may assume that the interatomic potential is only a function of the interatomic distance \\(r\\) .","title":"Preliminary provocations"},{"location":"Lost/#exercise-1-linear-triatomic-molecule","text":"Consider carbon dioxide (C0 \\(_2\\) ) which is a linear triatomic molecule shown below ??? info \"source\" By Jasek FH. - Own work, [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/3.0 \"Creative Commons Attribution-Share Alike 3.0\"), [Link](https://commons.wikimedia.org/w/index.php?curid=2875238) How many normal modes does this molecule have assuming motion in only 1D? How many normal modes does it have if the atoms can move in all three dimensions? For simplicity, we only consider 1D motion of the atoms. Write down Newton's equations of motion for the atoms, you may assume that the spring constant is the same for both bonds. Consider a symmetric mode, for which the displacements of the oxygen atoms are equal in magnitude and have an opposite direction. Find the eigenfrequency of this mode. Now consider the antisymmetric mode when both of the oxygen atoms move in phase and have the same displacement. Find the ratio between the displacements of the carbon and oxygen atoms. Make sure that the center of mass of the molecule is at rest. Compute the eigenfrequency of the antisymmetric mode. Hint Compare your answers with Wikipedia . From Diatomic solids","title":"Exercise 1: Linear triatomic molecule"},{"location":"Lost/#exercise-2-the-peierls-transition","text":"In the previous lecture, we have derived the electronic band structure of an 1D, equally spaced atomic chain. Such chains, however, are in fact not stable and the equal spacing will be distorted. This is also known as the Peierls transition . The spacing of the distorted chain alternates between two different distances and this also causes the hopping energy to alternate between \\(t_1\\) and \\(t_2\\) . We further set the onsite energies of the atoms to \\(\\epsilon\\) . The situation is depicted in the figure below. Due to the alternating hopping energies, we must treat two consecutive atoms as two different orbitals ( \\(|n,1\u27e9\\) and \\(|n,2 \u27e9\\) in the figure) from the same unit cell. The corresponding LCAO of this chain is given by \\left|\\Psi \\right\\rangle = \\sum_n \\left(\\phi_n \\left| n,1 \\right\\rangle + \\psi_n \\left| n,2 \\right\\rangle\\right) As usual, we assume that all these atomic orbitals are orthogonal to each other. Indicate the length of the unit cell \\(a\\) in the figure. Using the Schr\u00f6dinger equation, write the equations of motion of the electrons. Hint To this end, find expressions for \\(E \\left< n,1 \\vert \\Psi \\right> = \\left< n,1 \\right| H \\left|\\Psi \\right>\\) and \\(E \\left< n,2 \\vert \\Psi \\right> = \\left< n,2 \\right| H \\left|\\Psi \\right>\\) . Using the trial solutions \\(\\phi_n = \\phi_0 e^{ikna}\\) and \\(\\psi_n = \\psi_0 e^{ikna}\\) , show that the Sch\u00f6dinger equation can be written in matrix form: \\( \\(\\begin{pmatrix} \\epsilon & t_1 + t_2 e^{-i k a} \\\\ t_1 + t_2 e^{i k a} & \\epsilon \\end{pmatrix} \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix} = E \\begin{pmatrix} \\phi_0 \\\\ \\psi_0 \\end{pmatrix}.\\) \\) Derive the dispersion relation of this Hamiltonian. Does it look like the figure of the band structure shown on the Wikipedia page ? Does it reduce to the 1D, equally spaced atomic chain if \\(t_1 = t_2\\) ? Find an expression of the group velocity \\(v(k)\\) and effective mass \\(m^*(k)\\) of both bands. Derive an expression for the density of states \\(g(E)\\) of the entire band structure and make a plot of it. Does your result makes sense when considering the band structure?","title":"Exercise 2: the Peierls transition"},{"location":"Lost/#tight-binding","text":"","title":"Tight binding"},{"location":"Lost/#group-velocity-effective-mass-density-of-states","text":"(here we only discuss electrons; for phonons everything is the same except for replacing \\(E = \\hbar \\omega\\) ) Let us think what happens if we apply an external electric field to the crystal: x = np . linspace ( 0.001 , 3 , 200 ) fig , ax = pyplot . subplots ( 1 , 1 ) ax . plot ( x , 1.2 - 1 / np . abs ( np . sin ( np . pi * x )) ** ( 1 / 2 ) + .2 * ( x - 1.5 )) ax . plot ( x , .2 * ( x - 0.25 ), '--' ) ax . set_ylim ( - .7 , .5 ) ax . set_xlabel ( \"$x$\" ) ax . set_ylabel ( \"$U(x)$\" ) ax . set_xticks ([ - .05 , 1 , 2 ]) ax . set_xticklabels ([ \"$0$\" , \"$a$\" , \"$2a$\" ]) draw_classic_axes ( ax ) The full Hamiltonian of the system is H = \\frac{p^2}{2m} + U_\\textrm{atomic}(x) + e \\mathcal{E} x, where \\(U_\\textrm{atomic}\\) is the potential created by the nuclei, and \\(\\mathcal{E}\\) the electric field. A typical electric field is much smaller than the interatomic potential, and therefore we can start by obtaining the dispersion relation \\(E(k)\\) without electric field (by applying the LCAO method), and then solve H = E(k) + e\\mathcal{E}x. To derive how particles with an arbitrary dispersion relation move, we recall the Hamilton's equations for particle velocity \\(v\\) and force \\(F\\) : \\[\\begin{aligned} v \\equiv \\frac{dr}{dt} &= \\frac{\\partial H(p, r)}{\\partial p}\\\\ F \\equiv \\frac{dp}{dt} &= -\\frac{\\partial H(p, r)}{\\partial r}. \\end{aligned}\\] Substituting \\(p = \\hbar k\\) into the first equation we arrive to the expression for the electron group velocity \\(v \\equiv \\hbar^{-1}\\partial E/\\partial k\\) . From the second equation we obtain that the force acting on electron in a band stays \\(-e\\mathcal{E}\\) , which in turn gives results in the acceleration \\frac{dv}{dt} = \\frac{\u2202v}{\u2202p}\\frac{dp}{dt} = F/m. Comparing this expression with \\(dv/dt = F/m\\) , we arrive to the effective mass : m^* \\equiv \\left(\\frac{\u2202v}{\u2202p}\\right)^{-1} = \\left(\\frac{\u2202\u00b2E}{\u2202p\u00b2}\\right)^{-1} = \u0127\u00b2\\left(\\frac{\u2202\u00b2E}{\u2202k\u00b2}\\right)^{-1}. The group velocity describes how quickly electrons with a certain \\(k\\) -vector move, while the effective mass describes how hard they are to accelerate by applying external force. By using the dispersion relation we derived earlier, we obtain the effective mass like this: pyplot . figure ( figsize = ( 8 , 5 )) k = np . linspace ( - pi , pi , 300 ) meff = 1 / np . cos ( k ) color = list ( matplotlib . rcParams [ 'axes.prop_cycle' ])[ 0 ][ 'color' ] pyplot . plot ( k [ meff > 0 ], meff [ meff > 0 ], c = color ) pyplot . plot ( k [ meff < 0 ], meff [ meff < 0 ], c = color ) pyplot . ylim ( - 5 , 5 ) pyplot . xlabel ( '$ka$' ); pyplot . ylabel ( '$m^*$' ) pyplot . xticks ([ - pi , 0 , pi ], [ r '$-\\pi$' , 0 , r '$\\pi$' ]); Notice that the effective mass can be negative, which implies the electrons accelerate in the direction opposite to the applied force.","title":"Group velocity, effective mass, density of states"},{"location":"Lost/#density-of-states","text":"The DOS is the number of states per unit energy. In 1D we have \\( \\(g(E) = \\frac{L}{2\\pi}\\sum |dk/dE| = \\frac{L}{2\\pi}\\sum |v|^{-1}\\) \\) The sum goes over all possible values of \\(k\\) and spin which have the same energy \\(E\\) . If we are working in two or more dimensions, we must integrate over the values of \\(k\\) with the same energy. Also take note that for energies below \\(E_0 - 2t\\) or above \\(E_0 + 2t\\) , there are no values of \\(k\\) with that energy, so there is nothing to sum over. Once again, starting from E = E_0 - 2t \\cos(ka), we get ka = \\pm\\arccos[(E - E_0) / 2t], and |v| ^{-1} = \\left|\\frac{dk}{dE} \\right| = \\frac{1}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. You can get to this result immediately if you remember the derivative of arccosine. Otherwise you need to go the long way: compute \\(dE/dk\\) as a function of \\(k\\) , express \\(k\\) through \\(E\\) as we did above, and take the inverse. We now add together the contributions of the positive and the negative momenta as well both spin orientations, and arrive to the density of states g(E) = \\frac{L}{2\\pi}\\frac{4}{a}\\frac{1}{\\sqrt{4t^2 - (E - E_0)^2}}. A quick check: when the energy is close to the bottom of the band, \\(E = E_0 - 2t + \\delta E\\) , we get \\(g(E) \\propto \\delta E^{-1/2}\\) , as we expect in 1D. The process of calculating the DOS at a given energy \\(E\\) of a spin-independent Hamiltonian is done systematically with the following steps: At a given energy \\(E\\) , determine all of the values of \\(k\\) which correspond to that \\(E\\) using the dispersion relation. Compute \\(\\rvert dk / dE \\rvert\\) . Do this either by writing \\(k\\) as a (multi-valued) function of \\(E\\) and differentiating, or by computing \\((dE / dk)^{-1}\\) . Sum or integrate \\(dk / dE\\) over the allowed values of \\(k\\) found in 1 and multiply by any degeneracies (spin/polarization). Multiply by spin degeneracy. If the Hamiltonian depends on spin, then there is no spin degeneracy and the spin number \\(s\\) must be treated in the same way as \\(k\\) .","title":"Density of states"},{"location":"additional/","text":"Additional resources \u00b6 This page is the space for additional resources which may prove to be of some use and/or interest for curious individuals. Websites Modern Physics: Quantum Mechanics by Leonard Susskind from Stanford is a popular youtube series covering much of the content of this course. The series was recorded in 2008 and thus the audio and video quality is left wanting, but the content is very well presented. Texts Undergraduate texts for quantum mechanics are common; however, concise, informed, relevant, and entertaining texts are much less common. I think the prescribed text is the best text for this course, but an excellent alternative which follows a similar approach to the material is A Modern Approach to Quantum Mechanics, Second Edition by John S. Townsend from Harvey Mudd College . If you are looking for a more traditional presentation of introductory quantum mechanics, a classic of the genre is Introduction to Quantum Mechanics by David J. Griffiths and Darrell F. Schroeter from Reed College . Quantum Mechanics and Quantum and Atom Optics by Daniel A. Steck from the University of Oregon : marvellous books that have been diligently curated and provide excellent reading, although are more advanced for the most part. The Quantum Mechanics text is highly pertinent to this course, and the Quantum and Atom Optics text, whilst more pertinent for both the atomic physics and solid-state physics courses to follow, contains relevant content and includes some of the most interesting material one is likely to encounter in the realm of quantum mechanics 1 ; however, it is pitched at the graduate level and assumed knowledge of material not taught in the UTAS undergraduate program. I still think it worthwhile as an additional resource, but don't fret if it becomes a bit hard to follow once it gets into the weeds. Harry Potter and the methods of rationality by Eliezer Eudkowsky . Who know that Harry Potter fan fiction could provide such insight. As a jumping off point: Petunia married a biochemist, and Harry grew up reading science and science fiction. Then came the Hogwarts letter, and a world of intriguing new possibilities to exploit. Previous course notes Quantum mechanics at UTAS is taught every year, with the previous course outing having been taught by Stas Shabala and Andrew Cole for advanced wave mechanics and quantum mechanics respectively. The notes from the 2022 course are posted here as a reference, but it should be emphasised that the course structure is vastly different, and consequently one's mileage may vary. Advanced wave mechanics Quantum mechanics and I am not just saying this because my research has been in this area, it is objectively true! \u21a9","title":"Additional resources"},{"location":"additional/#additional-resources","text":"This page is the space for additional resources which may prove to be of some use and/or interest for curious individuals. Websites Modern Physics: Quantum Mechanics by Leonard Susskind from Stanford is a popular youtube series covering much of the content of this course. The series was recorded in 2008 and thus the audio and video quality is left wanting, but the content is very well presented. Texts Undergraduate texts for quantum mechanics are common; however, concise, informed, relevant, and entertaining texts are much less common. I think the prescribed text is the best text for this course, but an excellent alternative which follows a similar approach to the material is A Modern Approach to Quantum Mechanics, Second Edition by John S. Townsend from Harvey Mudd College . If you are looking for a more traditional presentation of introductory quantum mechanics, a classic of the genre is Introduction to Quantum Mechanics by David J. Griffiths and Darrell F. Schroeter from Reed College . Quantum Mechanics and Quantum and Atom Optics by Daniel A. Steck from the University of Oregon : marvellous books that have been diligently curated and provide excellent reading, although are more advanced for the most part. The Quantum Mechanics text is highly pertinent to this course, and the Quantum and Atom Optics text, whilst more pertinent for both the atomic physics and solid-state physics courses to follow, contains relevant content and includes some of the most interesting material one is likely to encounter in the realm of quantum mechanics 1 ; however, it is pitched at the graduate level and assumed knowledge of material not taught in the UTAS undergraduate program. I still think it worthwhile as an additional resource, but don't fret if it becomes a bit hard to follow once it gets into the weeds. Harry Potter and the methods of rationality by Eliezer Eudkowsky . Who know that Harry Potter fan fiction could provide such insight. As a jumping off point: Petunia married a biochemist, and Harry grew up reading science and science fiction. Then came the Hogwarts letter, and a world of intriguing new possibilities to exploit. Previous course notes Quantum mechanics at UTAS is taught every year, with the previous course outing having been taught by Stas Shabala and Andrew Cole for advanced wave mechanics and quantum mechanics respectively. The notes from the 2022 course are posted here as a reference, but it should be emphasised that the course structure is vastly different, and consequently one's mileage may vary. Advanced wave mechanics Quantum mechanics and I am not just saying this because my research has been in this area, it is objectively true! \u21a9","title":"Additional resources"},{"location":"particulars/","text":"Course information \u00b6 Administration \u00b6 The measurement component of the quantum course will run for six weeks, beginning in week 8 and concluding at the end of semester. In previous years, the quantum mechanics covered advanced wave mechanics in the context of single-particle systems and a subsequent discussion of quantum mechanical systems. In contrast, this course begins with the foundations of quantum mechanics, taking an axiomatic approach to QM theory and using the wavefunction as a tool to model physical phenomena, and the latter part of the course devoted to quantum measurement and a generalised description of quantum states. Prerequisite knowledge The content covered the measurement component of the course is testing, and without the frim bedrock of requisite knowledge and associated competencies, attempts to construct additional structures may be compromised. It is critical that one is comfortable with the following: The principles and machinery of wave mechanics. Explicitly, an understanding of how physical systems and their evolution are modelled using the wave equation, along with a fluency in common examples (plane-wave solutions, travelling waves, etc.). The foundations of quantum mechanics, including the (time dependent) Schr\u00f6dinger equation and its solutions for common physical systems, and importantly, you must be comfortable with the physical concepts which underpin the mathematics. Fortunately, you have just completed a 7 week introduction to quantum mechanics and it will be assumed that you are comfortable with the content. It is my intention that you will be required to call upon many of the other tools from the toolbox that you have been developing during your studies, with the explicit aim of further honing these tools, and maybe adding a few to the kit. Delivery of content \u00b6 The course will operate in a flipped-mode configuration, whereby the undergirding principle is that your out-of-class time is used to consume prepared content (e.g. lectures ) and scheduled times are used for discussions in a problem-based learning framework. I prefer to refer to the lecture-style material as the content download , and interactive, active-learning sessions as the content unpacking component. Subject matter \u00b6 The content for this course draws heavily from off the excellent text Quantum Mechanics, A Paradigms Approach (2nd edition) by David H. McIntyre , and the book is a prescribed text for the course, that is, it is assumed that you will have access to this book. This particular text was chosen because of its considered approach to the ordering of content, its accessible rigour, and its delightful quirks and humour. It is also one of the best introductory texts on the subject, so whether you fall deeply into the quantum rabbit hole or pack it all in to cultivate vanilla in Madagascar, your will be able to polish up on the basics thanks to the text 1 . Wait, are you actually prescribing a textbook? Yes. And no, you haven't just been transported to 1993; I endeavour to employ evidence-based, best-practice methods for teaching, and this includes deploying many modern teaching aids, and also includes ensuring a glorious reference is prescribed. I will be working from the hardcopy, and I encourage you to do the same, although softcopies can be a more cost effective option. Course outline \u00b6 Course summary This subject is designed to be a thorough introduction to quantum mechanics. As an experiment, cast your mind back to when you first started learning (classical) physics. Now, how many years has it been since you started? How much content have you learned? This course seeks to introduce you to the theory which supplants classical physics, which by its very nature means there is an enormous amount of content, and necessarily it is both more refined and complex. Therefore, the course really will be an introduction, a taster for what is out there in the quantum world; in the context of study at UTAS , the endpoint of this course will serve as the starting point of both the atomic physics KYA323 and solid-state physics KYA322 units, which are in essence, applications of quantum mechanics. The building blocks we shall study are the principles of nonrelativistic quantum theory and applications, starting with spin and quantum measurement in a state vector formalism and broadly moving onto implications and applications of quantum mechanics. A rough outline of the course is as follows: The Stern-Gerlach experiment, state vectors, and Dirac (bra-ket) notation Matrix notation, general quantum systems Operators, Measurement, Spin 1 system Time evolution with Dirac - precession, neutrino oscillations, magnetic resonance (2-level atom) EPR paradox, Bell's inequalities, Schr\u00f6dinger's Cat Applications with approximately one week devoted to each topic, but with the natural ebb and flow ultimately dictating the timeline. The notes \u00b6 The notes are designed to be consumed in concert to the video content, with certain aspects highlighted differently in the different media, and in extreme cases with different paths used to arrive at the same destination. One of my aims is to expose you to different ways of thinking about problems, not just have the same method and then just \"press play\". Expected competencies Content has been constructed with the assumption that the material is consumed sequentially, with sections often explicitly relying on results from previous work. I have also to placed expected competency markers at the beginning of each section, outlining knowledge that I expect you to have seen in other areas of study, and importantly, these are cumulative from section to section. Text reference You will also encounter text references at the beginning of each section, relating to the relevant content in the course text Quantum Mechanics, A Paradigms Approach (2nd edition) Computational content Computational content, which is normally just the jupyter notebook associated with the section, also appears at the top of the page, but may also contain links to other software or pertinent computational material. The videos \u00b6 The video content is hosted on Echo360 and is available only to those enrolled at the University of Tasmania, and is best accessed through the course MyLO page . Support \u00b6 You are not on this journey alone: there are many avenues available to you to help you on the journey (depending on your inclination to watch fantasy movies in the 2000s, you may or not take comfort in the support Harry Potter received by those around him). The course materials as consumed through the content download components are necessarily an individual effort, but in all other facets I strongly encourage collaboration. The structure of content unpacking sessions is deliberately geared towards discussion, the exchange of ideas, and collective problem solving moreso than the execution of a solution finding program. Quote ... there's something in science like the shine of the Patronus Charm, driving back all sorts of darkness and madness ... Eliezer Eudkowsky (Less Wrong), Harry Potter and the methods of rationality Computational resources \u00b6 As part of the course, it will be expected that you perform calculation and computations. You are welcome to do this in which ever language you prefer, but it is strongly recommended that you use Python , and indeed, this is the only language that will be supported. In order to ensure equitable and easy access to Python computing resources, a Jupyter Notebook server has been established, which allows for one to write and execute code via a web browser. The server is named Jove 2 , and access is through the JupyterHub portal . You will need to create an account to start using the server, but beyond this is should be click and go. Should you experience any problems getting this up and running, please see the computation section of POLUS . Should you have a machine upon which you already have, or you wish to deploy, your own instance of Python , this is perfectly acceptable, but note that you will have to manually import the distributed materials into Jupyter. This can be effectively accomplished using the clone functionality of GitHub as this is where the course content is hosted. Bug catcher \u00b6 Finally, this is more of a request than anything else, but should you find any errors in the content - this site, the distributed notebooks, the content download sessions, whatever - please let me know so I can correct the content, which is a major boon for everyone involved. Thanks! No, I am not a shill , I just really endorse the book. Although David, if you see this, contact me for my bank deets. \u21a9 For those wondering, Jove is an alternate name for the Roman god Jupiter. \u21a9","title":"Course particulars"},{"location":"particulars/#course-information","text":"","title":"Course information"},{"location":"particulars/#administration","text":"The measurement component of the quantum course will run for six weeks, beginning in week 8 and concluding at the end of semester. In previous years, the quantum mechanics covered advanced wave mechanics in the context of single-particle systems and a subsequent discussion of quantum mechanical systems. In contrast, this course begins with the foundations of quantum mechanics, taking an axiomatic approach to QM theory and using the wavefunction as a tool to model physical phenomena, and the latter part of the course devoted to quantum measurement and a generalised description of quantum states. Prerequisite knowledge The content covered the measurement component of the course is testing, and without the frim bedrock of requisite knowledge and associated competencies, attempts to construct additional structures may be compromised. It is critical that one is comfortable with the following: The principles and machinery of wave mechanics. Explicitly, an understanding of how physical systems and their evolution are modelled using the wave equation, along with a fluency in common examples (plane-wave solutions, travelling waves, etc.). The foundations of quantum mechanics, including the (time dependent) Schr\u00f6dinger equation and its solutions for common physical systems, and importantly, you must be comfortable with the physical concepts which underpin the mathematics. Fortunately, you have just completed a 7 week introduction to quantum mechanics and it will be assumed that you are comfortable with the content. It is my intention that you will be required to call upon many of the other tools from the toolbox that you have been developing during your studies, with the explicit aim of further honing these tools, and maybe adding a few to the kit.","title":"Administration"},{"location":"particulars/#delivery-of-content","text":"The course will operate in a flipped-mode configuration, whereby the undergirding principle is that your out-of-class time is used to consume prepared content (e.g. lectures ) and scheduled times are used for discussions in a problem-based learning framework. I prefer to refer to the lecture-style material as the content download , and interactive, active-learning sessions as the content unpacking component.","title":"Delivery of content"},{"location":"particulars/#subject-matter","text":"The content for this course draws heavily from off the excellent text Quantum Mechanics, A Paradigms Approach (2nd edition) by David H. McIntyre , and the book is a prescribed text for the course, that is, it is assumed that you will have access to this book. This particular text was chosen because of its considered approach to the ordering of content, its accessible rigour, and its delightful quirks and humour. It is also one of the best introductory texts on the subject, so whether you fall deeply into the quantum rabbit hole or pack it all in to cultivate vanilla in Madagascar, your will be able to polish up on the basics thanks to the text 1 . Wait, are you actually prescribing a textbook? Yes. And no, you haven't just been transported to 1993; I endeavour to employ evidence-based, best-practice methods for teaching, and this includes deploying many modern teaching aids, and also includes ensuring a glorious reference is prescribed. I will be working from the hardcopy, and I encourage you to do the same, although softcopies can be a more cost effective option.","title":"Subject matter"},{"location":"particulars/#course-outline","text":"Course summary This subject is designed to be a thorough introduction to quantum mechanics. As an experiment, cast your mind back to when you first started learning (classical) physics. Now, how many years has it been since you started? How much content have you learned? This course seeks to introduce you to the theory which supplants classical physics, which by its very nature means there is an enormous amount of content, and necessarily it is both more refined and complex. Therefore, the course really will be an introduction, a taster for what is out there in the quantum world; in the context of study at UTAS , the endpoint of this course will serve as the starting point of both the atomic physics KYA323 and solid-state physics KYA322 units, which are in essence, applications of quantum mechanics. The building blocks we shall study are the principles of nonrelativistic quantum theory and applications, starting with spin and quantum measurement in a state vector formalism and broadly moving onto implications and applications of quantum mechanics. A rough outline of the course is as follows: The Stern-Gerlach experiment, state vectors, and Dirac (bra-ket) notation Matrix notation, general quantum systems Operators, Measurement, Spin 1 system Time evolution with Dirac - precession, neutrino oscillations, magnetic resonance (2-level atom) EPR paradox, Bell's inequalities, Schr\u00f6dinger's Cat Applications with approximately one week devoted to each topic, but with the natural ebb and flow ultimately dictating the timeline.","title":"Course outline"},{"location":"particulars/#the-notes","text":"The notes are designed to be consumed in concert to the video content, with certain aspects highlighted differently in the different media, and in extreme cases with different paths used to arrive at the same destination. One of my aims is to expose you to different ways of thinking about problems, not just have the same method and then just \"press play\". Expected competencies Content has been constructed with the assumption that the material is consumed sequentially, with sections often explicitly relying on results from previous work. I have also to placed expected competency markers at the beginning of each section, outlining knowledge that I expect you to have seen in other areas of study, and importantly, these are cumulative from section to section. Text reference You will also encounter text references at the beginning of each section, relating to the relevant content in the course text Quantum Mechanics, A Paradigms Approach (2nd edition) Computational content Computational content, which is normally just the jupyter notebook associated with the section, also appears at the top of the page, but may also contain links to other software or pertinent computational material.","title":"The notes"},{"location":"particulars/#the-videos","text":"The video content is hosted on Echo360 and is available only to those enrolled at the University of Tasmania, and is best accessed through the course MyLO page .","title":"The videos"},{"location":"particulars/#support","text":"You are not on this journey alone: there are many avenues available to you to help you on the journey (depending on your inclination to watch fantasy movies in the 2000s, you may or not take comfort in the support Harry Potter received by those around him). The course materials as consumed through the content download components are necessarily an individual effort, but in all other facets I strongly encourage collaboration. The structure of content unpacking sessions is deliberately geared towards discussion, the exchange of ideas, and collective problem solving moreso than the execution of a solution finding program. Quote ... there's something in science like the shine of the Patronus Charm, driving back all sorts of darkness and madness ... Eliezer Eudkowsky (Less Wrong), Harry Potter and the methods of rationality","title":"Support"},{"location":"particulars/#computational-resources","text":"As part of the course, it will be expected that you perform calculation and computations. You are welcome to do this in which ever language you prefer, but it is strongly recommended that you use Python , and indeed, this is the only language that will be supported. In order to ensure equitable and easy access to Python computing resources, a Jupyter Notebook server has been established, which allows for one to write and execute code via a web browser. The server is named Jove 2 , and access is through the JupyterHub portal . You will need to create an account to start using the server, but beyond this is should be click and go. Should you experience any problems getting this up and running, please see the computation section of POLUS . Should you have a machine upon which you already have, or you wish to deploy, your own instance of Python , this is perfectly acceptable, but note that you will have to manually import the distributed materials into Jupyter. This can be effectively accomplished using the clone functionality of GitHub as this is where the course content is hosted.","title":"Computational resources"},{"location":"particulars/#bug-catcher","text":"Finally, this is more of a request than anything else, but should you find any errors in the content - this site, the distributed notebooks, the content download sessions, whatever - please let me know so I can correct the content, which is a major boon for everyone involved. Thanks! No, I am not a shill , I just really endorse the book. Although David, if you see this, contact me for my bank deets. \u21a9 For those wondering, Jove is an alternate name for the Roman god Jupiter. \u21a9","title":"Bug catcher"},{"location":"placeholder/","text":"Placeholder \u00b6 Introduction \u00b6 Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Text reference The material covered here is discussed in section(s) \\(\\S1.1\\) of Quantum Mechanics, A Paradigms Approach (2nd edition) Computational content The Jupyter notebook associated with this section can be accessed by clicking the icon below: Content Conclusions \u00b6 Exercises \u00b6 Preliminary provocations \u00b6 Heavy hitters \u00b6 Image credits Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients","title":"Placeholder"},{"location":"placeholder/#placeholder","text":"","title":"Placeholder"},{"location":"placeholder/#introduction","text":"Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Text reference The material covered here is discussed in section(s) \\(\\S1.1\\) of Quantum Mechanics, A Paradigms Approach (2nd edition) Computational content The Jupyter notebook associated with this section can be accessed by clicking the icon below: Content","title":"Introduction"},{"location":"placeholder/#conclusions","text":"","title":"Conclusions"},{"location":"placeholder/#exercises","text":"","title":"Exercises"},{"location":"placeholder/#preliminary-provocations","text":"","title":"Preliminary provocations"},{"location":"placeholder/#heavy-hitters","text":"Image credits Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients","title":"Heavy hitters"},{"location":"00-introduction/0-1-intro/","text":"Quantum physics 101 \u00b6 Nature uses only the longest threads to weave her patterns, so each small piece of her fabric reveals the organization of the entire tapestry. Richard Feynman Introduction \u00b6 Let us run a thought experiment: imagine your collection of cups, which is comprised of both tumblers and mugs, with both a mix of glass and ceramic. Being someone that is happier when everything is in its place, you decide that you are going to sort your cups into separate cupboards as determined by their shape, and confident in your ability to pull out a specific without looking mug based on touch alone. It would turn out that you were hosting a morning tea, so were required to pull out many cups, but fortunately you were prepared. However, when you reached into the cupboard of mugs and pulled out only ceramic cups, there was a 50/50 chance that you would pull out a tumbler! Flummoxed, you reach into the cupboard of tumblers, and pull out all of the ceramic cups and one again, you are now pulling out mugs 50% of the time. Convinced that your kitchen just had a bad day, you sort your cups into cupboards based on their material, certain in your ability to pull out cups based solely on their shape. Your next morning tea roles around, and once again, when you go rummaging based on shape, you are only capable of pulling out a mixture of tumblers and mugs! Upon investigating your kitchen cupboards, you spy a tiny engraving which reads quantum cabinetry . What is that about? You enrol in a quantum mechanics course to find out. Futurama meme A somewhat different tone, but both too relevant and too classic to pass up (from S03E14: Time Keeps On Slippin' ). The study of quantum mechanics is a wild ride: it is punctuated by brief periods of understanding and then profound lulls of nothing making sense. It is often stated that quantum mechanics is counter intuitive, or that it cannot be understood, and whilst there one can argue that a deeper level this is true, one can use the scientific method to probe the universe, and formulate theories which accurately predict what will take place (with extraordinary accuracy!). Repeated exposure to commonly encountered systems and physical situations can be used to cultivate an intuition for might be likely to take place. If you come seeking explanations for quantum phenomena through analogy with \"intuitive\" classical systems, you will leave (mostly) empty handed. The best thing one can do to harness the power of quantum mechanics is take one's time: really marinate in the content. Build on the foundations of your existing physics knowledge (e.g. wave mechanics) and embark on a journey to harness the best model we have for the natural world. Image credits Header image taken from IBM quantum systems .","title":"0.1 - Quantum mechanics 101"},{"location":"00-introduction/0-1-intro/#quantum-physics-101","text":"Nature uses only the longest threads to weave her patterns, so each small piece of her fabric reveals the organization of the entire tapestry. Richard Feynman","title":"Quantum physics 101"},{"location":"00-introduction/0-1-intro/#introduction","text":"Let us run a thought experiment: imagine your collection of cups, which is comprised of both tumblers and mugs, with both a mix of glass and ceramic. Being someone that is happier when everything is in its place, you decide that you are going to sort your cups into separate cupboards as determined by their shape, and confident in your ability to pull out a specific without looking mug based on touch alone. It would turn out that you were hosting a morning tea, so were required to pull out many cups, but fortunately you were prepared. However, when you reached into the cupboard of mugs and pulled out only ceramic cups, there was a 50/50 chance that you would pull out a tumbler! Flummoxed, you reach into the cupboard of tumblers, and pull out all of the ceramic cups and one again, you are now pulling out mugs 50% of the time. Convinced that your kitchen just had a bad day, you sort your cups into cupboards based on their material, certain in your ability to pull out cups based solely on their shape. Your next morning tea roles around, and once again, when you go rummaging based on shape, you are only capable of pulling out a mixture of tumblers and mugs! Upon investigating your kitchen cupboards, you spy a tiny engraving which reads quantum cabinetry . What is that about? You enrol in a quantum mechanics course to find out. Futurama meme A somewhat different tone, but both too relevant and too classic to pass up (from S03E14: Time Keeps On Slippin' ). The study of quantum mechanics is a wild ride: it is punctuated by brief periods of understanding and then profound lulls of nothing making sense. It is often stated that quantum mechanics is counter intuitive, or that it cannot be understood, and whilst there one can argue that a deeper level this is true, one can use the scientific method to probe the universe, and formulate theories which accurately predict what will take place (with extraordinary accuracy!). Repeated exposure to commonly encountered systems and physical situations can be used to cultivate an intuition for might be likely to take place. If you come seeking explanations for quantum phenomena through analogy with \"intuitive\" classical systems, you will leave (mostly) empty handed. The best thing one can do to harness the power of quantum mechanics is take one's time: really marinate in the content. Build on the foundations of your existing physics knowledge (e.g. wave mechanics) and embark on a journey to harness the best model we have for the natural world. Image credits Header image taken from IBM quantum systems .","title":"Introduction"},{"location":"01-stern-gerlach/1-1-exp/","text":"The Stern-Gerlach Experiment \u00b6 Time to do the same experiment lots of times and get different results Introduction \u00b6 Our journey begins with what may be the most famous experiment in the context of quantum mechanics, which was undertaken in the early part of the twentieth century. The nascent ideas of quantum mechanics were being explored, and a delightfully simple experiment managed to break our understanding of how the world works. We shall explore the rich physics of this foundational experiment and use it as our foundation for introducing quantum mechanics using Dirac notation and matrix mechanics. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Kinematics of particles in magnetic fields Text reference The material covered here is discussed in section(s) \\(\\S1.1\\) of Quantum Mechanics, A Paradigms Approach (2nd edition) The year was 1921... \u00b6 A touch over 100 years ago, Otto Stern and Walther Gerlach performed the following experiment: Creating a beam of neutral silver atoms Passing the beam through an inhomogeneous magnetic field Measuring the beam profile after the magnetic field A schematic of the experiment is shown below: A schematic of the Stern-Gerlach experiment The experiment is conceptually very simple, and despite the experiment being extremely difficult to execute, they were able to obtain the following result : \"Bohr was right after all\", Walther Gerlach Without context, it is somewhat difficult to appreciate the Earth shattering nature of this image, so that is what we are going to explore. The classical experiment \u00b6 Given there is some interaction between the atoms and the magnetic field, this leads to us assuming that the atom possesses a magnetic moment magnetic moment \\boldsymbol{\\mu}. The energy of the interaction is given by \\[ E = -\\boldsymbol{\\mu} \\cdot \\mathbf{B} \\] where \\(\\mathbf{B}\\) is the magnetic field. Question 1.1.1: What is the force due to this interaction? Write an expression for the force in the \\(z\\) -direction The force is the negative gradient of the energy, which in this case yields \\[ \\mathbf{F} = \\nabla \\left(\\boldsymbol{\\mu} \\cdot \\mathbf{B}\\right) \\] and by the design of the experiment, we know the field is primarily in the \\(z\\) -direction and so \\[ \\begin{align} F_z & = \\frac{\\partial}{\\partial z}\\left(\\boldsymbol{\\mu} \\cdot \\mathbf{B}\\right) \\\\ & \\approx \\mu_z \\frac{\\partial B_z}{\\partial z} \\end{align} \\] Consequently, the force is largely perpendicular to the direction of beam propagation, with the amount of deflection being proportional to the component of the magnetic moment in the direction of the field gradient. The origin of a (classical) magnetic moment is either a separation of poles, or loops of current, and explicitly the magnitude of the magnetic moment \\(\\mu\\) is \\[ \\mu = I \\times A \\] where \\(I\\) is the current in the loop and \\(A\\) is the area of the loop. In the early 1920s, atomic model de jour was the Bohr model 1 , where atoms consist of charges in discrete energy shells, and so we can meaningfully talk about a charge \\(q\\) moving at speed \\(v\\) around the loop of a circle of radius \\(r\\) . Question 1.1.2: Show that the magnitude of the magnetic moment is given by \\(qrv/2\\) This is plug and play from \\(\\mu = I \\times A\\) , requiring only that one the definition of current: \\[ \\begin{align} \\mu & = I \\times A \\\\ & = \\frac{q}{2\\pi r / v} \\times \\pi r^2 \\\\ & = \\frac{qrv}{2} \\end{align} \\] From rotational mechanics, we know the orbital the angular momentum \\(L = mvr\\) , so we rewrite \\[ \\mu = \\frac{q}{2m} L. \\] We also take further inspiration from rotational mechanics in the form of an orbiting body can itself rotate (e.g. the earth spinning whilst rotating around the sun), so we assume our charged particle has Orbital angular momentum \\(\\mathbf{L}\\) Intrinsic angular momentum \\(\\mathbf{S}\\) both of which will contribute to the magnetic interaction. By analogy with the orbital angular momentum, we can propose a relation between the magnetic moment and the intrinsic angular momentum as \\[ \\boldsymbol{\\mu} = g\\frac{q}{2m} \\mathbf{S} \\] where \\(g\\) is the dimensionless \\(g-\\) factor which contains all of the juicy physics. Arriving at a theoretical value for this constant goes beyond the scope of this course 2 , but it turns out the value of \\(g\\) is approximately -2, and the deviation from -2 is hailed as one of the grand successes of the theory of Quantum Electrodynamics: the predicted value of \\[ g_{\\mathrm{theory}} = -2.002319304363286 \\] matches the experimental value of \\[ g_{\\mathrm{exp}} = \u22122.00231930436256(35) \\] very well. Long-shot silver \u00b6 We must take a brief sojourn from physics fundamentals to look at the practicalities of the experiment, such that we can realistically model the system. Question 1.1.3: How many common isotopes of silver are there and how many neutrons are in each isotope? How does the existence of these isotopes alter our analysis? The common isotopes of silver are \\(^{107}\\) Ag and \\(^{109}\\) Ag, having 60 and 62 neutrons respectively. Impressively, these isotopes occur with near-similar abundances at \\(51.8%\\) and \\(48.2%\\) respectively. In all cases, the magnetic moment depends on the inverse of the particle mass, so for both protons and neutrons which have a mass some thousands of times bigger, we can simply ignore 3 thier contribution to the magnetic moment of the atom. Question 1.1.4: What is the electronic configuration of Silver? How many unpaired electrons are in the outer shell? What are the consequneces for our (the Stern-Gerlach) experiment? Write an expression of the magnetic moment of neutral silver. The electronic confiuration for silver is \\[ \\mathrm{Ag} = 1\\mathrm{s}^2 2\\mathrm{s}^2 2\\mathrm{p}^6 3\\mathrm{s}^2 3\\mathrm{p}^6 4\\mathrm{s}^2 3\\mathrm{d}^{10} 4\\mathrm{p}^6 4\\mathrm{d}^{10} 5\\mathrm{s}^1 \\] or equivalently \\[ \\mathrm{Ag} = [\\mathrm{Kr}] 4\\mathrm{d}^{10} 5\\mathrm{s}^1 \\] meaning that there is only a single unpaired electron in the outer shell, and it is also in the ground state, which has an isotropic distribution and thus no orbital angular momentum, meaning only the intrinsic angular momentum of the electron will contribute to the interaction. The magnetic moment for the silver atom is then \\[ \\boldsymbol{\\mu} = -g\\frac{e}{2 m_e} \\mathbf{S} \\] where \\(e\\) is the magnitude of the electron charge and \\(m_e\\) is the electronic mass. Are we baking in the result for the classical analysis by using what amounts to quantum info? Yes, but this needn't be the case; however, it really simplifies the discussion. The Stern-Gerlach experiment was done with neutral silver, so we seek to analyse this result; but we could look at the case of Hydrogen (which was done afterwards) or the plethora of other systems, but multielectron systems do require a bit of modern knowledge to make the classical analysis fit together. An interesting thought is why don't we do the experiment or analysis with electrons themselves ? The force in the the \\(z-\\) direction for a silver atom is thus \\[ \\begin{align} F_z & \\approx \\mu_z \\frac{\\partial B_z}{\\partial z} \\\\ & = - g \\frac{e}{2 m_e} S_z \\frac{\\partial B_z}{\\partial z} \\end{align} \\] and directly, we have the deflection of the beam through the apparatus being a direct measurement of the \\(z\\) component of the spin along the axis of the magnetic field gradient. Question 1.1.5: Make a prediction of the distribution of deflected silver atoms you would expect for a thermal source. A reasonable assumption one can make is that the intrinsic angular momentum for each \\(5\\mathrm{s}\\) electron has the same magnitude, and thus we can write the \\(z-\\) component as \\[ S_z = |\\mathbf{S}|\\cos\\left(\\theta\\right) \\] where \\(\\theta\\) is the angle between the \\(z-\\) axis and the spin vector \\(\\mathbf{S}\\) . For a thermal beam, we would expect all values of \\(\\theta\\) , with the explicit angular flux to be determined by the apparatus; however, the from of this being largely unimportant save for the fact we expect all values of \\(\\theta\\) to be present. We therefore would expect a continuous range of spin projections, ranging from \\(S_z \\in [-|\\mathbf{S}|, |\\mathbf{S}|]\\) The results \u00b6 Reprint: the experimental results of the original Stern-Gerlach experiment We can now return to the results as recorded by Stern and Gerlach. If we look at the image without the magnetic field gradient, we see the silver beam form a line (which is due to the geometry of experiment) and when the gradient is switched on, only two projections along the field gradient are observed, which indicates only two values of the \\(z-\\) component of the electron spin are possible. The magnitude of these deflections are consistent with the values of the spin component of \\[ S_z = \\pm \\frac{\\hbar}{2} \\] where the reduced Planck constant is \\(\\hbar = h/2\\pi\\) and Plank's constant is \\(h=6.62607015 \\times 10^{-34}~\\mathrm{J \\cdot Hz^{-1}}\\) . The Stern-Gerlach experiment is evidence of the quantisation of the electron spin angular momentum along an axis. The quantisation axis In our working here, we have chosen the \\(z-\\) axis to be the direction along which we measure the spin component, but we could have equally picked any other axis and observed the same result. It is a well-observed convention to define the axis of the magnetic field (gradient) to be along \\(z\\) , and we are not going to start rocking the boat. A general Stern-Gerlach experiment \u00b6 We are going to regroup: with your socks (hopefully) having been blown off by the above result, we are going to move into a generalised framework to consider these kinds of experiments - and yes, should you need to take a minute to collect you socks, please do so now. Details in the bin \u00b6 We are going to strip back the Stern-Gerlach experiment to the core features, which consists of the following: A beam of atoms A Stern-Gerlach device which analyses the component of spin along a given axis A schematic of the system is shown below: A schematic of the simplified Stern-Gerlach system We are also going to label the output ports of our analyser: the up and down arrows ( \\(\\uparrow\\) and \\(\\downarrow\\) ) indicate the possible measurement results for the analyser, which correspond to the measurements \\[ S_z = \\pm \\frac{\\hbar}{2} \\] and as there are only two results, we can refer to these as spin up and spin down . The thing that we are measuring, the projection of \\(\\mathbf{S}\\) onto the \\(z-\\) axis ( \\(S_z\\) ) is the observable , i.e. the thing we are measuring. The quantum state \u00b6 When we talk about the beams in our system, be it the input beam or the beams after the analyser, we are describing quantum states. In the first part of this course, you will have encountered quantum mechanical states in the context of wavefunctions, which are solutions to the Schr\u00f6dinger equation. Here we adopt a more general representation of quantum states, which is not limited to the degrees of freedom chosen to represent the wavefunction (e.g. position/momentum space) but rather talk about a state as an object containing all of the information that we can know about the system. Mathematically, we represent states using Dirac notation ; in the case of our spin up and spin down states, we label these \\(|+\\rangle\\) and \\(|-\\rangle\\) , where we have introduced a new symbol to demarcate a quantum state, the ket. We will delve deeper into these objects later , but for the moment it sufficient to know that a general state is mathematically described by the ket \\(|\\psi\\rangle\\) . Uniqueness of ket labels A quantum state is described by a ket, but the label in the ket is not unique. For example, we might label the spin-up state as \\(| + \\rangle\\) \\(| S_z = +\\hbar/2 \\rangle\\) \\(| +\\mathbf{\\hat{z}} \\rangle\\) \\(| \\uparrow \\rangle\\) \\(\\ldots\\) where the label is not important; in all cases, we are talking about the state with a projection of \\(+\\hbar/2\\) through our Stern-Gerlach analyser. Postulate 1 The state of a quantum mechanical system - the entirety of information that you can know about it - is represented mathematically by a normalised ket \\(|\\psi\\rangle\\) We now seek to perform a series of experiments which the systems will behave exactly as expected and no strange behaviour will take place. Experiment simulator An online simulation is available to allow you to play along with the following experiments. Experiment one \u00b6 The following set of experiments are conducted by sending our beam through various analysers. An example of such an experiment from our simple setup above is shown below: The simplified Stern-Gerlach experiment with proportions of atoms detected from the output ports In our first example, we are going to stack two analysers aligned along the \\(z-\\) axis. The beam will be split by the first analyser, and we then take the spin up component of the beam and use this as the input to a second analyser, meaning the spin component is again analysed. Experiment time Experimental setup Experimental results What will the proportion of particles detected at the output ports? This result is perhaps unsurprising, as the first analyser measures an atom to have a \\(z-\\) component of spin \\(S_z = +\\hbar/2\\) , and the 2nd analyser also measures \\(S_z = +\\hbar/2\\) for these atoms. It should be emphasised that in this scenario, the first analyser can be considered to be preparing the quantum state: if we have a mixture of spin up and spin down atoms before the analyser, atoms from a given output port will be either spin up or spin down. Experiment two \u00b6 We are now going to preform the same experiment as experiment one with the exception being that we are going to replace the second analyser with an analyser which is aligned to the \\(x-\\) axis, meaning that we now measure the \\(x\\) component of the spin \\(S_x\\) rather than \\(S_z\\) . Experiment time Experimental setup Experimental results What will the proportion of particles detected at the output ports? At the top port of the first analyser, we still have atoms in the spin up state \\(|+\\rangle\\) as per the previous example, but following the second analyser, we have atoms which have components \\(S_x = +\\hbar/2\\) and \\(S_x = -\\hbar/2\\) , which we denote by \\(|+\\rangle_x\\) and \\(|-\\rangle_x\\) respectively. Points of note from this experiment are Even though we have changed the orientation of the analyser, there are still only two possible values for the projection of the spin Results for this experiment would be unchanged if we had taken the spin down output from the first analyser Critically: for any given atom, we cannot predict the output of the second analyser. We know that there will be a \\(50\\%\\) probability of an atom exiting via a specific port, but nothing more Quantum mechanics is inherently probabilistic: we cannot know the outcome of a given measurement without making said measurement. In the development of quantum mechanics, it was postulated that whilst measurements appeared to be probabilistic, there was actually some other variable which was underwriting the system, which if known would allow us to conclusively predict results. This so-called hidden variable theory of quantum mechanics was shown to be incompatible with observed results 4 , something we shall discuss in detail later in the course. Experiment three \u00b6 We shall now extend experiment two with the addition of a third analyser, again aligned along the \\(z-\\) axis, meaning we are measuring the component of the spin along the \\(z\\) , \\(x\\) , and \\(z\\) axes respectively. Experiment time Experimental setup Experimental results What will the proportion of particles detected at the output ports? If this result does not cause a double take, then marinate in it a bit longer until that happens. We have measured \\(S_z = +\\hbar/2\\) , then we have taken a measurement of \\(S_x\\) , and then immediately taken another measurement of \\(S_z\\) , but the result is now a mixture of \\(S_z = +\\hbar/2\\) and \\(S_z = -\\hbar/2\\) . Somehow, by measuring \\(S_x\\) , we have erased knowledge of \\(S_z\\) . A key feature of quantum mechanics is that making a measurement fundamentally alters the system. These experiments are designed to illustrate that there is a fundamental incompatibility between measurements of different spin components, or formally: that \\(S_x\\) and \\(S_z\\) are incompatible observables. This means that we cannot these values simultaneously. Compatible versus incompatible observables In this case we see that \\(S_z\\) is incompatible with \\(S_x\\) (and also \\(S_y\\) ), but this does not mean that all pairs of observables are incompatible. It is an important aspect of quantum mechanics that we can make certain measurements without altering other aspects of the system. We shall discuss this in detail later, but for now it is sufficient to say that there are both sets of compatible observables and incompatible observables. Experiment four \u00b6 For our final experiment, we are going to repeat experiment three but we are going to alter the beam as it comes out of analyser number 2: namely change what goes into analyser number three. Experiment time Experimental setup Spin up only Spin down only Combined spin up and spin down What will the proportion of particles detected at the output ports? This is exactly the same as experiment three . This is in effect, exactly the same as experiment three . This result is perhaps the strangest of all: by recombining the outputs from the second analyser, we have somehow made the atoms recall their state from the output of analyser number one! Classical probability theory cannot explain this aspect of quantum mechanics. Whilst these results may appear extremely foreign, you already have an intuition for what is going on: consider the canonical double-slit experiment. When light waves pass through slits, each slit produces a nearly uniform illumination of the screen, but when the two slits are allowed to combine, an interference pattern in observed. In order to describe this phenomenon, we consider the complex-valued electric fields from both sources, and ultimately calculate the intensity as the square of the field amplitude, and the nature of complex-valued fields permits interference effects. In this sense, quantum mechanical is no different to any other form of wave mechanics, but we must work to describe and calculate the amplitudes of the quantum mechanical waves. Conclusions \u00b6 The Stern-Gerlach experiment demonstrates some foundational concepts of quantum mechanics: Quantum mechanics is probabilistic Spin measurements are quantised Quantum measurements disturb the system Exercises \u00b6 Preliminary provocations \u00b6 Why use an inhomogeneous magnetic field? Why is the experiment done with silver atoms? Heavy hitters \u00b6 1. 2. Image credits Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better. \u21a9 A study of the the relativistic wave equation, known as the Dirac equation , is required to fully flesh out this result. \u21a9 In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting) \u21a9 The 2022 Nobel Prize in physics was awarded for the pioneering work of making these measurements \u21a9","title":"1.1 - The experiment"},{"location":"01-stern-gerlach/1-1-exp/#the-stern-gerlach-experiment","text":"Time to do the same experiment lots of times and get different results","title":"The Stern-Gerlach Experiment"},{"location":"01-stern-gerlach/1-1-exp/#introduction","text":"Our journey begins with what may be the most famous experiment in the context of quantum mechanics, which was undertaken in the early part of the twentieth century. The nascent ideas of quantum mechanics were being explored, and a delightfully simple experiment managed to break our understanding of how the world works. We shall explore the rich physics of this foundational experiment and use it as our foundation for introducing quantum mechanics using Dirac notation and matrix mechanics. Expected competencies It is assumed that you have familiarity with the following concepts/techniques: Kinematics of particles in magnetic fields Text reference The material covered here is discussed in section(s) \\(\\S1.1\\) of Quantum Mechanics, A Paradigms Approach (2nd edition)","title":"Introduction"},{"location":"01-stern-gerlach/1-1-exp/#the-year-was-1921","text":"A touch over 100 years ago, Otto Stern and Walther Gerlach performed the following experiment: Creating a beam of neutral silver atoms Passing the beam through an inhomogeneous magnetic field Measuring the beam profile after the magnetic field A schematic of the experiment is shown below: A schematic of the Stern-Gerlach experiment The experiment is conceptually very simple, and despite the experiment being extremely difficult to execute, they were able to obtain the following result : \"Bohr was right after all\", Walther Gerlach Without context, it is somewhat difficult to appreciate the Earth shattering nature of this image, so that is what we are going to explore.","title":"The year was 1921..."},{"location":"01-stern-gerlach/1-1-exp/#the-classical-experiment","text":"Given there is some interaction between the atoms and the magnetic field, this leads to us assuming that the atom possesses a magnetic moment magnetic moment \\boldsymbol{\\mu}. The energy of the interaction is given by \\[ E = -\\boldsymbol{\\mu} \\cdot \\mathbf{B} \\] where \\(\\mathbf{B}\\) is the magnetic field. Question 1.1.1: What is the force due to this interaction? Write an expression for the force in the \\(z\\) -direction The force is the negative gradient of the energy, which in this case yields \\[ \\mathbf{F} = \\nabla \\left(\\boldsymbol{\\mu} \\cdot \\mathbf{B}\\right) \\] and by the design of the experiment, we know the field is primarily in the \\(z\\) -direction and so \\[ \\begin{align} F_z & = \\frac{\\partial}{\\partial z}\\left(\\boldsymbol{\\mu} \\cdot \\mathbf{B}\\right) \\\\ & \\approx \\mu_z \\frac{\\partial B_z}{\\partial z} \\end{align} \\] Consequently, the force is largely perpendicular to the direction of beam propagation, with the amount of deflection being proportional to the component of the magnetic moment in the direction of the field gradient. The origin of a (classical) magnetic moment is either a separation of poles, or loops of current, and explicitly the magnitude of the magnetic moment \\(\\mu\\) is \\[ \\mu = I \\times A \\] where \\(I\\) is the current in the loop and \\(A\\) is the area of the loop. In the early 1920s, atomic model de jour was the Bohr model 1 , where atoms consist of charges in discrete energy shells, and so we can meaningfully talk about a charge \\(q\\) moving at speed \\(v\\) around the loop of a circle of radius \\(r\\) . Question 1.1.2: Show that the magnitude of the magnetic moment is given by \\(qrv/2\\) This is plug and play from \\(\\mu = I \\times A\\) , requiring only that one the definition of current: \\[ \\begin{align} \\mu & = I \\times A \\\\ & = \\frac{q}{2\\pi r / v} \\times \\pi r^2 \\\\ & = \\frac{qrv}{2} \\end{align} \\] From rotational mechanics, we know the orbital the angular momentum \\(L = mvr\\) , so we rewrite \\[ \\mu = \\frac{q}{2m} L. \\] We also take further inspiration from rotational mechanics in the form of an orbiting body can itself rotate (e.g. the earth spinning whilst rotating around the sun), so we assume our charged particle has Orbital angular momentum \\(\\mathbf{L}\\) Intrinsic angular momentum \\(\\mathbf{S}\\) both of which will contribute to the magnetic interaction. By analogy with the orbital angular momentum, we can propose a relation between the magnetic moment and the intrinsic angular momentum as \\[ \\boldsymbol{\\mu} = g\\frac{q}{2m} \\mathbf{S} \\] where \\(g\\) is the dimensionless \\(g-\\) factor which contains all of the juicy physics. Arriving at a theoretical value for this constant goes beyond the scope of this course 2 , but it turns out the value of \\(g\\) is approximately -2, and the deviation from -2 is hailed as one of the grand successes of the theory of Quantum Electrodynamics: the predicted value of \\[ g_{\\mathrm{theory}} = -2.002319304363286 \\] matches the experimental value of \\[ g_{\\mathrm{exp}} = \u22122.00231930436256(35) \\] very well.","title":"The classical experiment"},{"location":"01-stern-gerlach/1-1-exp/#long-shot-silver","text":"We must take a brief sojourn from physics fundamentals to look at the practicalities of the experiment, such that we can realistically model the system. Question 1.1.3: How many common isotopes of silver are there and how many neutrons are in each isotope? How does the existence of these isotopes alter our analysis? The common isotopes of silver are \\(^{107}\\) Ag and \\(^{109}\\) Ag, having 60 and 62 neutrons respectively. Impressively, these isotopes occur with near-similar abundances at \\(51.8%\\) and \\(48.2%\\) respectively. In all cases, the magnetic moment depends on the inverse of the particle mass, so for both protons and neutrons which have a mass some thousands of times bigger, we can simply ignore 3 thier contribution to the magnetic moment of the atom. Question 1.1.4: What is the electronic configuration of Silver? How many unpaired electrons are in the outer shell? What are the consequneces for our (the Stern-Gerlach) experiment? Write an expression of the magnetic moment of neutral silver. The electronic confiuration for silver is \\[ \\mathrm{Ag} = 1\\mathrm{s}^2 2\\mathrm{s}^2 2\\mathrm{p}^6 3\\mathrm{s}^2 3\\mathrm{p}^6 4\\mathrm{s}^2 3\\mathrm{d}^{10} 4\\mathrm{p}^6 4\\mathrm{d}^{10} 5\\mathrm{s}^1 \\] or equivalently \\[ \\mathrm{Ag} = [\\mathrm{Kr}] 4\\mathrm{d}^{10} 5\\mathrm{s}^1 \\] meaning that there is only a single unpaired electron in the outer shell, and it is also in the ground state, which has an isotropic distribution and thus no orbital angular momentum, meaning only the intrinsic angular momentum of the electron will contribute to the interaction. The magnetic moment for the silver atom is then \\[ \\boldsymbol{\\mu} = -g\\frac{e}{2 m_e} \\mathbf{S} \\] where \\(e\\) is the magnitude of the electron charge and \\(m_e\\) is the electronic mass. Are we baking in the result for the classical analysis by using what amounts to quantum info? Yes, but this needn't be the case; however, it really simplifies the discussion. The Stern-Gerlach experiment was done with neutral silver, so we seek to analyse this result; but we could look at the case of Hydrogen (which was done afterwards) or the plethora of other systems, but multielectron systems do require a bit of modern knowledge to make the classical analysis fit together. An interesting thought is why don't we do the experiment or analysis with electrons themselves ? The force in the the \\(z-\\) direction for a silver atom is thus \\[ \\begin{align} F_z & \\approx \\mu_z \\frac{\\partial B_z}{\\partial z} \\\\ & = - g \\frac{e}{2 m_e} S_z \\frac{\\partial B_z}{\\partial z} \\end{align} \\] and directly, we have the deflection of the beam through the apparatus being a direct measurement of the \\(z\\) component of the spin along the axis of the magnetic field gradient. Question 1.1.5: Make a prediction of the distribution of deflected silver atoms you would expect for a thermal source. A reasonable assumption one can make is that the intrinsic angular momentum for each \\(5\\mathrm{s}\\) electron has the same magnitude, and thus we can write the \\(z-\\) component as \\[ S_z = |\\mathbf{S}|\\cos\\left(\\theta\\right) \\] where \\(\\theta\\) is the angle between the \\(z-\\) axis and the spin vector \\(\\mathbf{S}\\) . For a thermal beam, we would expect all values of \\(\\theta\\) , with the explicit angular flux to be determined by the apparatus; however, the from of this being largely unimportant save for the fact we expect all values of \\(\\theta\\) to be present. We therefore would expect a continuous range of spin projections, ranging from \\(S_z \\in [-|\\mathbf{S}|, |\\mathbf{S}|]\\)","title":"Long-shot silver"},{"location":"01-stern-gerlach/1-1-exp/#the-results","text":"Reprint: the experimental results of the original Stern-Gerlach experiment We can now return to the results as recorded by Stern and Gerlach. If we look at the image without the magnetic field gradient, we see the silver beam form a line (which is due to the geometry of experiment) and when the gradient is switched on, only two projections along the field gradient are observed, which indicates only two values of the \\(z-\\) component of the electron spin are possible. The magnitude of these deflections are consistent with the values of the spin component of \\[ S_z = \\pm \\frac{\\hbar}{2} \\] where the reduced Planck constant is \\(\\hbar = h/2\\pi\\) and Plank's constant is \\(h=6.62607015 \\times 10^{-34}~\\mathrm{J \\cdot Hz^{-1}}\\) . The Stern-Gerlach experiment is evidence of the quantisation of the electron spin angular momentum along an axis. The quantisation axis In our working here, we have chosen the \\(z-\\) axis to be the direction along which we measure the spin component, but we could have equally picked any other axis and observed the same result. It is a well-observed convention to define the axis of the magnetic field (gradient) to be along \\(z\\) , and we are not going to start rocking the boat.","title":"The results"},{"location":"01-stern-gerlach/1-1-exp/#a-general-stern-gerlach-experiment","text":"We are going to regroup: with your socks (hopefully) having been blown off by the above result, we are going to move into a generalised framework to consider these kinds of experiments - and yes, should you need to take a minute to collect you socks, please do so now.","title":"A general Stern-Gerlach experiment"},{"location":"01-stern-gerlach/1-1-exp/#details-in-the-bin","text":"We are going to strip back the Stern-Gerlach experiment to the core features, which consists of the following: A beam of atoms A Stern-Gerlach device which analyses the component of spin along a given axis A schematic of the system is shown below: A schematic of the simplified Stern-Gerlach system We are also going to label the output ports of our analyser: the up and down arrows ( \\(\\uparrow\\) and \\(\\downarrow\\) ) indicate the possible measurement results for the analyser, which correspond to the measurements \\[ S_z = \\pm \\frac{\\hbar}{2} \\] and as there are only two results, we can refer to these as spin up and spin down . The thing that we are measuring, the projection of \\(\\mathbf{S}\\) onto the \\(z-\\) axis ( \\(S_z\\) ) is the observable , i.e. the thing we are measuring.","title":"Details in the bin"},{"location":"01-stern-gerlach/1-1-exp/#the-quantum-state","text":"When we talk about the beams in our system, be it the input beam or the beams after the analyser, we are describing quantum states. In the first part of this course, you will have encountered quantum mechanical states in the context of wavefunctions, which are solutions to the Schr\u00f6dinger equation. Here we adopt a more general representation of quantum states, which is not limited to the degrees of freedom chosen to represent the wavefunction (e.g. position/momentum space) but rather talk about a state as an object containing all of the information that we can know about the system. Mathematically, we represent states using Dirac notation ; in the case of our spin up and spin down states, we label these \\(|+\\rangle\\) and \\(|-\\rangle\\) , where we have introduced a new symbol to demarcate a quantum state, the ket. We will delve deeper into these objects later , but for the moment it sufficient to know that a general state is mathematically described by the ket \\(|\\psi\\rangle\\) . Uniqueness of ket labels A quantum state is described by a ket, but the label in the ket is not unique. For example, we might label the spin-up state as \\(| + \\rangle\\) \\(| S_z = +\\hbar/2 \\rangle\\) \\(| +\\mathbf{\\hat{z}} \\rangle\\) \\(| \\uparrow \\rangle\\) \\(\\ldots\\) where the label is not important; in all cases, we are talking about the state with a projection of \\(+\\hbar/2\\) through our Stern-Gerlach analyser. Postulate 1 The state of a quantum mechanical system - the entirety of information that you can know about it - is represented mathematically by a normalised ket \\(|\\psi\\rangle\\) We now seek to perform a series of experiments which the systems will behave exactly as expected and no strange behaviour will take place. Experiment simulator An online simulation is available to allow you to play along with the following experiments.","title":"The quantum state"},{"location":"01-stern-gerlach/1-1-exp/#experiment-one","text":"The following set of experiments are conducted by sending our beam through various analysers. An example of such an experiment from our simple setup above is shown below: The simplified Stern-Gerlach experiment with proportions of atoms detected from the output ports In our first example, we are going to stack two analysers aligned along the \\(z-\\) axis. The beam will be split by the first analyser, and we then take the spin up component of the beam and use this as the input to a second analyser, meaning the spin component is again analysed. Experiment time Experimental setup Experimental results What will the proportion of particles detected at the output ports? This result is perhaps unsurprising, as the first analyser measures an atom to have a \\(z-\\) component of spin \\(S_z = +\\hbar/2\\) , and the 2nd analyser also measures \\(S_z = +\\hbar/2\\) for these atoms. It should be emphasised that in this scenario, the first analyser can be considered to be preparing the quantum state: if we have a mixture of spin up and spin down atoms before the analyser, atoms from a given output port will be either spin up or spin down.","title":"Experiment one"},{"location":"01-stern-gerlach/1-1-exp/#experiment-two","text":"We are now going to preform the same experiment as experiment one with the exception being that we are going to replace the second analyser with an analyser which is aligned to the \\(x-\\) axis, meaning that we now measure the \\(x\\) component of the spin \\(S_x\\) rather than \\(S_z\\) . Experiment time Experimental setup Experimental results What will the proportion of particles detected at the output ports? At the top port of the first analyser, we still have atoms in the spin up state \\(|+\\rangle\\) as per the previous example, but following the second analyser, we have atoms which have components \\(S_x = +\\hbar/2\\) and \\(S_x = -\\hbar/2\\) , which we denote by \\(|+\\rangle_x\\) and \\(|-\\rangle_x\\) respectively. Points of note from this experiment are Even though we have changed the orientation of the analyser, there are still only two possible values for the projection of the spin Results for this experiment would be unchanged if we had taken the spin down output from the first analyser Critically: for any given atom, we cannot predict the output of the second analyser. We know that there will be a \\(50\\%\\) probability of an atom exiting via a specific port, but nothing more Quantum mechanics is inherently probabilistic: we cannot know the outcome of a given measurement without making said measurement. In the development of quantum mechanics, it was postulated that whilst measurements appeared to be probabilistic, there was actually some other variable which was underwriting the system, which if known would allow us to conclusively predict results. This so-called hidden variable theory of quantum mechanics was shown to be incompatible with observed results 4 , something we shall discuss in detail later in the course.","title":"Experiment two"},{"location":"01-stern-gerlach/1-1-exp/#experiment-three","text":"We shall now extend experiment two with the addition of a third analyser, again aligned along the \\(z-\\) axis, meaning we are measuring the component of the spin along the \\(z\\) , \\(x\\) , and \\(z\\) axes respectively. Experiment time Experimental setup Experimental results What will the proportion of particles detected at the output ports? If this result does not cause a double take, then marinate in it a bit longer until that happens. We have measured \\(S_z = +\\hbar/2\\) , then we have taken a measurement of \\(S_x\\) , and then immediately taken another measurement of \\(S_z\\) , but the result is now a mixture of \\(S_z = +\\hbar/2\\) and \\(S_z = -\\hbar/2\\) . Somehow, by measuring \\(S_x\\) , we have erased knowledge of \\(S_z\\) . A key feature of quantum mechanics is that making a measurement fundamentally alters the system. These experiments are designed to illustrate that there is a fundamental incompatibility between measurements of different spin components, or formally: that \\(S_x\\) and \\(S_z\\) are incompatible observables. This means that we cannot these values simultaneously. Compatible versus incompatible observables In this case we see that \\(S_z\\) is incompatible with \\(S_x\\) (and also \\(S_y\\) ), but this does not mean that all pairs of observables are incompatible. It is an important aspect of quantum mechanics that we can make certain measurements without altering other aspects of the system. We shall discuss this in detail later, but for now it is sufficient to say that there are both sets of compatible observables and incompatible observables.","title":"Experiment three"},{"location":"01-stern-gerlach/1-1-exp/#experiment-four","text":"For our final experiment, we are going to repeat experiment three but we are going to alter the beam as it comes out of analyser number 2: namely change what goes into analyser number three. Experiment time Experimental setup Spin up only Spin down only Combined spin up and spin down What will the proportion of particles detected at the output ports? This is exactly the same as experiment three . This is in effect, exactly the same as experiment three . This result is perhaps the strangest of all: by recombining the outputs from the second analyser, we have somehow made the atoms recall their state from the output of analyser number one! Classical probability theory cannot explain this aspect of quantum mechanics. Whilst these results may appear extremely foreign, you already have an intuition for what is going on: consider the canonical double-slit experiment. When light waves pass through slits, each slit produces a nearly uniform illumination of the screen, but when the two slits are allowed to combine, an interference pattern in observed. In order to describe this phenomenon, we consider the complex-valued electric fields from both sources, and ultimately calculate the intensity as the square of the field amplitude, and the nature of complex-valued fields permits interference effects. In this sense, quantum mechanical is no different to any other form of wave mechanics, but we must work to describe and calculate the amplitudes of the quantum mechanical waves.","title":"Experiment four"},{"location":"01-stern-gerlach/1-1-exp/#conclusions","text":"The Stern-Gerlach experiment demonstrates some foundational concepts of quantum mechanics: Quantum mechanics is probabilistic Spin measurements are quantised Quantum measurements disturb the system","title":"Conclusions"},{"location":"01-stern-gerlach/1-1-exp/#exercises","text":"","title":"Exercises"},{"location":"01-stern-gerlach/1-1-exp/#preliminary-provocations","text":"Why use an inhomogeneous magnetic field? Why is the experiment done with silver atoms?","title":"Preliminary provocations"},{"location":"01-stern-gerlach/1-1-exp/#heavy-hitters","text":"1. 2. Image credits Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better. \u21a9 A study of the the relativistic wave equation, known as the Dirac equation , is required to fully flesh out this result. \u21a9 In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting) \u21a9 The 2022 Nobel Prize in physics was awarded for the pioneering work of making these measurements \u21a9","title":"Heavy hitters"},{"location":"01-stern-gerlach/1-2-statevectors/","text":"State vectors \u00b6 Time to do the same experiment lots of times and get different results Introduction \u00b6 Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Conclusions \u00b6 Exercises \u00b6 Preliminary provocations \u00b6 Why use an inhomogeneous magnetic field? Why is the experiment done with silver atoms? Heavy hitters \u00b6 Image credits Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better. \u21a9 A study of the the relativistic wave equation, known as the Dirac equation , is required to fully flesh out this result. \u21a9 In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting) \u21a9","title":"1.2 - State vectors"},{"location":"01-stern-gerlach/1-2-statevectors/#state-vectors","text":"Time to do the same experiment lots of times and get different results","title":"State vectors"},{"location":"01-stern-gerlach/1-2-statevectors/#introduction","text":"Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis.","title":"Introduction"},{"location":"01-stern-gerlach/1-2-statevectors/#conclusions","text":"","title":"Conclusions"},{"location":"01-stern-gerlach/1-2-statevectors/#exercises","text":"","title":"Exercises"},{"location":"01-stern-gerlach/1-2-statevectors/#preliminary-provocations","text":"Why use an inhomogeneous magnetic field? Why is the experiment done with silver atoms?","title":"Preliminary provocations"},{"location":"01-stern-gerlach/1-2-statevectors/#heavy-hitters","text":"Image credits Header image taken from the PhD thesis Spinor Bose-Einstein condensates in magnetic field gradients more accurately, at this time it was the Bohr-Sommerfeld model, which is an extension of the Bohr model to include elliptical orbits which fixed some problems. One will also see in solid-state physics that Sommerfeld has a real talent for tweaking existing theories to make them run a bit better. \u21a9 A study of the the relativistic wave equation, known as the Dirac equation , is required to fully flesh out this result. \u21a9 In this case we can, but more generally, the magnetic moment of the nucleus cannot be ignored (see LINK ME! hyperfine splitting) \u21a9","title":"Heavy hitters"},{"location":"solutions/3-3-solutions/","text":"Solutions to exercises \u00b6 Solutions for The specific heat of solids I exercises \u00b6 Solutions for lecture 7 exercises \u00b6 Warm up exercises \u00b6 Check by yourself 2. [m^*] = \\frac{[p^2]}{[E]} = kg 3. m^* = m_e, where \\(m_e\\) is the free electron mass. This is expected because the free elctrons are not subject to a potential If the dispersion relation is parabolic, so in the free electron model. Exercise 1: Next-nearest neighbours chain \u00b6 1. The Schr\u00f6dinger equation is given by: \\(|\\Psi\\rangle = \\sum_n \\phi_n |n\\rangle\\) such that we find E\\phi_n = E_0\\phi_n - t\\phi_{n-1} - t\\phi_{n+1} - t'\\phi_{n-2} - t'\\phi_{n+2} 2. Solving the Schr\u00f6dinger equation yields dispersion: \\( \\(E(k) = E_0 -2t\\cos(ka) -2t'\\cos(2ka)\\) \\) 3. \\[m^* = \\frac{\\hbar^2}{2a^2}\\frac{1}{t\\cos(ka)+4t'\\cos(2ka)}\\] Plot for t=t': k1 = np . linspace ( - pi , - pi / 2 - 0.01 , 300 ); k2 = np . linspace ( - pi / 2 + 0.01 , pi / 2 - 0.01 , 300 ); k3 = np . linspace ( pi / 2 + 0.01 , pi , 300 ); pyplot . plot ( k1 , 1 / ( 5 * np . cos ( k1 )), 'b' ); pyplot . plot ( k2 , 1 / ( 5 * np . cos ( k2 )), 'b' ); pyplot . plot ( k3 , 1 / ( 5 * np . cos ( k3 )), 'b' ); pyplot . xlabel ( r '$k$' ); pyplot . ylabel ( '$m_ {eff} (k)$' ); pyplot . xticks ([ - pi , 0 , pi ],[ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); pyplot . yticks ([],[]); pyplot . tight_layout (); 4. Plots for 2t'=t, 4t'=t and 10t'=t: def m ( k , t ): return 1 / ( np . cos ( k ) + 4 * t * np . cos ( 2 * k )) k1 = np . linspace ( - 1.6 , - 0.83 , 300 ); k2 = np . linspace ( - 0.826 , 0.826 , 300 ); k3 = np . linspace ( 0.83 , 1.6 , 300 ); pyplot . plot ( k1 , m ( k1 , 2 ), 'b' ); pyplot . plot ( k2 , m ( k2 , 2 ), 'b' ); pyplot . plot ( k3 , m ( k3 , 2 ), 'b' , label = 't=2t \\' ' ); pyplot . xlabel ( '$k$' ); pyplot . ylabel ( '$m_ {eff} (k)$' ); pyplot . xticks ([ - 1.6 , 0 , 1.6 ],[ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); pyplot . yticks ([ 0 ],[]); pyplot . tight_layout (); k1 = np . linspace ( - 1.58 , - 0.81 , 300 ); k2 = np . linspace ( - 0.804 , 0.804 , 300 ); k3 = np . linspace ( 0.81 , 1.58 , 300 ); pyplot . plot ( k1 , m ( k1 , 4 ), 'r' ); pyplot . plot ( k2 , m ( k2 , 4 ), 'r' ); pyplot . plot ( k3 , m ( k3 , 4 ), 'r' , label = 't=4t \\' ' ); k1 = np . linspace ( - 1.575 , - 0.798 , 300 ); k2 = np . linspace ( - 0.790 , 0.790 , 300 ); k3 = np . linspace ( 0.798 , 1.575 , 300 ); pyplot . plot ( k1 , m ( k1 , 10 ), 'k' ); pyplot . plot ( k2 , m ( k2 , 10 ), 'k' ); pyplot . plot ( k3 , m ( k3 , 10 ), 'k' , label = 't=10t \\' ' ); pyplot . legend ();","title":"Solutions to exercises"},{"location":"solutions/3-3-solutions/#solutions-to-exercises","text":"","title":"Solutions to exercises"},{"location":"solutions/3-3-solutions/#solutions-for-the-specific-heat-of-solids-i-exercises","text":"","title":"Solutions for The specific heat of solids I exercises"},{"location":"solutions/3-3-solutions/#solutions-for-lecture-7-exercises","text":"","title":"Solutions for lecture 7 exercises"},{"location":"solutions/3-3-solutions/#warm-up-exercises","text":"Check by yourself 2. [m^*] = \\frac{[p^2]}{[E]} = kg 3. m^* = m_e, where \\(m_e\\) is the free electron mass. This is expected because the free elctrons are not subject to a potential If the dispersion relation is parabolic, so in the free electron model.","title":"Warm up exercises"},{"location":"solutions/3-3-solutions/#exercise-1-next-nearest-neighbours-chain","text":"1. The Schr\u00f6dinger equation is given by: \\(|\\Psi\\rangle = \\sum_n \\phi_n |n\\rangle\\) such that we find E\\phi_n = E_0\\phi_n - t\\phi_{n-1} - t\\phi_{n+1} - t'\\phi_{n-2} - t'\\phi_{n+2} 2. Solving the Schr\u00f6dinger equation yields dispersion: \\( \\(E(k) = E_0 -2t\\cos(ka) -2t'\\cos(2ka)\\) \\) 3. \\[m^* = \\frac{\\hbar^2}{2a^2}\\frac{1}{t\\cos(ka)+4t'\\cos(2ka)}\\] Plot for t=t': k1 = np . linspace ( - pi , - pi / 2 - 0.01 , 300 ); k2 = np . linspace ( - pi / 2 + 0.01 , pi / 2 - 0.01 , 300 ); k3 = np . linspace ( pi / 2 + 0.01 , pi , 300 ); pyplot . plot ( k1 , 1 / ( 5 * np . cos ( k1 )), 'b' ); pyplot . plot ( k2 , 1 / ( 5 * np . cos ( k2 )), 'b' ); pyplot . plot ( k3 , 1 / ( 5 * np . cos ( k3 )), 'b' ); pyplot . xlabel ( r '$k$' ); pyplot . ylabel ( '$m_ {eff} (k)$' ); pyplot . xticks ([ - pi , 0 , pi ],[ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); pyplot . yticks ([],[]); pyplot . tight_layout (); 4. Plots for 2t'=t, 4t'=t and 10t'=t: def m ( k , t ): return 1 / ( np . cos ( k ) + 4 * t * np . cos ( 2 * k )) k1 = np . linspace ( - 1.6 , - 0.83 , 300 ); k2 = np . linspace ( - 0.826 , 0.826 , 300 ); k3 = np . linspace ( 0.83 , 1.6 , 300 ); pyplot . plot ( k1 , m ( k1 , 2 ), 'b' ); pyplot . plot ( k2 , m ( k2 , 2 ), 'b' ); pyplot . plot ( k3 , m ( k3 , 2 ), 'b' , label = 't=2t \\' ' ); pyplot . xlabel ( '$k$' ); pyplot . ylabel ( '$m_ {eff} (k)$' ); pyplot . xticks ([ - 1.6 , 0 , 1.6 ],[ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); pyplot . yticks ([ 0 ],[]); pyplot . tight_layout (); k1 = np . linspace ( - 1.58 , - 0.81 , 300 ); k2 = np . linspace ( - 0.804 , 0.804 , 300 ); k3 = np . linspace ( 0.81 , 1.58 , 300 ); pyplot . plot ( k1 , m ( k1 , 4 ), 'r' ); pyplot . plot ( k2 , m ( k2 , 4 ), 'r' ); pyplot . plot ( k3 , m ( k3 , 4 ), 'r' , label = 't=4t \\' ' ); k1 = np . linspace ( - 1.575 , - 0.798 , 300 ); k2 = np . linspace ( - 0.790 , 0.790 , 300 ); k3 = np . linspace ( 0.798 , 1.575 , 300 ); pyplot . plot ( k1 , m ( k1 , 10 ), 'k' ); pyplot . plot ( k2 , m ( k2 , 10 ), 'k' ); pyplot . plot ( k3 , m ( k3 , 10 ), 'k' , label = 't=10t \\' ' ); pyplot . legend ();","title":"Exercise 1: Next-nearest neighbours chain"},{"location":"solutions/assignment1/","text":"Assignment 1: Debye, Drude, Sommerfeld, and chemistry \u00b6 The first assignment can be found here Exercise 1 - Debye \u00b6 What are the assumptions of the Debye model? The Debye model considers only sound waves in a material (i.e. one assumes a linear dispersion \\(\\omega = v k\\) ) which oscillate up to a maximum frequency \\(\\omega_{\\mathrm{cutoff}} = \\omega_d\\) , the Debye frequency, which exists to ensure that the total number of vibrational modes in the system is correct (equal to the number of degrees of freedom in the system). Write an expression for the number of modes in a two-dimensional system, and thus determine the Debye wavenumber (the wavenumber which corresponds to the Debye frequency). In two dimensions, there should be \\(2N\\) modes (we implicitly assume that the different sound polarisations propagate with the same velocity, and thus \\[ 2N = 2 \\frac{A}{2\\pi^2} \\int_0^{|k| = k_d} \\mathrm{d}^2 k \\] where \\(A\\) is the area of our periodic system ( \\(L \\times L\\) ). The integral is simply the area of a circle with a radius \\(k_d\\) , so it evaluates to \\[ 2N = \\frac{2A}{(2\\pi)^2}(\\pi k_d^2) \\] and ultimately obtains \\[ k_d = \\sqrt{4\\pi n} \\] with \\(n = N/A\\) (the two-dimensional density). Provide a brief discussion of which elements you would expect to have a high Debye temperature, and which elements you would expect to have a low Debye temperature. The Debye temperature \\(T_d\\) is defined through \\[ E_d = \\hbar \\omega_{d} = k_{\\mathrm{B}} T_d \\] and as was shown in class , the Debye frequency is \\[ \\omega_d^3 = 6\\pi^2 n v_s^3 \\] where \\(v_s\\) is the speed of sound in the material. Therefore, one would expect the materials with large \\(v_s\\) to have the highest \\(T_d\\) . Consequently, a good guess for the highest \\(T_d\\) would be diamond (and indeed, it is the highest). For low \\(T_d\\) , low speed of sound materials will be compressible - a small spring constant in the Einstein/Debye models - so the nobel gasses or soft metals (e.g. group I) would be good candidates. Exercise 2 - Drude: mixed ion-electron conductors (MIECs) \u00b6 Calculate the electrical resistivity \\(\\rho\\) Assuming that both species respond to the electric field independently - we assume that there are no interactions - the total conductivity is the sum of the two independent conductivities \\[ \\sigma = \\sigma_e + \\sigma_i = e^2 \\left(\\frac{n_e \\tau_e}{m_e} + \\frac{n_i \\tau_i}{m_i}\\right) \\] and therefore the resistivity \\(\\rho = 1/\\sigma\\) \\[ \\rho \\frac{1}{e^2 \\left(\\frac{n_e \\tau_e}{m_e} + \\frac{n_i \\tau_i}{m_i}\\right)} \\] Calculate the thermal conductivity \\(\\kappa\\) The thermal conductivity is calculated in the same way as the resistivity, in that we add the two pieces: \\[ \\kappa = \\kappa_e + \\kappa_i = \\frac{4k_{\\textrm{B}}^2 T}{\\pi} \\left( \\frac{n_e \\tau_e}{m_e} + \\frac{n_i \\tau_i}{m_i} \\right) \\] What is the Wiedemann-Franz law? Does it hold in this situation? The Wiedemann-Franz law states that the ratio (also known as the Lorenz number) \\[ L = \\frac{\\kappa}{T\\sigma} = \\frac{3}{2} \\left(\\frac{k_{\\textrm{B}}}{e}\\right) \\] is roughly constant for metals, and it indeed holds for MIECs If we consider a magnetic field applied in the \\(+z\\) direction, we need only consider the conductivity in \\(x\\) and \\(y\\) and can write \\[ \\rho = \\begin{pmatrix} \\frac{m}{nq^2\\tau} & \\frac{Bq}{n} \\\\ -\\frac{Bq}{n} & \\frac{m}{nq^2\\tau} \\end{pmatrix} \\] which is true for both charge carrier species. Use this result to calculate the resistivity matrix in the case of a MIEC. To make life simpler, one can write \\[ \\rho = \\begin{pmatrix} r & B R \\\\ -B R & r \\end{pmatrix} \\] where \\(r = m/(n q^2 \\tau)\\) and \\(R=q/n\\) . We can then define \\(\\rho_e\\) and \\(\\rho_i\\) for the two species. The conductivities are then \\(\\sigma_j=\\rho_j^{-1}\\) for \\(j = e, i\\) , and then the total conductivity \\(\\sigma_t = \\sigma_e + \\sigma_i\\) . The total resistivity is then \\(\\rho = \\sigma_t^{-1}\\) \\mrk{1}. The process is pretty algebra heavy, but the results are \\[\\begin{align} \\rho_{xx} & = \\frac{B^2 (r_e R_i^2 + r_i R_e^2) + r_i r_e (r_e + r_i)}{B^2 (R_e + R_i)^2 + (r_e + r_i)^2} \\\\ \\rho_{xy} & = \\frac{B (B^2 R_e R_i (R_e + R_i) + R_i r_e^2 + R_e r_i^2 }{B^2 (R_e + R_i)^2 + (r_e + r_i)^2} \\end{align}\\] Note that using software to do this kind of grunt work is absolutely fine (encouraged even) Exercise 3 - Sommerfeld \u00b6 In your own words, explain what is the Fermi energy, Fermi temperature and the Fermi surface The Fermi energy is the chemical potential at \\(T=0\\) , the Fermi temperature is the associated temperature \\(T_F = E_F/k_{\\textrm{B}}\\) , and is the temperature at which thermal energy would dictate the properties of a material to the same degree as the fact they are fermions. The Fermi surface is the surface in momentum space which separates the filled and unfilled states at zero temperature_ . Write an expression for the number of states for a gas of free electrons in three dimension and use this to calculate the Fermi wavenumber and Fermi Energy \\[ N = \\frac{2V}{(2\\pi)^3} \\int_{k<k_F} \\mathrm{d}\\mathbf{k} \\] The factor of two is very important. The integral is just the volume of a sphere of radius \\(k_F\\) , this is, \\(4\\pi k_F^3/3\\) which then yields \\[ k_F = (3\\pi^2 N/V)^{1/3} \\] and thus the Fermi energy is \\[ E_F = \\frac{\\hbar^2(3\\pi^2 N/V)^{2/3}}{2m} \\] Using the previous result, estimate the value of the Fermi energy for Caesium Caesium has a density of \\(1.93\\textrm{g/cm^3}\\) and a mass of approximately \\(133 \\textrm{amu}\\) (132.9055) and thus the density of atoms is \\[ N/V = (1.93 \\textrm{g/cm^3}) \\times (10^2 \\textrm{cm/m})^3 \\times (\\frac{1}{133}\\textrm{mol/g}) \\times (N_A \\textrm{atoms/mol}) = 8.7 \\textrm{atoms/m^3} \\] and with one valence electron, \\(N/V\\) for electrons is identical and we can plug it into the expression for \\(E_F\\) from part (ii) which returns \\(E_F = 2.48 \\times 10^{-19} \\textrm {J} = 1.6 \\textrm{eV}\\) Obtain an expression for the density of states at the Fermi surface of a \\textbf{two-dimensional} free-electron gas. For a two-dimensional gas \\[ N = 2A \\int_{k<k_F} \\frac{\\mathrm{d}\\mathbf{k}}{(2\\pi)^2} = \\frac{2A}{(2\\pi)^2}\\pi k_F^2 \\] where (again) \\(A\\) is the area and the integral is over a circle with radius \\(k_F\\) (c.f. exercise 1 (ii), only a factor of two different due to polarisation). Therefore \\[ k_F = (2\\pi N/A)^{1/2} \\] and the Fermi energy is \\[ E_F = \\frac{\\hbar^2 (2\\pi N/A)}{2m} = \\frac{\\hbar^2\\pi N/A}{m} \\] The density of states is then independent of energy and is given by \\[ \\frac{\\mathrm{d}N}{\\mathrm{d}E} = \\frac{Am}{\\hbar^2\\pi} = N/E_F \\] Using the above result, show that for a two-dimensional free-electron gas that the chemical potential \\(\\mu\\) is independent of temperature when \\(T \\ll \\mu\\) From above, we have the density of states which we note to be temperature independent. Thus, for a fixed density of electrons, the chemical potential is fixed by \\[ n = \\int_0^{\\infty} \\mathrm{d}E~g(E)~\\frac{1}{\\exp\\left(\\beta(E-\\mu)\\right)+1}. \\] The connection one must make is that except for corrections exponentially small in \\(\\beta\\mu\\) , the value of the integral is independent of \\(\\beta\\) and thus one can assume that the dependence of \\(n\\) on \\(\\mu\\) is temperature independent. If one wants to do the maths, we write the density of states as a constant \\(g\\) (see above) and then the integral above can be recast \\[ n = g \\int_{-\\mu}^{\\infty} \\mathrm{d}x~\\frac{1}{\\exp(\\beta x)+1} = g \\int_{-\\mu}^{\\infty} \\mathrm{d}x \\frac{\\exp(-\\beta x)}{\\exp(-\\beta x)+1} = \\frac{g}{\\beta} \\log(\\exp(\\beta \\mu)+1) \\] And for large \\(\\beta\\mu\\) (small) we can expand to have \\[ n/g = \\mu + \\mathcal{O}\\left(\\exp(-\\beta\\mu)\\right) \\] which means that provided \\(T \\ll \\mu\\) , there is no dependence on the temperature. Exercise 4 - chemistry \u00b6 Explain using the simplest language you can muster why is there periodic table important? Ability to predict properties of elements, ability to predict properties of compounds, ability to group/classify elements with similar characteristics, displays trends Choose a naturally occurring element with a high atomic number and use Madelung's Rule to deduce the shell filling configuration. The configuration for uranium is shown below, and all shell filling will be in this order: U: 1s \\(^2\\) 2s \\(^2\\) 2p \\(^6\\) 3s \\(^2\\) 3p \\(^6\\) 4s \\(^2\\) 3d \\(^{10}\\) 4p \\(^6\\) 5s \\(^2\\) 4d \\(^{10}\\) 5p \\(^6\\) 6s \\(^2\\) 4e \\(^{14}\\) 5d \\(^{10}\\) 6p \\(^6\\) 7s \\(^2\\) 5f \\(^4\\) which can be written in shorthand as [Rn]7s \\(^2\\) 5f \\(^4\\) . Using any tools at your disposal (i.e. use a computer) produce a plot of the energy eigenstate described by \\(|5, 2, 0 \\rangle\\) . You must include your code and you will be partially assessed on presentation: producing content that is digestible and visually pleasing is an important part of modern science! I made a mistake here, I should have the angular dependence or something, as plotting the wavefunction in 3D is hard. The electronic states of hydrogen can be found in many places (e.g. Wikipedia ) and are given by \\[ \\psi _{n\\ell m}(r,\\theta ,\\varphi )={\\sqrt {{\\left({\\frac {2}{na_{0}^{*}}}\\right)}^{3}{\\frac {(n-\\ell -1)!}{2n(n+\\ell )!}}}}e^{-\\rho /2}\\rho ^{\\ell }L_{n-\\ell -1}^{2\\ell +1}(\\rho )Y_{\\ell }^{m}(\\theta ,\\varphi ) \\] where \\(\\rho = 2r/n a_0^*\\) , \\(a_0^*=4\\pi\\epsilon_0\\hbar^2/\\mu e^2\\) is the reduced Bohr radius, \\(\\mu = m_e M/(m_e + M)\\) is the reduced mass, \\(L_{n-\\ell -1}^{2\\ell +1}(\\rho )\\) is the generalised Laguerre polynomial and \\(Y_{\\ell }^{m}(\\theta ,\\varphi )\\) is the spherical harmonic function.","title":"Assignment 1: Debye, Drude, Sommerfeld, and chemistry"},{"location":"solutions/assignment1/#assignment-1-debye-drude-sommerfeld-and-chemistry","text":"The first assignment can be found here","title":"Assignment 1: Debye, Drude, Sommerfeld, and chemistry"},{"location":"solutions/assignment1/#exercise-1-debye","text":"What are the assumptions of the Debye model? The Debye model considers only sound waves in a material (i.e. one assumes a linear dispersion \\(\\omega = v k\\) ) which oscillate up to a maximum frequency \\(\\omega_{\\mathrm{cutoff}} = \\omega_d\\) , the Debye frequency, which exists to ensure that the total number of vibrational modes in the system is correct (equal to the number of degrees of freedom in the system). Write an expression for the number of modes in a two-dimensional system, and thus determine the Debye wavenumber (the wavenumber which corresponds to the Debye frequency). In two dimensions, there should be \\(2N\\) modes (we implicitly assume that the different sound polarisations propagate with the same velocity, and thus \\[ 2N = 2 \\frac{A}{2\\pi^2} \\int_0^{|k| = k_d} \\mathrm{d}^2 k \\] where \\(A\\) is the area of our periodic system ( \\(L \\times L\\) ). The integral is simply the area of a circle with a radius \\(k_d\\) , so it evaluates to \\[ 2N = \\frac{2A}{(2\\pi)^2}(\\pi k_d^2) \\] and ultimately obtains \\[ k_d = \\sqrt{4\\pi n} \\] with \\(n = N/A\\) (the two-dimensional density). Provide a brief discussion of which elements you would expect to have a high Debye temperature, and which elements you would expect to have a low Debye temperature. The Debye temperature \\(T_d\\) is defined through \\[ E_d = \\hbar \\omega_{d} = k_{\\mathrm{B}} T_d \\] and as was shown in class , the Debye frequency is \\[ \\omega_d^3 = 6\\pi^2 n v_s^3 \\] where \\(v_s\\) is the speed of sound in the material. Therefore, one would expect the materials with large \\(v_s\\) to have the highest \\(T_d\\) . Consequently, a good guess for the highest \\(T_d\\) would be diamond (and indeed, it is the highest). For low \\(T_d\\) , low speed of sound materials will be compressible - a small spring constant in the Einstein/Debye models - so the nobel gasses or soft metals (e.g. group I) would be good candidates.","title":"Exercise 1 - Debye"},{"location":"solutions/assignment1/#exercise-2-drude-mixed-ion-electron-conductors-miecs","text":"Calculate the electrical resistivity \\(\\rho\\) Assuming that both species respond to the electric field independently - we assume that there are no interactions - the total conductivity is the sum of the two independent conductivities \\[ \\sigma = \\sigma_e + \\sigma_i = e^2 \\left(\\frac{n_e \\tau_e}{m_e} + \\frac{n_i \\tau_i}{m_i}\\right) \\] and therefore the resistivity \\(\\rho = 1/\\sigma\\) \\[ \\rho \\frac{1}{e^2 \\left(\\frac{n_e \\tau_e}{m_e} + \\frac{n_i \\tau_i}{m_i}\\right)} \\] Calculate the thermal conductivity \\(\\kappa\\) The thermal conductivity is calculated in the same way as the resistivity, in that we add the two pieces: \\[ \\kappa = \\kappa_e + \\kappa_i = \\frac{4k_{\\textrm{B}}^2 T}{\\pi} \\left( \\frac{n_e \\tau_e}{m_e} + \\frac{n_i \\tau_i}{m_i} \\right) \\] What is the Wiedemann-Franz law? Does it hold in this situation? The Wiedemann-Franz law states that the ratio (also known as the Lorenz number) \\[ L = \\frac{\\kappa}{T\\sigma} = \\frac{3}{2} \\left(\\frac{k_{\\textrm{B}}}{e}\\right) \\] is roughly constant for metals, and it indeed holds for MIECs If we consider a magnetic field applied in the \\(+z\\) direction, we need only consider the conductivity in \\(x\\) and \\(y\\) and can write \\[ \\rho = \\begin{pmatrix} \\frac{m}{nq^2\\tau} & \\frac{Bq}{n} \\\\ -\\frac{Bq}{n} & \\frac{m}{nq^2\\tau} \\end{pmatrix} \\] which is true for both charge carrier species. Use this result to calculate the resistivity matrix in the case of a MIEC. To make life simpler, one can write \\[ \\rho = \\begin{pmatrix} r & B R \\\\ -B R & r \\end{pmatrix} \\] where \\(r = m/(n q^2 \\tau)\\) and \\(R=q/n\\) . We can then define \\(\\rho_e\\) and \\(\\rho_i\\) for the two species. The conductivities are then \\(\\sigma_j=\\rho_j^{-1}\\) for \\(j = e, i\\) , and then the total conductivity \\(\\sigma_t = \\sigma_e + \\sigma_i\\) . The total resistivity is then \\(\\rho = \\sigma_t^{-1}\\) \\mrk{1}. The process is pretty algebra heavy, but the results are \\[\\begin{align} \\rho_{xx} & = \\frac{B^2 (r_e R_i^2 + r_i R_e^2) + r_i r_e (r_e + r_i)}{B^2 (R_e + R_i)^2 + (r_e + r_i)^2} \\\\ \\rho_{xy} & = \\frac{B (B^2 R_e R_i (R_e + R_i) + R_i r_e^2 + R_e r_i^2 }{B^2 (R_e + R_i)^2 + (r_e + r_i)^2} \\end{align}\\] Note that using software to do this kind of grunt work is absolutely fine (encouraged even)","title":"Exercise 2 - Drude: mixed ion-electron conductors (MIECs)"},{"location":"solutions/assignment1/#exercise-3-sommerfeld","text":"In your own words, explain what is the Fermi energy, Fermi temperature and the Fermi surface The Fermi energy is the chemical potential at \\(T=0\\) , the Fermi temperature is the associated temperature \\(T_F = E_F/k_{\\textrm{B}}\\) , and is the temperature at which thermal energy would dictate the properties of a material to the same degree as the fact they are fermions. The Fermi surface is the surface in momentum space which separates the filled and unfilled states at zero temperature_ . Write an expression for the number of states for a gas of free electrons in three dimension and use this to calculate the Fermi wavenumber and Fermi Energy \\[ N = \\frac{2V}{(2\\pi)^3} \\int_{k<k_F} \\mathrm{d}\\mathbf{k} \\] The factor of two is very important. The integral is just the volume of a sphere of radius \\(k_F\\) , this is, \\(4\\pi k_F^3/3\\) which then yields \\[ k_F = (3\\pi^2 N/V)^{1/3} \\] and thus the Fermi energy is \\[ E_F = \\frac{\\hbar^2(3\\pi^2 N/V)^{2/3}}{2m} \\] Using the previous result, estimate the value of the Fermi energy for Caesium Caesium has a density of \\(1.93\\textrm{g/cm^3}\\) and a mass of approximately \\(133 \\textrm{amu}\\) (132.9055) and thus the density of atoms is \\[ N/V = (1.93 \\textrm{g/cm^3}) \\times (10^2 \\textrm{cm/m})^3 \\times (\\frac{1}{133}\\textrm{mol/g}) \\times (N_A \\textrm{atoms/mol}) = 8.7 \\textrm{atoms/m^3} \\] and with one valence electron, \\(N/V\\) for electrons is identical and we can plug it into the expression for \\(E_F\\) from part (ii) which returns \\(E_F = 2.48 \\times 10^{-19} \\textrm {J} = 1.6 \\textrm{eV}\\) Obtain an expression for the density of states at the Fermi surface of a \\textbf{two-dimensional} free-electron gas. For a two-dimensional gas \\[ N = 2A \\int_{k<k_F} \\frac{\\mathrm{d}\\mathbf{k}}{(2\\pi)^2} = \\frac{2A}{(2\\pi)^2}\\pi k_F^2 \\] where (again) \\(A\\) is the area and the integral is over a circle with radius \\(k_F\\) (c.f. exercise 1 (ii), only a factor of two different due to polarisation). Therefore \\[ k_F = (2\\pi N/A)^{1/2} \\] and the Fermi energy is \\[ E_F = \\frac{\\hbar^2 (2\\pi N/A)}{2m} = \\frac{\\hbar^2\\pi N/A}{m} \\] The density of states is then independent of energy and is given by \\[ \\frac{\\mathrm{d}N}{\\mathrm{d}E} = \\frac{Am}{\\hbar^2\\pi} = N/E_F \\] Using the above result, show that for a two-dimensional free-electron gas that the chemical potential \\(\\mu\\) is independent of temperature when \\(T \\ll \\mu\\) From above, we have the density of states which we note to be temperature independent. Thus, for a fixed density of electrons, the chemical potential is fixed by \\[ n = \\int_0^{\\infty} \\mathrm{d}E~g(E)~\\frac{1}{\\exp\\left(\\beta(E-\\mu)\\right)+1}. \\] The connection one must make is that except for corrections exponentially small in \\(\\beta\\mu\\) , the value of the integral is independent of \\(\\beta\\) and thus one can assume that the dependence of \\(n\\) on \\(\\mu\\) is temperature independent. If one wants to do the maths, we write the density of states as a constant \\(g\\) (see above) and then the integral above can be recast \\[ n = g \\int_{-\\mu}^{\\infty} \\mathrm{d}x~\\frac{1}{\\exp(\\beta x)+1} = g \\int_{-\\mu}^{\\infty} \\mathrm{d}x \\frac{\\exp(-\\beta x)}{\\exp(-\\beta x)+1} = \\frac{g}{\\beta} \\log(\\exp(\\beta \\mu)+1) \\] And for large \\(\\beta\\mu\\) (small) we can expand to have \\[ n/g = \\mu + \\mathcal{O}\\left(\\exp(-\\beta\\mu)\\right) \\] which means that provided \\(T \\ll \\mu\\) , there is no dependence on the temperature.","title":"Exercise 3 - Sommerfeld"},{"location":"solutions/assignment1/#exercise-4-chemistry","text":"Explain using the simplest language you can muster why is there periodic table important? Ability to predict properties of elements, ability to predict properties of compounds, ability to group/classify elements with similar characteristics, displays trends Choose a naturally occurring element with a high atomic number and use Madelung's Rule to deduce the shell filling configuration. The configuration for uranium is shown below, and all shell filling will be in this order: U: 1s \\(^2\\) 2s \\(^2\\) 2p \\(^6\\) 3s \\(^2\\) 3p \\(^6\\) 4s \\(^2\\) 3d \\(^{10}\\) 4p \\(^6\\) 5s \\(^2\\) 4d \\(^{10}\\) 5p \\(^6\\) 6s \\(^2\\) 4e \\(^{14}\\) 5d \\(^{10}\\) 6p \\(^6\\) 7s \\(^2\\) 5f \\(^4\\) which can be written in shorthand as [Rn]7s \\(^2\\) 5f \\(^4\\) . Using any tools at your disposal (i.e. use a computer) produce a plot of the energy eigenstate described by \\(|5, 2, 0 \\rangle\\) . You must include your code and you will be partially assessed on presentation: producing content that is digestible and visually pleasing is an important part of modern science! I made a mistake here, I should have the angular dependence or something, as plotting the wavefunction in 3D is hard. The electronic states of hydrogen can be found in many places (e.g. Wikipedia ) and are given by \\[ \\psi _{n\\ell m}(r,\\theta ,\\varphi )={\\sqrt {{\\left({\\frac {2}{na_{0}^{*}}}\\right)}^{3}{\\frac {(n-\\ell -1)!}{2n(n+\\ell )!}}}}e^{-\\rho /2}\\rho ^{\\ell }L_{n-\\ell -1}^{2\\ell +1}(\\rho )Y_{\\ell }^{m}(\\theta ,\\varphi ) \\] where \\(\\rho = 2r/n a_0^*\\) , \\(a_0^*=4\\pi\\epsilon_0\\hbar^2/\\mu e^2\\) is the reduced Bohr radius, \\(\\mu = m_e M/(m_e + M)\\) is the reduced mass, \\(L_{n-\\ell -1}^{2\\ell +1}(\\rho )\\) is the generalised Laguerre polynomial and \\(Y_{\\ell }^{m}(\\theta ,\\varphi )\\) is the spherical harmonic function.","title":"Exercise 4 - chemistry"},{"location":"solutions/assignment2/","text":"Assignment 2: Bonding and harmonic chains \u00b6 The second assignment can be found here . Exercise 1 - Bonding: not LCAO \u00b6 In you own words, explain why ionic bonds occur, and what properties one would expect from and ionic solid. Ionic bonds occur as an electron is transferred from one atom to another, and the resulting ions attract each other. Typical properties are due to the nature of the bond being very strong, with materials having high melting temperatures, and usually being hard, brittle, and electrically insulating. They are also mostly soluble, but this is not of so much relevance here. The (first) ionisation energy of sodium is roughly \\(5.14\\mathrm{eV}\\) , and the electron affinity of chlorine is roughly \\(3.62\\) , and the bond length between the two atoms when a sodium chloride molecule is formed is roughly \\(0.236\\mathrm{nm}\\) . Assuming that all of the cohesive energy is due to the Coulomb interaction, calculate the bonding energy. The cohesive energy is related to the bond distance \\(d\\) via \\[ E_{coh} = \\frac{e^2}{4\\pi\\epsilon_0 d}. \\] Using the value \\(d= 2.36 \\unicode{x212B}\\) one finds a cohesive enrgy of \\(6.10\\mathrm{eV}\\) and thus the total binding energy is \\[ E = -5.14 + 3.62 + 6.10 = 4.58 \\mathrm{eV} \\] The measured value of the bonding energy of sodium chloride is \\(4.26\\mathrm{eV}\\) . How does this compare to your value above? Justify your response. The calculated value above is slightly larger than the measured value with the reason for the discrepancy being there must be a repulsive fore between the ions (otherwise the would collapse into a singularity!) in addition to the Coulomb attraction, therefore reducing the size of the cohesive (binding) energy. In our discussion of bonding, we did not explicitly discuss van der Waals bonding. Research what is the nature of the van der Waals bond, explicitly describing the origin of the attractive force formation and reason as to why the force is of the form \\(R^{-7}\\) Van der Waals forces are from correlated dipole fluctuations. If the electron is a given fixed position, there is a dipole moment \\(\\mathbf{p} = e\\mathbf{r}\\) where \\(\\mathbf{r}\\) is the vector from the electron to the proton. With the electron \"orbiting\" (i.e, in an eigenstate), the average dipole moment is zero. However, if an electric field is applied to the atom, the atom will develop a polarisation (i.e., it will be more likely for the electron to be found on one side of the nucleus than on the other). We write \\[ \\mathbf{p} = \\chi \\mathbf{E} \\] with \\(\\chi\\) the polarisability. Now, let us suppose we have two such atoms, separated a distance \\(r\\) in the \\(\\hat{x}\\) direction. Suppose one atom momentarily has a dipole moment \\(\\mathbf{p}_1\\) (for definiteness, suppose this dipole moment is in the \\(\\hat{z}\\) direction). Then the second atom will feel an electric field \\[ E = \\frac{p_1}{4\\pi\\epsilon_0 r^3} \\] in the negative \\(\\hat{z}\\) direction. The second atom then, due to its polarisability, develops a dipole moment \\(p_2 = \\chi E\\) which in turn is attracted to the first atom. The potential energy between these two dipoles is \\[ U=\\frac{-\\left|p_{1}\\right|\\left|p_{2}\\right|}{4 \\pi \\epsilon_{0} r^{3}}=\\frac{-p_{1} \\chi E}{\\left(4 \\pi \\epsilon_{0}\\right) r^{3}}=\\frac{-\\left|p_{1}\\right|^{2} \\chi}{\\left(4 \\pi \\epsilon_{0} r^{3}\\right)^{2}} \\] corresponding to a force which is attractive and proportional to \\(1/r7\\) . Note that while for a single isolated atom \\(\\langle p \\rangle = 0\\) the result is proportional instead to \\(\\langle |p|^2 \\rangle \\sim \\langle |r|^2 \\rangle\\) with r the position of an electron, is nonzero. Exercise 2 - Bonding: LCAO \u00b6 In our formulation of the LCAO formulation we assumed that orbitals were orthogonal, with the justification that the qualitative behaviour was still going to be fine. Assume that we introduce a trial wavefunction: \\[ |\\psi \\rangle = \\sum_{i=1}^{N} \\phi_i |i\\rangle \\] however, we are not going to enforce that the state be orthogonal. Rather, we define an overlap matrix \\(\\mathcal{S}\\) with elements \\[ \\mathcal{S}_{i,j} = \\langle i | j \\rangle \\] Show that with the above conditions, one arrives at an effective Schr\u00f6dinger equation \\[ \\mathcal{H} \\phi = E\\mathcal{S}\\phi \\] where \\[ \\mathcal{H}_{i,j} = \\langle i | \\hat{H} | j \\rangle \\] and \\(\\phi\\) is the vector of the coefficients for the \\(\\phi_i\\) . This is the variational method 101. It is necessary to compute \\(E\\) through \\[ E=\\frac{\\langle\\psi|H| \\psi\\rangle}{\\langle\\psi \\mid \\psi\\rangle}=\\frac{\\sum_{n, m} \\phi_{n}^{*} \\mathcal{H}_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}} \\] which must then be minimised with respect to the \\(\\phi_n\\) . This is most simply done by differentiating with respect to \\(\\phi_n^*\\) and solving for the root(s): \\[ \\begin{aligned} 0 =\\frac{\\partial E}{\\partial \\phi_{n}^{*}} & =\\frac{\\sum_{m} \\mathcal{H}_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}}-\\left(\\frac{\\sum_{n, m} \\phi_{n}^{*} \\mathcal{H}_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}}\\right) \\frac{\\sum_{n, m} S_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}} \\\\ & =\\sum_{m} \\mathcal{H}_{n m} \\phi_{m}-E \\sum_{m} S_{n m} \\phi_{m} \\end{aligned} \\] where we have used the definition of \\(E\\) above to simplify the 2nd term in the top line. This is exactly the result required. Consider the case where N=2 (i.e. the diatomic case) and the orbitals are \\(s\\) ( \\(l=0\\) ) orbitals. Use the above equation to solve for the energy eigenvalues of the system. Firstly, the reason we consider \\(s\\) states is because an \\(s\\) orbital can be taken to be manifestly positive everywhere (it has no nodes), so overlaps \\(S_{ij}\\) must be real and positive, making life a little easier. In order to solve the equation \\[ \\mathcal{H} \\phi = E\\mathcal{S}\\phi \\] it is simplest to solve the eigenvalue problem \\[ \\mathcal{S}^{-1}\\mathcal{H} \\phi = E\\phi. \\] As we normally do, we write the Hamiltonian \\(\\mathcal{H}\\) as \\[ \\mathcal{H}=\\left(\\begin{array}{cc} \\epsilon & t \\\\ t^{*} & \\epsilon \\end{array}\\right) \\] with \\(t\\) the hopping and \\(\\epsilon = \\epsilon_0 + V_{\\mathrm{cross}}\\) , and the overlap matrix is just \\[ \\mathcal{S}=\\left(\\begin{array}{cc} 1 & S \\\\ S & 1 \\end{array}\\right) \\] where we have defined the only non-trivial element \\(\\mathcal{S}_{12} = S\\) . We then need to diagonalise \\[ \\mathcal{S}^{-1} \\mathcal{H}=\\frac{1}{1-S^{2}}\\left(\\begin{array}{cc} \\epsilon-S t & t-\\epsilon S \\\\ t-\\epsilon S & \\epsilon-S t \\end{array}\\right) \\] which has eigenvalues \\[\\begin{equation} E_{\\pm} = \\frac{1}{1-S^2}\\left( |\\epsilon - S t| \\pm |t - \\epsilon S| \\right). \\end{equation}\\] Exercise 3 - Quantum thermal expansion \u00b6 In a content unpacking session, we discussed thermal expansion arising from the anharmonic term in the interatomic potential. Assume masses \\(m_1\\) and \\(m_2\\) for the interacting particles and let's consider an anharmonic perturbation \\(\\delta V\\) \\[ \\delta V = -\\frac{\\kappa_3}{6}(x-x_0)^3 \\] to the one-dimensional quantum harmonic oscillator \\(H_0\\) : \\[ H_0 = \\frac{p^2}{2m}+\\frac{\\kappa}{2}(x-x_0)^2. \\] To first order in \\(\\kappa_3\\) , it can be shown that \\[ \\langle n | x | n \\rangle = x_0 + \\frac{E_n \\kappa_3}{2\\kappa^2} \\] where \\(|n\\rangle\\) is the eigenstate of the harmonic oscillator with \\[ E_n = \\hbar\\omega \\left(n+\\frac{1}{2}\\right) \\] What is the value of \\(\\omega\\) in terms of \\(m_1\\) and \\(m_2\\) ? The relationship between frequency and mass for a harmonic oscillator is \\[ \\omega = \\sqrt{\\frac{\\kappa}{m}} \\] and given our system is comprised of two masses \\(m_1\\) and \\(m_2\\) , we should use the reduced mass \\(\\mu\\) : \\[ \\mu = \\frac{m_1 m_2}{m_1 + m_2} \\] What is the interpretation of the \\(|0\\rangle\\) state? The \\(|0\\rangle\\) state is the ground state of the harmonic oscillator, which has some notable features, but most relevant is that the energy is not equal to the minimum of the potential, but rather \\(\\hbar\\omega/2\\) above the minimum, and therefore the will be fluctuations in both the position and momentum of the trapped particle around the minimum which is what gives rise to the average separation of atoms. The expectation value of \\(x\\) as a function of temperature is written as \\[ \\langle x \\rangle_{\\beta} = \\frac{\\sum_n \\langle n | x | n \\rangle e^{-\\beta E_n}}{\\sum_n e^{-\\beta E_n}} \\] Find the coefficient of thermal expansion Just crank the handle: \\[ \\begin{aligned} \\langle x\\rangle_{\\beta} &=\\frac{\\sum_{n}\\langle n|x| n\\rangle e^{-\\beta E_{n}}}{\\sum_{n} e^{-\\beta E_{n}}}=\\frac{\\sum_{n} \\left(x_{0}+E_{n} \\kappa_{3} /\\left(2 \\kappa^{2}\\right) \\right) e^{-\\beta E_{n}}}{\\sum_{n} e^{-\\beta E_{n}}} \\\\ &=x_{0}+\\frac{\\langle E\\rangle_{\\beta} \\kappa_{3}}{2 \\kappa^{2}} \\end{aligned} \\] where \\(\\langle E \\rangle_\\beta\\) is the energy expectation of a harmonic oscillator of frequency \\(\\omega\\) at temperature \\(\\beta = 1/(k_{\\mathrm{B}} T)\\) . It is fine to use the result that \\(\\langle E \\rangle_\\beta\\) directly: \\[ \\begin{aligned} \\langle E\\rangle_\\beta &=-(1 / Z) \\partial Z / \\partial \\beta=(\\hbar \\omega / 2) \\operatorname{coth}(\\beta \\hbar \\omega / 2) \\\\ &=\\hbar \\omega\\left(n_{B}(\\beta \\hbar \\omega)+\\frac{1}{2}\\right) \\end{aligned} \\] but this can be derived easily enough from the partition function: \\[ \\begin{aligned} Z_{1 d} &=\\sum_{n \\geq 0} e^{-\\beta \\hbar \\omega(n+1 / 2)} \\\\ &=e^{-\\beta \\hbar \\omega / 2} 1 /\\left(1-e^{-\\beta \\hbar \\omega}\\right) \\\\ &=1 /[2 \\sinh (\\beta \\hbar \\omega / 2)] \\end{aligned} \\] Combining the above equations one arrives at \\[ \\langle x\\rangle_{\\beta}=x_{0}+\\left(\\kappa_{3} \\hbar \\omega /\\left(4 \\kappa^{2}\\right)\\right) \\operatorname{coth}(\\beta \\hbar \\omega / 2) \\] and then the coefficient of thermal expansion is then \\[ \\alpha=\\frac{1}{x_{0}} \\frac{d\\langle x\\rangle_{\\beta}}{d T}=\\frac{\\kappa_{3}}{2 x_{0} \\kappa^{2}} \\frac{d\\langle E\\rangle}{d T} \\] The term \\(\\frac{d\\langle E\\rangle}{d T}\\) is identified as the specific heat \\(C\\) , and the specific heat of the a harmonic oscillator was covered when discussing the Einstein model of a solid, but can be calculated directly from the equation for \\(\\langle E \\rangle_\\beta\\) to yield \\[\\begin{equation} \\alpha=\\frac{\\kappa_{3} C}{2 x_{0} \\kappa^{2}}=\\frac{\\kappa_{3}}{2 x_{0} \\kappa^{2}} k_{b}(\\beta \\hbar \\omega)^{2} \\frac{e^{\\beta \\hbar \\omega}}{\\left(e^{\\beta \\hbar \\omega}-1\\right)^{2}} \\end{equation}\\] What is the behaviour of the coefficient at both high and low temperature, and comment on the physical significance of these results. In the low-temperature limit, the modes \"freeze\" out, entirely analogous to the specific heat dropping out at low temperature (there needs to be a minimum energy put into the system to enact change because of the quantised states of the harmonic oscillator). In the high-temperature limit, \\(C \\rightarrow k_{\\mathrm{B}}\\) so one obtains \\[ \\alpha = \\frac{\\kappa_3 k_{\\mathrm{B}}}{2 x_0 \\kappa^2} \\] in agreement with the classical result, and this result is valid when \\(k_{\\mathrm{B}} T \\gg \\hbar \\omega.\\) Exercise 4 - One-dimensional oscillations \u00b6 Explain what is meant by a normal mode and a phonon A normal mode is a periodic collective motion where all particles move at the same frequency. A phonon is a quantum of vibration. People tend to be confused by phonons, so to explicitly connect the two and explain why phonons are bosons: each classical normal mode of vibration corresponds to a quantum mode of vibration which can be excited multiple times. A single mode may be occupied by a single phonon, or it may be occupied with multiple phonons corresponding to a larger amplitude oscillation. The fact that the same state may be multiply occupied by phonons means that phonons must be bosons. Derive the dispersion relation for longitudinal oscillations of an infinite one-dimensional chain of identical atoms, assuming mass \\(m\\) , spring constant \\(\\kappa\\) , and lattice spacing \\(a\\) The equation of motion of the \\(n^{\\textrm{th}}\\) particle along the chain is given by \\[ m \\ddot{x}_{n}=\\kappa\\left(x_{n+1}-x_{n}\\right)+\\kappa\\left(x_{n-1}-x_{n}\\right)=\\kappa\\left(x_{n+1}+x_{n-1}-2 x_{n}\\right) \\] where \\(na\\) is the equilibrium position of the \\(n^{\\textrm{th}}\\) particle. Looking for solutions of the form \\[ x_n = A e^{i\\omega t - i k n a} \\] one obtains \\[ \\begin{aligned} -\\omega^{2} m e^{i \\omega t-i k n a} &=\\kappa e^{i \\omega t}\\left(e^{i k(n+1) a}+e^{i k(n-1) a}-2 e^{i k n}\\right) \\\\ \\omega^{2} m &=2 \\kappa(\\cos (k a)-1) \\end{aligned} \\] which can be recast as \\[ \\omega = \\sqrt{\\frac{2\\kappa}{m}\\left(\\cos(ka)-1\\right)} = 2\\sqrt{\\frac{\\kappa}{m}}\\left|\\sin\\left(\\frac{ka}{2}\\right)\\right| \\] Show that a the mode with wavevector \\(k\\) is equivalent to the mode \\(k + 2\\pi/a\\) \\[ e^{-i(k+2\\pi/a)na} = e^{-i k n a} e^{-i 2\\pi n} = e^{-i k n a} \\] Assuming periodic boundary conditions, how many different modes are there? If one assumes periodic boundary conditions, then \\(k = 2 \\pi m/L\\) , but \\(k\\) is identified with \\(k + 2 \\pi /a\\) so that there are therefore exactly \\(N = L/a\\) different normal modes. Find expressions for and plot both the group and phase velocities The phase velocity is calculated via \\[ v_p = \\omega/k = \\frac{2\\sqrt{\\frac{\\kappa}{m}}\\left|\\sin\\left( \\frac{ka}{2} \\right)\\right|}{k} \\] and the group velocity is \\[ v_g = \\frac{d\\omega}{dk} = a\\sqrt{\\frac{\\kappa}{m}} \\cos\\left(\\frac{|k|a}{2}\\right) = \\frac{a \\omega_0}{2}\\sqrt{1-\\frac{\\omega^2}{\\omega_0^2}} \\] where \\(\\omega_0 = 2\\sqrt{\\kappa/m}\\) . To plot this, code such as that below kappa = 1 m = 1 a = 1 def omega ( k ): return 2 * np . sqrt ( kappa / m ) * abs ( np . sin ( k * a / 2 )) def v_p ( k ): return omega ( k ) / k def v_g ( k ): omega_0 = 2 * np . sqrt ( kappa / m ) return omega_0 * ( a / 2 ) * np . sqrt ( 1 - ( omega ( k ) / omega_0 ) ** 2 ) fig , ax = plt . subplots () k = np . linspace ( - np . pi + 0.01 , np . pi - 0.01 , 300 ) ax . plot ( k [ 0 : 149 ], v_p ( k [ 0 : 149 ]), color = 'C0' , label = 'Phase velocity' ); ax . plot ( k [ 150 : 300 ], v_p ( k [ 150 : 300 ]), color = 'C0' ); ax . plot ( k [ 0 : 149 ], - v_g ( k [ 0 : 149 ]), color = 'C1' , label = 'Group velocity' ); ax . plot ( k [ 150 : 300 ], v_g ( k [ 150 : 300 ]), color = 'C1' ); ax . set_title ( 'Velocities' ) ax . set_xlabel ( r '$k$' ); ax . set_ylabel ( '$v(k)$' ); plt . xticks ([ - np . pi , 0 , np . pi ], [ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); plt . yticks ([ - 1 , 0 , 1 ], [ r '$-2\\sqrt{\\frac{\\kappa} {m} }$' , 0 , r '$2\\sqrt{\\frac{\\kappa} {m} }$' ]); plt . legend (); plt . tight_layout (); plt . savefig ( 'A2-4-v.pdf' , facecolor = 'white' , transparent = False ) plt . show () will yield this plot: Find an expression for the density of states \\(g(\\omega)\\) and plot \\(g(\\omega)\\) The density of states is uniform in \\(k\\) : if there are \\(N\\) sites in the system, there are \\(N\\) modes total and the density of states is therefore \\(dN/dk = Na/(2\\pi) = L/(2\\pi)\\) where \\(L\\) is the length of the system. We then have \\[ \\begin{aligned} g(\\omega) &=d N / d \\omega=(d N / d k)(d k / d \\omega)=\\frac{N a}{2 \\pi v_{\\text {group }}} \\\\ &=\\frac{N}{2 \\pi \\sqrt{\\kappa / m} \\cos (|k| a / 2)} \\\\ &=\\frac{2 N}{2 \\pi \\sqrt{(\\kappa / m)-(\\omega(k) / 2)^{2}}} \\end{aligned} \\] where we have used \\[ \\left(\\frac{\\omega}{2}\\right)^2 + \\left(\\frac{v_g}{a}\\right)^2 = \\frac{\\kappa}{m} \\] where in turn we have used the equation for the group velocity (previous question) to obtain the above identity. Note that the additional factor of 2 that appears in the numerator is to account for the fact that for each value of \\(\\omega > 0\\) there are actually two values of \\(k\\) with that \\(\\omega\\) , to ensure that if you integrate over frequency you correctly get back \\(N\\) degrees of freedom. The above plot was produced using the code below N = 1 fig , ax = plt . subplots () w = np . linspace ( 0 , np . pi / a - 1.15 , 300 ); g = ( 2 * N ) / ( 2 * np . pi * np . sqrt (( kappa / m ) - ( w / 2 ) ** 2 )); ax . plot ( w , g , 'C0' ); ax . set_xlabel ( r '$\\omega$' ); ax . set_ylabel ( '$g(\\omega) [N/(\\pi \\sqrt{k/m})]$' ); ax . set_title ( 'Density of states' ) plt . yticks ([ N / ( np . pi * np . sqrt ( kappa / m )), 2 , 3 ], [ 1 , 2 , 3 ]); ax . set_ylim ( 0 , 3 ) plt . tight_layout (); plt . savefig ( 'A2-4-dos.pdf' , facecolor = 'white' , transparent = False ) plt . show () Using \\(g(\\omega)\\) , find an expression for the heat capacity and use any tools at your disposal to plot the heat capacity versus temperature The energy stored in the chain is given by \\[ U = \\int d\\omega~g(\\omega)~\\hbar \\omega \\left(n_{\\textrm{B}}(\\omega)+1/2\\right) \\] and so the heat capacity is \\(\\partial U/\\partial T\\) . The factor of 1/2 can be ignored as it is a temperature independent constant and thus will vanish upon differentiation. Plotting this requires numerical integration of the above equation, and one should get a plot similar to that as shown below, with the values on the \\(x\\) axis changing with the parameters \\(\\kappa\\) , \\(m\\) , and \\(a\\) . Code to perform the numerical integration appears below, with the highlighted lines actually performing the integration a = 1e-10 def integrand ( w ): b = 1 / T nb = 1 / ( np . exp ( b * w ) - 1 ) g = ( 2 * N ) / ( 2 * np . pi * np . sqrt (( kappa / m ) - ( w / 2 ) ** 2 )) return g * w * nb temp = np . linspace ( 0.01 , 5 , 150 ) U = [] for T in temp : U . append ( integrate . quad ( integrand , 0 , 2 * np . sqrt ( kappa / m ))[ 0 ]) dt = temp [ 1 ] - temp [ 0 ] dudt = np . gradient ( U , dt ) fig , ax = plt . subplots () ax . plot ( temp , dudt ) ax . set_xlabel ( '$T$ [K]' ) ax . set_ylabel ( '$C/k_\\mathrm {B} $' ) ax . set_title ( 'Specific heat' ) plt . savefig ( 'A2-4-c.pdf' , facecolor = 'white' , transparent = False ) plt . show () the output of which is shown here:","title":"Assignment 2: Bonding and harmonic chains"},{"location":"solutions/assignment2/#assignment-2-bonding-and-harmonic-chains","text":"The second assignment can be found here .","title":"Assignment 2: Bonding and harmonic chains"},{"location":"solutions/assignment2/#exercise-1-bonding-not-lcao","text":"In you own words, explain why ionic bonds occur, and what properties one would expect from and ionic solid. Ionic bonds occur as an electron is transferred from one atom to another, and the resulting ions attract each other. Typical properties are due to the nature of the bond being very strong, with materials having high melting temperatures, and usually being hard, brittle, and electrically insulating. They are also mostly soluble, but this is not of so much relevance here. The (first) ionisation energy of sodium is roughly \\(5.14\\mathrm{eV}\\) , and the electron affinity of chlorine is roughly \\(3.62\\) , and the bond length between the two atoms when a sodium chloride molecule is formed is roughly \\(0.236\\mathrm{nm}\\) . Assuming that all of the cohesive energy is due to the Coulomb interaction, calculate the bonding energy. The cohesive energy is related to the bond distance \\(d\\) via \\[ E_{coh} = \\frac{e^2}{4\\pi\\epsilon_0 d}. \\] Using the value \\(d= 2.36 \\unicode{x212B}\\) one finds a cohesive enrgy of \\(6.10\\mathrm{eV}\\) and thus the total binding energy is \\[ E = -5.14 + 3.62 + 6.10 = 4.58 \\mathrm{eV} \\] The measured value of the bonding energy of sodium chloride is \\(4.26\\mathrm{eV}\\) . How does this compare to your value above? Justify your response. The calculated value above is slightly larger than the measured value with the reason for the discrepancy being there must be a repulsive fore between the ions (otherwise the would collapse into a singularity!) in addition to the Coulomb attraction, therefore reducing the size of the cohesive (binding) energy. In our discussion of bonding, we did not explicitly discuss van der Waals bonding. Research what is the nature of the van der Waals bond, explicitly describing the origin of the attractive force formation and reason as to why the force is of the form \\(R^{-7}\\) Van der Waals forces are from correlated dipole fluctuations. If the electron is a given fixed position, there is a dipole moment \\(\\mathbf{p} = e\\mathbf{r}\\) where \\(\\mathbf{r}\\) is the vector from the electron to the proton. With the electron \"orbiting\" (i.e, in an eigenstate), the average dipole moment is zero. However, if an electric field is applied to the atom, the atom will develop a polarisation (i.e., it will be more likely for the electron to be found on one side of the nucleus than on the other). We write \\[ \\mathbf{p} = \\chi \\mathbf{E} \\] with \\(\\chi\\) the polarisability. Now, let us suppose we have two such atoms, separated a distance \\(r\\) in the \\(\\hat{x}\\) direction. Suppose one atom momentarily has a dipole moment \\(\\mathbf{p}_1\\) (for definiteness, suppose this dipole moment is in the \\(\\hat{z}\\) direction). Then the second atom will feel an electric field \\[ E = \\frac{p_1}{4\\pi\\epsilon_0 r^3} \\] in the negative \\(\\hat{z}\\) direction. The second atom then, due to its polarisability, develops a dipole moment \\(p_2 = \\chi E\\) which in turn is attracted to the first atom. The potential energy between these two dipoles is \\[ U=\\frac{-\\left|p_{1}\\right|\\left|p_{2}\\right|}{4 \\pi \\epsilon_{0} r^{3}}=\\frac{-p_{1} \\chi E}{\\left(4 \\pi \\epsilon_{0}\\right) r^{3}}=\\frac{-\\left|p_{1}\\right|^{2} \\chi}{\\left(4 \\pi \\epsilon_{0} r^{3}\\right)^{2}} \\] corresponding to a force which is attractive and proportional to \\(1/r7\\) . Note that while for a single isolated atom \\(\\langle p \\rangle = 0\\) the result is proportional instead to \\(\\langle |p|^2 \\rangle \\sim \\langle |r|^2 \\rangle\\) with r the position of an electron, is nonzero.","title":"Exercise 1 - Bonding: not LCAO"},{"location":"solutions/assignment2/#exercise-2-bonding-lcao","text":"In our formulation of the LCAO formulation we assumed that orbitals were orthogonal, with the justification that the qualitative behaviour was still going to be fine. Assume that we introduce a trial wavefunction: \\[ |\\psi \\rangle = \\sum_{i=1}^{N} \\phi_i |i\\rangle \\] however, we are not going to enforce that the state be orthogonal. Rather, we define an overlap matrix \\(\\mathcal{S}\\) with elements \\[ \\mathcal{S}_{i,j} = \\langle i | j \\rangle \\] Show that with the above conditions, one arrives at an effective Schr\u00f6dinger equation \\[ \\mathcal{H} \\phi = E\\mathcal{S}\\phi \\] where \\[ \\mathcal{H}_{i,j} = \\langle i | \\hat{H} | j \\rangle \\] and \\(\\phi\\) is the vector of the coefficients for the \\(\\phi_i\\) . This is the variational method 101. It is necessary to compute \\(E\\) through \\[ E=\\frac{\\langle\\psi|H| \\psi\\rangle}{\\langle\\psi \\mid \\psi\\rangle}=\\frac{\\sum_{n, m} \\phi_{n}^{*} \\mathcal{H}_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}} \\] which must then be minimised with respect to the \\(\\phi_n\\) . This is most simply done by differentiating with respect to \\(\\phi_n^*\\) and solving for the root(s): \\[ \\begin{aligned} 0 =\\frac{\\partial E}{\\partial \\phi_{n}^{*}} & =\\frac{\\sum_{m} \\mathcal{H}_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}}-\\left(\\frac{\\sum_{n, m} \\phi_{n}^{*} \\mathcal{H}_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}}\\right) \\frac{\\sum_{n, m} S_{n m} \\phi_{m}}{\\sum_{n, m} \\phi_{n}^{*} S_{n m} \\phi_{m}} \\\\ & =\\sum_{m} \\mathcal{H}_{n m} \\phi_{m}-E \\sum_{m} S_{n m} \\phi_{m} \\end{aligned} \\] where we have used the definition of \\(E\\) above to simplify the 2nd term in the top line. This is exactly the result required. Consider the case where N=2 (i.e. the diatomic case) and the orbitals are \\(s\\) ( \\(l=0\\) ) orbitals. Use the above equation to solve for the energy eigenvalues of the system. Firstly, the reason we consider \\(s\\) states is because an \\(s\\) orbital can be taken to be manifestly positive everywhere (it has no nodes), so overlaps \\(S_{ij}\\) must be real and positive, making life a little easier. In order to solve the equation \\[ \\mathcal{H} \\phi = E\\mathcal{S}\\phi \\] it is simplest to solve the eigenvalue problem \\[ \\mathcal{S}^{-1}\\mathcal{H} \\phi = E\\phi. \\] As we normally do, we write the Hamiltonian \\(\\mathcal{H}\\) as \\[ \\mathcal{H}=\\left(\\begin{array}{cc} \\epsilon & t \\\\ t^{*} & \\epsilon \\end{array}\\right) \\] with \\(t\\) the hopping and \\(\\epsilon = \\epsilon_0 + V_{\\mathrm{cross}}\\) , and the overlap matrix is just \\[ \\mathcal{S}=\\left(\\begin{array}{cc} 1 & S \\\\ S & 1 \\end{array}\\right) \\] where we have defined the only non-trivial element \\(\\mathcal{S}_{12} = S\\) . We then need to diagonalise \\[ \\mathcal{S}^{-1} \\mathcal{H}=\\frac{1}{1-S^{2}}\\left(\\begin{array}{cc} \\epsilon-S t & t-\\epsilon S \\\\ t-\\epsilon S & \\epsilon-S t \\end{array}\\right) \\] which has eigenvalues \\[\\begin{equation} E_{\\pm} = \\frac{1}{1-S^2}\\left( |\\epsilon - S t| \\pm |t - \\epsilon S| \\right). \\end{equation}\\]","title":"Exercise 2 - Bonding: LCAO"},{"location":"solutions/assignment2/#exercise-3-quantum-thermal-expansion","text":"In a content unpacking session, we discussed thermal expansion arising from the anharmonic term in the interatomic potential. Assume masses \\(m_1\\) and \\(m_2\\) for the interacting particles and let's consider an anharmonic perturbation \\(\\delta V\\) \\[ \\delta V = -\\frac{\\kappa_3}{6}(x-x_0)^3 \\] to the one-dimensional quantum harmonic oscillator \\(H_0\\) : \\[ H_0 = \\frac{p^2}{2m}+\\frac{\\kappa}{2}(x-x_0)^2. \\] To first order in \\(\\kappa_3\\) , it can be shown that \\[ \\langle n | x | n \\rangle = x_0 + \\frac{E_n \\kappa_3}{2\\kappa^2} \\] where \\(|n\\rangle\\) is the eigenstate of the harmonic oscillator with \\[ E_n = \\hbar\\omega \\left(n+\\frac{1}{2}\\right) \\] What is the value of \\(\\omega\\) in terms of \\(m_1\\) and \\(m_2\\) ? The relationship between frequency and mass for a harmonic oscillator is \\[ \\omega = \\sqrt{\\frac{\\kappa}{m}} \\] and given our system is comprised of two masses \\(m_1\\) and \\(m_2\\) , we should use the reduced mass \\(\\mu\\) : \\[ \\mu = \\frac{m_1 m_2}{m_1 + m_2} \\] What is the interpretation of the \\(|0\\rangle\\) state? The \\(|0\\rangle\\) state is the ground state of the harmonic oscillator, which has some notable features, but most relevant is that the energy is not equal to the minimum of the potential, but rather \\(\\hbar\\omega/2\\) above the minimum, and therefore the will be fluctuations in both the position and momentum of the trapped particle around the minimum which is what gives rise to the average separation of atoms. The expectation value of \\(x\\) as a function of temperature is written as \\[ \\langle x \\rangle_{\\beta} = \\frac{\\sum_n \\langle n | x | n \\rangle e^{-\\beta E_n}}{\\sum_n e^{-\\beta E_n}} \\] Find the coefficient of thermal expansion Just crank the handle: \\[ \\begin{aligned} \\langle x\\rangle_{\\beta} &=\\frac{\\sum_{n}\\langle n|x| n\\rangle e^{-\\beta E_{n}}}{\\sum_{n} e^{-\\beta E_{n}}}=\\frac{\\sum_{n} \\left(x_{0}+E_{n} \\kappa_{3} /\\left(2 \\kappa^{2}\\right) \\right) e^{-\\beta E_{n}}}{\\sum_{n} e^{-\\beta E_{n}}} \\\\ &=x_{0}+\\frac{\\langle E\\rangle_{\\beta} \\kappa_{3}}{2 \\kappa^{2}} \\end{aligned} \\] where \\(\\langle E \\rangle_\\beta\\) is the energy expectation of a harmonic oscillator of frequency \\(\\omega\\) at temperature \\(\\beta = 1/(k_{\\mathrm{B}} T)\\) . It is fine to use the result that \\(\\langle E \\rangle_\\beta\\) directly: \\[ \\begin{aligned} \\langle E\\rangle_\\beta &=-(1 / Z) \\partial Z / \\partial \\beta=(\\hbar \\omega / 2) \\operatorname{coth}(\\beta \\hbar \\omega / 2) \\\\ &=\\hbar \\omega\\left(n_{B}(\\beta \\hbar \\omega)+\\frac{1}{2}\\right) \\end{aligned} \\] but this can be derived easily enough from the partition function: \\[ \\begin{aligned} Z_{1 d} &=\\sum_{n \\geq 0} e^{-\\beta \\hbar \\omega(n+1 / 2)} \\\\ &=e^{-\\beta \\hbar \\omega / 2} 1 /\\left(1-e^{-\\beta \\hbar \\omega}\\right) \\\\ &=1 /[2 \\sinh (\\beta \\hbar \\omega / 2)] \\end{aligned} \\] Combining the above equations one arrives at \\[ \\langle x\\rangle_{\\beta}=x_{0}+\\left(\\kappa_{3} \\hbar \\omega /\\left(4 \\kappa^{2}\\right)\\right) \\operatorname{coth}(\\beta \\hbar \\omega / 2) \\] and then the coefficient of thermal expansion is then \\[ \\alpha=\\frac{1}{x_{0}} \\frac{d\\langle x\\rangle_{\\beta}}{d T}=\\frac{\\kappa_{3}}{2 x_{0} \\kappa^{2}} \\frac{d\\langle E\\rangle}{d T} \\] The term \\(\\frac{d\\langle E\\rangle}{d T}\\) is identified as the specific heat \\(C\\) , and the specific heat of the a harmonic oscillator was covered when discussing the Einstein model of a solid, but can be calculated directly from the equation for \\(\\langle E \\rangle_\\beta\\) to yield \\[\\begin{equation} \\alpha=\\frac{\\kappa_{3} C}{2 x_{0} \\kappa^{2}}=\\frac{\\kappa_{3}}{2 x_{0} \\kappa^{2}} k_{b}(\\beta \\hbar \\omega)^{2} \\frac{e^{\\beta \\hbar \\omega}}{\\left(e^{\\beta \\hbar \\omega}-1\\right)^{2}} \\end{equation}\\] What is the behaviour of the coefficient at both high and low temperature, and comment on the physical significance of these results. In the low-temperature limit, the modes \"freeze\" out, entirely analogous to the specific heat dropping out at low temperature (there needs to be a minimum energy put into the system to enact change because of the quantised states of the harmonic oscillator). In the high-temperature limit, \\(C \\rightarrow k_{\\mathrm{B}}\\) so one obtains \\[ \\alpha = \\frac{\\kappa_3 k_{\\mathrm{B}}}{2 x_0 \\kappa^2} \\] in agreement with the classical result, and this result is valid when \\(k_{\\mathrm{B}} T \\gg \\hbar \\omega.\\)","title":"Exercise 3 - Quantum thermal expansion"},{"location":"solutions/assignment2/#exercise-4-one-dimensional-oscillations","text":"Explain what is meant by a normal mode and a phonon A normal mode is a periodic collective motion where all particles move at the same frequency. A phonon is a quantum of vibration. People tend to be confused by phonons, so to explicitly connect the two and explain why phonons are bosons: each classical normal mode of vibration corresponds to a quantum mode of vibration which can be excited multiple times. A single mode may be occupied by a single phonon, or it may be occupied with multiple phonons corresponding to a larger amplitude oscillation. The fact that the same state may be multiply occupied by phonons means that phonons must be bosons. Derive the dispersion relation for longitudinal oscillations of an infinite one-dimensional chain of identical atoms, assuming mass \\(m\\) , spring constant \\(\\kappa\\) , and lattice spacing \\(a\\) The equation of motion of the \\(n^{\\textrm{th}}\\) particle along the chain is given by \\[ m \\ddot{x}_{n}=\\kappa\\left(x_{n+1}-x_{n}\\right)+\\kappa\\left(x_{n-1}-x_{n}\\right)=\\kappa\\left(x_{n+1}+x_{n-1}-2 x_{n}\\right) \\] where \\(na\\) is the equilibrium position of the \\(n^{\\textrm{th}}\\) particle. Looking for solutions of the form \\[ x_n = A e^{i\\omega t - i k n a} \\] one obtains \\[ \\begin{aligned} -\\omega^{2} m e^{i \\omega t-i k n a} &=\\kappa e^{i \\omega t}\\left(e^{i k(n+1) a}+e^{i k(n-1) a}-2 e^{i k n}\\right) \\\\ \\omega^{2} m &=2 \\kappa(\\cos (k a)-1) \\end{aligned} \\] which can be recast as \\[ \\omega = \\sqrt{\\frac{2\\kappa}{m}\\left(\\cos(ka)-1\\right)} = 2\\sqrt{\\frac{\\kappa}{m}}\\left|\\sin\\left(\\frac{ka}{2}\\right)\\right| \\] Show that a the mode with wavevector \\(k\\) is equivalent to the mode \\(k + 2\\pi/a\\) \\[ e^{-i(k+2\\pi/a)na} = e^{-i k n a} e^{-i 2\\pi n} = e^{-i k n a} \\] Assuming periodic boundary conditions, how many different modes are there? If one assumes periodic boundary conditions, then \\(k = 2 \\pi m/L\\) , but \\(k\\) is identified with \\(k + 2 \\pi /a\\) so that there are therefore exactly \\(N = L/a\\) different normal modes. Find expressions for and plot both the group and phase velocities The phase velocity is calculated via \\[ v_p = \\omega/k = \\frac{2\\sqrt{\\frac{\\kappa}{m}}\\left|\\sin\\left( \\frac{ka}{2} \\right)\\right|}{k} \\] and the group velocity is \\[ v_g = \\frac{d\\omega}{dk} = a\\sqrt{\\frac{\\kappa}{m}} \\cos\\left(\\frac{|k|a}{2}\\right) = \\frac{a \\omega_0}{2}\\sqrt{1-\\frac{\\omega^2}{\\omega_0^2}} \\] where \\(\\omega_0 = 2\\sqrt{\\kappa/m}\\) . To plot this, code such as that below kappa = 1 m = 1 a = 1 def omega ( k ): return 2 * np . sqrt ( kappa / m ) * abs ( np . sin ( k * a / 2 )) def v_p ( k ): return omega ( k ) / k def v_g ( k ): omega_0 = 2 * np . sqrt ( kappa / m ) return omega_0 * ( a / 2 ) * np . sqrt ( 1 - ( omega ( k ) / omega_0 ) ** 2 ) fig , ax = plt . subplots () k = np . linspace ( - np . pi + 0.01 , np . pi - 0.01 , 300 ) ax . plot ( k [ 0 : 149 ], v_p ( k [ 0 : 149 ]), color = 'C0' , label = 'Phase velocity' ); ax . plot ( k [ 150 : 300 ], v_p ( k [ 150 : 300 ]), color = 'C0' ); ax . plot ( k [ 0 : 149 ], - v_g ( k [ 0 : 149 ]), color = 'C1' , label = 'Group velocity' ); ax . plot ( k [ 150 : 300 ], v_g ( k [ 150 : 300 ]), color = 'C1' ); ax . set_title ( 'Velocities' ) ax . set_xlabel ( r '$k$' ); ax . set_ylabel ( '$v(k)$' ); plt . xticks ([ - np . pi , 0 , np . pi ], [ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); plt . yticks ([ - 1 , 0 , 1 ], [ r '$-2\\sqrt{\\frac{\\kappa} {m} }$' , 0 , r '$2\\sqrt{\\frac{\\kappa} {m} }$' ]); plt . legend (); plt . tight_layout (); plt . savefig ( 'A2-4-v.pdf' , facecolor = 'white' , transparent = False ) plt . show () will yield this plot: Find an expression for the density of states \\(g(\\omega)\\) and plot \\(g(\\omega)\\) The density of states is uniform in \\(k\\) : if there are \\(N\\) sites in the system, there are \\(N\\) modes total and the density of states is therefore \\(dN/dk = Na/(2\\pi) = L/(2\\pi)\\) where \\(L\\) is the length of the system. We then have \\[ \\begin{aligned} g(\\omega) &=d N / d \\omega=(d N / d k)(d k / d \\omega)=\\frac{N a}{2 \\pi v_{\\text {group }}} \\\\ &=\\frac{N}{2 \\pi \\sqrt{\\kappa / m} \\cos (|k| a / 2)} \\\\ &=\\frac{2 N}{2 \\pi \\sqrt{(\\kappa / m)-(\\omega(k) / 2)^{2}}} \\end{aligned} \\] where we have used \\[ \\left(\\frac{\\omega}{2}\\right)^2 + \\left(\\frac{v_g}{a}\\right)^2 = \\frac{\\kappa}{m} \\] where in turn we have used the equation for the group velocity (previous question) to obtain the above identity. Note that the additional factor of 2 that appears in the numerator is to account for the fact that for each value of \\(\\omega > 0\\) there are actually two values of \\(k\\) with that \\(\\omega\\) , to ensure that if you integrate over frequency you correctly get back \\(N\\) degrees of freedom. The above plot was produced using the code below N = 1 fig , ax = plt . subplots () w = np . linspace ( 0 , np . pi / a - 1.15 , 300 ); g = ( 2 * N ) / ( 2 * np . pi * np . sqrt (( kappa / m ) - ( w / 2 ) ** 2 )); ax . plot ( w , g , 'C0' ); ax . set_xlabel ( r '$\\omega$' ); ax . set_ylabel ( '$g(\\omega) [N/(\\pi \\sqrt{k/m})]$' ); ax . set_title ( 'Density of states' ) plt . yticks ([ N / ( np . pi * np . sqrt ( kappa / m )), 2 , 3 ], [ 1 , 2 , 3 ]); ax . set_ylim ( 0 , 3 ) plt . tight_layout (); plt . savefig ( 'A2-4-dos.pdf' , facecolor = 'white' , transparent = False ) plt . show () Using \\(g(\\omega)\\) , find an expression for the heat capacity and use any tools at your disposal to plot the heat capacity versus temperature The energy stored in the chain is given by \\[ U = \\int d\\omega~g(\\omega)~\\hbar \\omega \\left(n_{\\textrm{B}}(\\omega)+1/2\\right) \\] and so the heat capacity is \\(\\partial U/\\partial T\\) . The factor of 1/2 can be ignored as it is a temperature independent constant and thus will vanish upon differentiation. Plotting this requires numerical integration of the above equation, and one should get a plot similar to that as shown below, with the values on the \\(x\\) axis changing with the parameters \\(\\kappa\\) , \\(m\\) , and \\(a\\) . Code to perform the numerical integration appears below, with the highlighted lines actually performing the integration a = 1e-10 def integrand ( w ): b = 1 / T nb = 1 / ( np . exp ( b * w ) - 1 ) g = ( 2 * N ) / ( 2 * np . pi * np . sqrt (( kappa / m ) - ( w / 2 ) ** 2 )) return g * w * nb temp = np . linspace ( 0.01 , 5 , 150 ) U = [] for T in temp : U . append ( integrate . quad ( integrand , 0 , 2 * np . sqrt ( kappa / m ))[ 0 ]) dt = temp [ 1 ] - temp [ 0 ] dudt = np . gradient ( U , dt ) fig , ax = plt . subplots () ax . plot ( temp , dudt ) ax . set_xlabel ( '$T$ [K]' ) ax . set_ylabel ( '$C/k_\\mathrm {B} $' ) ax . set_title ( 'Specific heat' ) plt . savefig ( 'A2-4-c.pdf' , facecolor = 'white' , transparent = False ) plt . show () the output of which is shown here:","title":"Exercise 4 - One-dimensional oscillations"},{"location":"solutions/assignment3/","text":"Assignment 3: One-dimensional solids (welcome to the diatomic party) \u00b6 The third assignment can be found here Exercise 1 - Dispersion \u00b6 Use the dispersion relation to compute the group velocity \\(v_g\\) The group velocity is given by \\[\\begin{align} v_g(k) & =\\frac{\\partial \\omega(k)}{\\partial k}\\\\ & = a \\sqrt{\\frac{\\kappa}{m}}\\cos\\left(\\frac{ka}{2}\\right) \\frac{\\sin(ka/2)}{|\\sin(ka/2)|} \\end{align}\\] What is the relationship between the group velocity \\(v_g\\) and the density of states \\(g(\\omega)\\) ? Use this to calculate \\(g(\\omega)\\) The relationship is \\[ g(\\omega) = \\frac{L}{\\pi} \\left|\\frac{1}{v_g}\\right| \\] into which the equation from part (i) can be inserted: \\[\\begin{align} g(\\omega) & = \\frac{L}{a \\pi} \\sqrt{\\frac{m}{\\kappa}}\\frac{1}{\\cos(ka/2)}\\\\ & = \\frac{L}{a \\pi} \\sqrt{\\frac{m}{\\kappa}}\\frac{1}{\\sqrt{1-\\sin^2(ka/2)}}\\\\ & = \\frac{2L}{a \\pi} \\frac{1}{\\sqrt{4\\kappa / m - \\omega^2}} \\end{align}\\] Sketch or plot both \\(v_g\\) and \\(g(\\omega)\\) The group velocity is shown below and was produced using the following code: fig , ax = plt . subplots () k = np . linspace ( - np . pi + 0.01 , np . pi - 0.01 , 300 ) ax . plot ( k [ 0 : 149 ], np . sin ( k [ 0 : 149 ]) / ( np . sqrt ( 1 - np . cos ( k [ 0 : 149 ]))), color = 'C0' ); ax . plot ( k [ 150 : 300 ], np . sin ( k [ 150 : 300 ]) / ( np . sqrt ( 1 - np . cos ( k [ 150 : 300 ]))), color = 'C0' ); ax . set_title ( 'Group velocity' ) ax . set_xlabel ( r '$k$' ); ax . set_ylabel ( '$v(k)$' ); plt . xticks ([ - np . pi , 0 , np . pi ], [ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); plt . yticks ([ - np . sqrt ( 2 ), 0 , np . sqrt ( 2 )], [ r '$-2\\sqrt{\\frac{\\kappa} {m} }$' , 0 , r '$2\\sqrt{\\frac{\\kappa} {m} }$' ]); plt . tight_layout (); plt . savefig ( 'A3-1-v.pdf' , facecolor = 'white' , transparent = False ) plt . show () The density of states is shown below and was produced using the (near identical) code: fig , ax = plt . subplots () w = np . linspace ( 0 , 0.95 , 300 ); g = 1 / np . sqrt ( 1 - w ** 2 ); ax . plot ( w , g , 'C0' ); ax . set_xlabel ( r '$\\omega$' ); ax . set_ylabel ( '$g(\\omega)$' ); ax . set_title ( 'Density of states' ) plt . xticks ([ 0 , 1 ], [ 0 , r '$2\\sqrt{\\frac {k}{m} }$' ]); plt . yticks ([ 0.5 , 1 ], [ 0 , r '$\\frac {L} {2\\pi a}\\sqrt{\\frac{\\kappa} {m} }$' ]); plt . tight_layout (); plt . savefig ( 'A3-1-dos.pdf' , facecolor = 'white' , transparent = False ) plt . show () Consider the dispersion curve below: Sketch the group velocity \\(v_g(k)\\) One needs to sketch the derivative, which could be done by hand or computationally with the code to compute and plot the derivative shown below: k = k_vals [ 1 ] - k_vals [ 0 ] y = nn ( k_vals ) gradient = np . gradient ( y , dk ) fig , ax = plt . subplots () ax . plot ( k_vals [ k_vals < 0 ], gradient [ k_vals < 0 ], 'C0' ); ax . plot ( k_vals [ k_vals > .1 ], gradient [ k_vals > .1 ], 'C0' ); ax . set_xlabel ( r '$k$' ); ax . set_ylabel ( r '$\\frac{\\partial\\omega}{\\partial k}$' ); ax . set_xlim ( - 2 , 2 ) ax . set_title ( 'Group velocity' ) plt . xticks ([ - np . pi / a , 0 , np . pi / a ], [ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); plt . tight_layout (); plt . savefig ( 'A3-1-gv.pdf' , facecolor = 'white' , transparent = False ) plt . show () Produce a visualisation (e.g. a plot or histogram) of the density of states \\(g(\\omega)\\) A histogram well displays the density of states which can be compute using the following code: k_dos = np . linspace ( 0 , np . pi / a , 25 ) # dk value (2\\pi/L) # Make the band plot fig , ( ax , ax2 ) = plt . subplots ( ncols = 2 , sharey = True , figsize = ( 12 , 5 )) ax . plot ( k_vals , nn ( k_vals )); ax . vlines ( k_dos , 0 , nn ( k_dos ), colors = ( 0.5 , 0.5 , 0.5 , 0.5 )) ax . hlines ( np . hstack ( nn ( k_dos )), np . hstack ( k_dos ), np . pi / a , colors = ( 0.5 , 0.5 , 0.5 , 0.5 ) ) ax . set_xlabel ( '$k$' ) ax . set_ylabel ( r '$\u03c9$' ) ax . set_xticks ([ 0 , np . pi / 2 ]) ax . set_xticklabels ([ '$0$' , r '$\\pi/a$' ]) ax . set_yticks ([]) ax . set_yticklabels ([]) ax . set_xlim ( - 0.05 , max ( k ) + .05 ) k = np . linspace ( 0 , np . pi , 1000 ) omegas = nn ( k ) ax2 . hist ( omegas , orientation = 'horizontal' , bins = 75 ) ax2 . set_xlabel ( r '$g(\u03c9)$' ) ax2 . set_xticks ([]) plt . savefig ( 'A3-1-4-dos.pdf' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Exercise 2 - Normal modes of a one-dimensional diatomic chain \u00b6 What is the difference between an acoustic mode and optical mode? Describe the motion of atoms in the unit cell for long wavelength oscillations. In acoustic waves, the dispersion goes to zero and \\(k\\) and \\(\\omega \\sim k\\) for small \\(k\\) , whereas optical modes have an intercept with \\(\\omega = c k\\) where \\(c\\) is the speed of light. In the acoustic case, all atoms in a unit cell move in-phase with a slow spatial modulation, whereas in the optical case, adjacent atoms move out of phase with one another. Derive the dispersion relation for the longitudinal oscillations of a one-dimensional diatomic mass-and-spring crystal with unit cell length \\(a\\) and where each unit cell contains one atom of mass \\(m_1\\) and one atom of mass \\(m_2\\) connected by a spring with spring constant \\(\\kappa\\) . From the image, we write the position of the \\(n^{\\textrm{th}}\\) particle with mass \\(m_1\\) as \\(x_n\\) and the position of the \\(n^{\\textrm{th}}\\) particle with mass \\(m_2\\) as \\(y_n\\) . We assume that the equilibrium position of \\(x_n\\) is \\(n a\\) and the equilibrium position is \\(n a + d\\) . We then write the equations of motion for the deviations from the equilibrium positions as \\(\\delta x_n\\) and \\(\\delta y_n\\) \\[ \\begin{aligned} &m_{1} \\ddot{\\delta x}_{n} \\quad=-\\kappa\\left(\\delta x_{n}-\\delta y_{n-1}\\right)-\\kappa\\left(\\delta x_{n}-\\delta y_{n}\\right) \\\\ &m_{2} \\dot{\\delta} y_{n}=-\\kappa\\left(\\delta y_{n}-\\delta x_{n}\\right)-\\kappa\\left(\\delta y_{n}-\\delta x_{n+1}\\right) \\end{aligned} \\] We then assume solutions of the form \\[ \\begin{aligned} \\delta x_{n} &=A_{x} e^{i k a n-i \\omega t} \\\\ \\delta y_{n} &=A_{y} e^{i k a n-i \\omega t} \\end{aligned} \\] from which we obtain the equations \\[ \\begin{aligned} -m_{1} \\omega^{2} A_{x} e^{i k n a} &=-2 \\kappa A_{x} e^{i k n a}+\\kappa A_{y}\\left(e^{i k n a}+e^{i k(n-1) a}\\right) \\\\ -m_{2} \\omega^{2} A_{y} e^{i k n a} &=-2 \\kappa A_{y} e^{i k n a}+\\kappa A_{x}\\left(e^{i k n a}+e^{i k(n+1) a}\\right) \\end{aligned} \\] which simplify to \\[ \\begin{aligned} \\omega^{2} A_{x} &=2\\left(\\kappa / m_{1}\\right) A_{x}-\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) A_{y} \\\\ \\omega^{2} A_{y} &=2\\left(\\kappa / m_{2}\\right) A_{y}-\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) A_{x} \\end{aligned} \\] which defines an eigenvalue problem for \\(\\omega^2\\) . Therefore we must find the roots of the determinant \\[ \\left|\\begin{array}{cc} 2\\left(\\kappa / m_{1}\\right)-\\omega^{2} & -\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) \\\\ -\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) & 2\\left(\\kappa / m_{2}\\right)-\\omega^{2} \\end{array}\\right| \\] which yields the equation \\[ \\begin{aligned} &0=\\omega^{4}-\\omega^{2}\\left(2 \\kappa\\left(1 / m_{1}+1 / m_{2}\\right)\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}\\left(4-\\left(1+e^{i k a}\\right)\\left(1+e^{-i k a}\\right)\\right) \\\\ &\\left.0=\\omega^{4}-\\omega^{2}\\left(\\frac{2\\left(m_{1}+m_{2}\\right) \\kappa}{m_{1} m_{2}}\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}(2-2 \\cos (k a))\\right) \\end{aligned} \\] and ultimately \\[ \\begin{aligned} \\omega^{2} &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) \\\\ &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{\\left(m_{1}+m_{2}\\right)^{2}-4 m_{1} m_{2} \\sin ^{2}(k a / 2)}\\right) \\end{aligned} \\] Determine the frequencies of the acoustic and optical modes at \\(k=0\\) and at the Brillouin zone boundary At \\(k=0\\) , \\(\\cos(ka)=1\\) and therefore the acoustic mode has zero energy whereas the optical mode has energy \\[ \\omega = \\sqrt{\\frac{2\\kappa(m_1+m_2)}{m_1 m_2}} \\] At the Brilllouin zone boundary, \\(\\cos(ka)=-1\\) and so the energies of the two modes are \\[ \\omega = \\sqrt{\\frac{2\\kappa(m_1)}{m_1 m_2}} \\quad \\sqrt{\\frac{2\\kappa(m_2)}{m_1 m_2}} \\] Determine the sound velocity, and show that the group velocity is zero at the zone boundary () To find the sound velocity, one must expand around \\(k=0\\) for the acoustic mode and then one end with an equation of the from \\(\\omega = v k\\) with \\[ v = a \\sqrt{\\frac{\\kappa}{2(m_1 + m_2)}} \\] The group velocity \\(v_g\\) is given by \\(\\mathrm{d}\\omega/\\mathrm{k}\\) and whilst the form of \\(\\omega\\) is a bit ugly, if we write \\(f = \\omega^2\\) , we are interested in the derivative of the function \\(g = f^{1/2}\\) . So by the chain rule, \\[ \\frac{\\mathrm{d}g}{\\mathrm{k}} = \\frac{\\mathrm{d}g}{\\mathrm{d}f} \\frac{\\mathrm{d}f}{\\mathrm{d}k} \\] which means \\[ v_g = \\frac{1}{2}\\frac{1}{f^{1/2}} \\frac{\\mathrm{d}f}{\\mathrm{d}k}. \\] Now \\(f\\) is well behaved around \\(k = \\pm\\pi/a\\) , so we only need look at \\(\\frac{\\mathrm{d}f}{\\mathrm{d}k}\\) . Again, \\(f\\) is a bit ugly, but is essentially \\[ f = c_1 \\pm \\sqrt{c_2 + c_3 \\cos(k a)} \\] with constants \\(c_i\\) , and therefore, once again using the chain rule \\[ \\mathrm{d}f/\\mathrm{d}k \\sim \\pm \\frac{c_4 \\sin(k a)}{\\sqrt{c_2 + c_3 \\cos(k a)}} \\] which goes to zero for \\(k = \\pi/a\\) and therefore \\(v_g \\rightarrow 0\\) Sketch or plot the dispersion in both the reduced and extended zone scheme The dispersion in the reduced zone scheme: The dispersion in the extended zone scheme: The above plots were computed using the code below: Much code # Define a function to return the dispersion def dispersion_diatomic ( k , kappa = 1 , m1 = 2 , m2 = 1 , acoustic = True ): cons = m1 + m2 sq = np . sqrt (( cons ** 2 ) - ( 4 * m1 * m2 * np . sin ( k * a / 2 ) ** 2 )) if acoustic : sq *= - 1 return np . sqrt ( kappa / ( m1 * m2 ) * ( cons + sq ) / m ) scale = 3 # Set the sclae for plotting past the Brillouin zone a = 2 # Set the lattice constant brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # k values in the Brillouin zone ks = brillouin * scale # k values further afield - obviously less well sampled kappa = 1 # Plot the dispersion fig , ax = plt . subplots () ax . plot ( brillouin , dispersion_diatomic ( brillouin ), color = 'C0' , label = 'Acoustic' ) ax . plot ( brillouin , dispersion_diatomic ( brillouin , acoustic = False ), color = 'C1' , label = 'Optical' ) ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundary xvals = [ - np . pi / a , np . pi / a ] for v in xvals : ax . axvline ( x = v , color = 'black' ) offset = 0.3 if v < 0 : sign = '-' elif v > 0 : sign = '+' offset = - offset # Label the Brillouin range ax . text ( v + offset , .1 , f '$k = { sign } \\pi/a$' , horizontalalignment = 'center' , fontsize = 16 ) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$\\omega$' ) ax . set_xlim ( 1.1 * min ( xvals ), 1.1 * max ( xvals )) plt . legend ( bbox_to_anchor = ( .5 , - .125 ), loc = 'lower center' , ncol = 2 ) draw_classic_axes ( ax ) plt . savefig ( 'A3-2-brillouin.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () # Make arrays for the first and second Brillouin zones # first Bz brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # second Bz # You may be tempted to have a single array here, but if you do this, your plot will be ugly! # Verify this for yourself: you will find the function \"numpy.concatenate\" useful. first_ex = np . linspace ( - 2 * np . pi / a , - np . pi / a , 250 ) second_ex = np . flip ( first_ex * - 1 ) # Plot the Brillouin zones fig , ax = plt . subplots () ax . plot ( brillouin , dispersion_diatomic ( brillouin ), color = 'C0' , label = 'acoustic' ) ax . plot ( first_ex , dispersion_diatomic ( first_ex , acoustic = False ), color = 'C1' , label = 'optical' ) ax . plot ( second_ex , dispersion_diatomic ( second_ex , acoustic = False ), color = 'C1' ) # Only use one label to avoid double-tagging ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundaries - this is painfully manual xvals = [ - 2 * np . pi / a , - np . pi / a , np . pi / a , 2 * np . pi / a ] for n , v in enumerate ( xvals ): ax . axvline ( x = v , color = 'black' , linestyle = '--' ) offset = 0.3 if v < 0 : sign = '-' if n == 0 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' elif v > 0 : sign = '+' offset = - offset if n == 3 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' # Label the Brillouin range text ax . text ( v + offset , .1 , text , horizontalalignment = 'center' , fontsize = 16 ) omega_plus = np . sqrt ( 2 * kappa / m ) omega_minus = np . sqrt ( 2 * kappa / 2 * m ) gap = ( omega_plus + omega_minus ) / 2 # Band gap for arrows # Label the 1st Bz ax . text ( 0 , gap - offset / 2 , '1st Brillouin zone' , horizontalalignment = 'center' , fontsize = 16 ) ax . annotate ( text = '' , xy = ( - np . pi / a , gap ), xytext = ( np . pi / a , gap ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) # Label the 2nd Bz (<0) ax . text ( - 3 * np . pi / ( 2 * a ), gap + 1.75 * offset , '2nd Brillouin \\n zone' , horizontalalignment = 'center' , fontsize = 16 ) ax . annotate ( text = '' , xy = ( - 2 * np . pi / a , gap - .1 ), xytext = ( - np . pi / a , gap - .1 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) # Label the 2nd Bz(>0) ax . text ( 3 * np . pi / ( 2 * a ), gap + 1.75 * offset , '2nd Brillouin \\n zone' , horizontalalignment = 'center' , fontsize = 16 ) ax . annotate ( text = '' , xy = ( np . pi / a , gap - .1 ), xytext = ( 2 * np . pi / a , gap - .1 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$\\omega$' ) ax . set_title ( 'Extended zone scheme' ); plt . legend ( bbox_to_anchor = ( .5 , - .25 ), loc = 'lower center' , ncol = 2 ) plt . savefig ( 'A3-2-extended.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Assuming that there are \\(N\\) unit cells, how many different normal modes are there? And how many branches of excitation are there? If there are \\(N\\) unit cells, therefore \\(2N\\) atoms, there are \\(2N\\) modes. As there are 2 modes for \\(k\\) in the reduced zone scheme, there are two branches What happens when m_1 = m_2 When the masses as equal, the unit cell is now of size \\(a/2\\) to the Brillouin zone is double in size, and the gap between the branches vanishes, and the system looks identical to the monatomic chain (the image from the extended zone scheme works well here) Exercise 3 - Diatomic tight binding chain \u00b6 We have seen the both the diatomic chain and the tight-binding chain, so we are going to combine the two. Consider the system shown below Suppose that the onsite energy of atom \\(A\\) is different for atom \\(B\\) , that is \\(\\langle n | H | n \\rangle = \\epsilon_A\\) for | n \\rangle being on site \\(A\\) and \\(\\langle n | H | n \\rangle = \\epsilon_B\\) for \\(| n \\rangle\\) being on site \\(B\\) . We assume that the hopping \\(-t\\) is unchanged from the monatomic case. Derive the dispersion curve for electrons The unit cell \\(a\\) is the distance from an \\(A\\) atom to another \\(A\\) atom. Let \\(\\phi_n^A\\) be the amplitude of the wavefunction on the \\(n^{\\mathrm{th}}\\) site of type \\(A\\) and \\(\\phi_n^B\\) be the amplitude of the wavefunction on the \\(n^{\\mathrm{th}}\\) site of type \\(B\\) . We assume a trial wavefunction of the form \\[ | \\psi \\rangle = \\sum_n (\\phi_n^A + \\phi_n^B) | \\psi \\rangle \\] and put this into the Schr\u00f6dinger equation and find an effective Schr\u00f6dinger equation of the form \\[ \\begin{aligned} E \\phi_{n}^{A} &=\\epsilon_{A} \\phi_{n}^{A}-t\\left(\\phi_{n}^{B}+\\phi_{n-1}^{B}\\right) \\\\ E \\phi_{n}^{B} &=\\epsilon_{B} \\phi_{n}^{B}-t\\left(\\phi_{n}^{A}+\\phi_{n+1}^{A}\\right) \\end{aligned} \\] Assuming solutions of the form \\[ \\begin{aligned} \\phi_{n}^{A} &=A e^{i k n a} \\\\ \\phi_{n}^{B} &=B e^{i k n a} \\end{aligned} \\] gives \\[ \\begin{aligned} E A &=\\epsilon_{A} A-t\\left(1+e^{-i k a}\\right) B \\\\ E B &=\\epsilon_{B} B-t\\left(1+e^{i k a}\\right) A \\end{aligned} \\] again giving a \\(2 \\times 2\\) eigenvalue problem. We solve for the roots of the determinant \\[ \\left|\\begin{array}{cc} \\epsilon_{A}-E & -t\\left(1+e^{-i k a}\\right) \\\\ -t\\left(1+e^{i k a}\\right) & \\epsilon_{B}-E \\end{array}\\right| \\] which givens the equation \\[ 0=E^{2}-E\\left(\\epsilon_{A}+\\epsilon_{B}\\right)+\\left(\\epsilon_{A} \\epsilon_{B}-t^{2}(2+2 \\cos (k a))\\right) \\] \\[ E_{\\pm}(k)=\\frac{1}{2}\\left(\\epsilon_{A}+\\epsilon_{B} \\pm \\sqrt{\\left(\\epsilon_{A}-\\epsilon_{B}\\right)^{2}+4 t^{2}(2+2 \\cos (k a))}\\right) \\] Sketch or plot the above dispersion relation in both the reduced and extended zone schemes The dispersion in the reduced zone scheme: The dispersion in the extended zone scheme: The above plots were computed using the code below: Very code def energy ( k , ea = 5 , eb = 3 , t = 1 , low = True ): const = ea - eb sqrt = np . sqrt ( const ** 2 + 4 * t ** 2 * ( 2 + 2 * np . cos ( k * a ))) if low : sqrt *= - 1 return 1 / 2 * ( ea + eb + sqrt ) scale = 3 # Set the sclae for plotting past the Brillouin zone a = 2 # Set the lattice constant brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # k values in the Brillouin zone ks = brillouin * scale # k values further afield - obviously less well sampled # Plot the dispersion fig , ax = plt . subplots () ax . plot ( brillouin , energy ( brillouin ), color = 'C0' , label = 'Low E' ) ax . plot ( brillouin , energy ( brillouin , low = False ), color = 'C1' , label = 'High E' ) ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundary xvals = [ - np . pi / a , np . pi / a ] for v in xvals : ax . axvline ( x = v , color = 'black' ) offset = 0.3 if v < 0 : sign = '-' elif v > 0 : sign = '+' offset = - offset # Label the Brillouin range ax . text ( v + offset , 2 , f '$k = { sign } \\pi/a$' , horizontalalignment = 'center' , fontsize = 16 ) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$E$' ) ax . set_xlim ( 1.1 * min ( xvals ), 1.1 * max ( xvals )) plt . legend ( bbox_to_anchor = ( .5 , - .25 ), loc = 'lower center' , ncol = 2 ) plt . savefig ( 'A3-3-brillouin.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () # Make arrays for the first and second Brillouin zones # first Bz brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # second Bz # You may be tempted to have a single array here, but if you do this, your plot will be ugly! # Verify this for yourself: you will find the function \"numpy.concatenate\" useful. first_ex = np . linspace ( - 2 * np . pi / a , - np . pi / a , 250 ) second_ex = np . flip ( first_ex * - 1 ) # Plot the Brillouin zones fig , ax = plt . subplots () ax . plot ( brillouin , energy ( brillouin ), color = 'C0' , label = 'Low E' ) ax . plot ( first_ex , energy ( first_ex , low = False ), color = 'C1' , label = 'High E' ) ax . plot ( second_ex , energy ( second_ex , low = False ), color = 'C1' ) # Only use one label to avoid double-tagging ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundaries - this is painfully manual xvals = [ - 2 * np . pi / a , - np . pi / a , np . pi / a , 2 * np . pi / a ] for n , v in enumerate ( xvals ): ax . axvline ( x = v , color = 'black' , linestyle = '--' ) offset = 0.3 if v < 0 : sign = '-' if n == 0 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' elif v > 0 : sign = '+' offset = - offset if n == 3 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' # Label the Brillouin range text ax . text ( v + offset , 1.75 , text , horizontalalignment = 'center' , fontsize = 16 ) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$\\omega$' ) ax . set_title ( 'Extended zone scheme' ); plt . legend ( bbox_to_anchor = ( .5 , - .25 ), loc = 'lower center' , ncol = 2 ) plt . savefig ( 'A3-3-extended.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () What is the effective mass of an electron near the bottom of the lower band? To find the effective mass, we expand the energy around the minimum which gives \\[ E= \\mathrm{ constant }+\\frac{2 t^{2}(k a)^{2}}{\\sqrt{\\left(\\epsilon_{A}-\\epsilon_{B}\\right)^{2}+16 t^{2}}} \\] which set equal to \\(\\hbar^2 k^2 / (2m^*)\\) and find \\[ m^{*}=\\frac{\\hbar^{2} \\sqrt{\\left(\\epsilon_{A}-\\epsilon_{B}\\right)^{2}+16 t^{2}}}{4 t^{2} a^{2}} \\] If each atom ( \\(A\\) and \\(B\\) ) are monovalent, is the system a conductor or insulator? Justify your response If each atom is monovalent, there are now two electrons per unit cell, and this fills exactly the lower band and therefore the system is insulating. Consider the material LiF, and use the above results to justify why it is observed to be an excellent insulator. For LiF we can expect a much lower energy for electrons on F than on Li (F has a large electron affinity, Li has a low ionization energy). So we can set \\(\\epsilon_A \\ll \\epsilon_B\\) . What happens in this limit is that the bands are extremely far apart \u2013 thus a very good insulator. If you are really keen, one can look at the eigenvectors in the lower band, and one will find that they are almost completely on the lower energy atoms. Thus the free electron is transferred almost completely from the higher to the lower energy atom.","title":"Assignment 3: One-dimensional solids (welcome to the diatomic party)"},{"location":"solutions/assignment3/#assignment-3-one-dimensional-solids-welcome-to-the-diatomic-party","text":"The third assignment can be found here","title":"Assignment 3: One-dimensional solids (welcome to the diatomic party)"},{"location":"solutions/assignment3/#exercise-1-dispersion","text":"Use the dispersion relation to compute the group velocity \\(v_g\\) The group velocity is given by \\[\\begin{align} v_g(k) & =\\frac{\\partial \\omega(k)}{\\partial k}\\\\ & = a \\sqrt{\\frac{\\kappa}{m}}\\cos\\left(\\frac{ka}{2}\\right) \\frac{\\sin(ka/2)}{|\\sin(ka/2)|} \\end{align}\\] What is the relationship between the group velocity \\(v_g\\) and the density of states \\(g(\\omega)\\) ? Use this to calculate \\(g(\\omega)\\) The relationship is \\[ g(\\omega) = \\frac{L}{\\pi} \\left|\\frac{1}{v_g}\\right| \\] into which the equation from part (i) can be inserted: \\[\\begin{align} g(\\omega) & = \\frac{L}{a \\pi} \\sqrt{\\frac{m}{\\kappa}}\\frac{1}{\\cos(ka/2)}\\\\ & = \\frac{L}{a \\pi} \\sqrt{\\frac{m}{\\kappa}}\\frac{1}{\\sqrt{1-\\sin^2(ka/2)}}\\\\ & = \\frac{2L}{a \\pi} \\frac{1}{\\sqrt{4\\kappa / m - \\omega^2}} \\end{align}\\] Sketch or plot both \\(v_g\\) and \\(g(\\omega)\\) The group velocity is shown below and was produced using the following code: fig , ax = plt . subplots () k = np . linspace ( - np . pi + 0.01 , np . pi - 0.01 , 300 ) ax . plot ( k [ 0 : 149 ], np . sin ( k [ 0 : 149 ]) / ( np . sqrt ( 1 - np . cos ( k [ 0 : 149 ]))), color = 'C0' ); ax . plot ( k [ 150 : 300 ], np . sin ( k [ 150 : 300 ]) / ( np . sqrt ( 1 - np . cos ( k [ 150 : 300 ]))), color = 'C0' ); ax . set_title ( 'Group velocity' ) ax . set_xlabel ( r '$k$' ); ax . set_ylabel ( '$v(k)$' ); plt . xticks ([ - np . pi , 0 , np . pi ], [ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); plt . yticks ([ - np . sqrt ( 2 ), 0 , np . sqrt ( 2 )], [ r '$-2\\sqrt{\\frac{\\kappa} {m} }$' , 0 , r '$2\\sqrt{\\frac{\\kappa} {m} }$' ]); plt . tight_layout (); plt . savefig ( 'A3-1-v.pdf' , facecolor = 'white' , transparent = False ) plt . show () The density of states is shown below and was produced using the (near identical) code: fig , ax = plt . subplots () w = np . linspace ( 0 , 0.95 , 300 ); g = 1 / np . sqrt ( 1 - w ** 2 ); ax . plot ( w , g , 'C0' ); ax . set_xlabel ( r '$\\omega$' ); ax . set_ylabel ( '$g(\\omega)$' ); ax . set_title ( 'Density of states' ) plt . xticks ([ 0 , 1 ], [ 0 , r '$2\\sqrt{\\frac {k}{m} }$' ]); plt . yticks ([ 0.5 , 1 ], [ 0 , r '$\\frac {L} {2\\pi a}\\sqrt{\\frac{\\kappa} {m} }$' ]); plt . tight_layout (); plt . savefig ( 'A3-1-dos.pdf' , facecolor = 'white' , transparent = False ) plt . show () Consider the dispersion curve below: Sketch the group velocity \\(v_g(k)\\) One needs to sketch the derivative, which could be done by hand or computationally with the code to compute and plot the derivative shown below: k = k_vals [ 1 ] - k_vals [ 0 ] y = nn ( k_vals ) gradient = np . gradient ( y , dk ) fig , ax = plt . subplots () ax . plot ( k_vals [ k_vals < 0 ], gradient [ k_vals < 0 ], 'C0' ); ax . plot ( k_vals [ k_vals > .1 ], gradient [ k_vals > .1 ], 'C0' ); ax . set_xlabel ( r '$k$' ); ax . set_ylabel ( r '$\\frac{\\partial\\omega}{\\partial k}$' ); ax . set_xlim ( - 2 , 2 ) ax . set_title ( 'Group velocity' ) plt . xticks ([ - np . pi / a , 0 , np . pi / a ], [ r '$-\\pi/a$' , 0 , r '$\\pi/a$' ]); plt . tight_layout (); plt . savefig ( 'A3-1-gv.pdf' , facecolor = 'white' , transparent = False ) plt . show () Produce a visualisation (e.g. a plot or histogram) of the density of states \\(g(\\omega)\\) A histogram well displays the density of states which can be compute using the following code: k_dos = np . linspace ( 0 , np . pi / a , 25 ) # dk value (2\\pi/L) # Make the band plot fig , ( ax , ax2 ) = plt . subplots ( ncols = 2 , sharey = True , figsize = ( 12 , 5 )) ax . plot ( k_vals , nn ( k_vals )); ax . vlines ( k_dos , 0 , nn ( k_dos ), colors = ( 0.5 , 0.5 , 0.5 , 0.5 )) ax . hlines ( np . hstack ( nn ( k_dos )), np . hstack ( k_dos ), np . pi / a , colors = ( 0.5 , 0.5 , 0.5 , 0.5 ) ) ax . set_xlabel ( '$k$' ) ax . set_ylabel ( r '$\u03c9$' ) ax . set_xticks ([ 0 , np . pi / 2 ]) ax . set_xticklabels ([ '$0$' , r '$\\pi/a$' ]) ax . set_yticks ([]) ax . set_yticklabels ([]) ax . set_xlim ( - 0.05 , max ( k ) + .05 ) k = np . linspace ( 0 , np . pi , 1000 ) omegas = nn ( k ) ax2 . hist ( omegas , orientation = 'horizontal' , bins = 75 ) ax2 . set_xlabel ( r '$g(\u03c9)$' ) ax2 . set_xticks ([]) plt . savefig ( 'A3-1-4-dos.pdf' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show ()","title":"Exercise 1 - Dispersion"},{"location":"solutions/assignment3/#exercise-2-normal-modes-of-a-one-dimensional-diatomic-chain","text":"What is the difference between an acoustic mode and optical mode? Describe the motion of atoms in the unit cell for long wavelength oscillations. In acoustic waves, the dispersion goes to zero and \\(k\\) and \\(\\omega \\sim k\\) for small \\(k\\) , whereas optical modes have an intercept with \\(\\omega = c k\\) where \\(c\\) is the speed of light. In the acoustic case, all atoms in a unit cell move in-phase with a slow spatial modulation, whereas in the optical case, adjacent atoms move out of phase with one another. Derive the dispersion relation for the longitudinal oscillations of a one-dimensional diatomic mass-and-spring crystal with unit cell length \\(a\\) and where each unit cell contains one atom of mass \\(m_1\\) and one atom of mass \\(m_2\\) connected by a spring with spring constant \\(\\kappa\\) . From the image, we write the position of the \\(n^{\\textrm{th}}\\) particle with mass \\(m_1\\) as \\(x_n\\) and the position of the \\(n^{\\textrm{th}}\\) particle with mass \\(m_2\\) as \\(y_n\\) . We assume that the equilibrium position of \\(x_n\\) is \\(n a\\) and the equilibrium position is \\(n a + d\\) . We then write the equations of motion for the deviations from the equilibrium positions as \\(\\delta x_n\\) and \\(\\delta y_n\\) \\[ \\begin{aligned} &m_{1} \\ddot{\\delta x}_{n} \\quad=-\\kappa\\left(\\delta x_{n}-\\delta y_{n-1}\\right)-\\kappa\\left(\\delta x_{n}-\\delta y_{n}\\right) \\\\ &m_{2} \\dot{\\delta} y_{n}=-\\kappa\\left(\\delta y_{n}-\\delta x_{n}\\right)-\\kappa\\left(\\delta y_{n}-\\delta x_{n+1}\\right) \\end{aligned} \\] We then assume solutions of the form \\[ \\begin{aligned} \\delta x_{n} &=A_{x} e^{i k a n-i \\omega t} \\\\ \\delta y_{n} &=A_{y} e^{i k a n-i \\omega t} \\end{aligned} \\] from which we obtain the equations \\[ \\begin{aligned} -m_{1} \\omega^{2} A_{x} e^{i k n a} &=-2 \\kappa A_{x} e^{i k n a}+\\kappa A_{y}\\left(e^{i k n a}+e^{i k(n-1) a}\\right) \\\\ -m_{2} \\omega^{2} A_{y} e^{i k n a} &=-2 \\kappa A_{y} e^{i k n a}+\\kappa A_{x}\\left(e^{i k n a}+e^{i k(n+1) a}\\right) \\end{aligned} \\] which simplify to \\[ \\begin{aligned} \\omega^{2} A_{x} &=2\\left(\\kappa / m_{1}\\right) A_{x}-\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) A_{y} \\\\ \\omega^{2} A_{y} &=2\\left(\\kappa / m_{2}\\right) A_{y}-\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) A_{x} \\end{aligned} \\] which defines an eigenvalue problem for \\(\\omega^2\\) . Therefore we must find the roots of the determinant \\[ \\left|\\begin{array}{cc} 2\\left(\\kappa / m_{1}\\right)-\\omega^{2} & -\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) \\\\ -\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) & 2\\left(\\kappa / m_{2}\\right)-\\omega^{2} \\end{array}\\right| \\] which yields the equation \\[ \\begin{aligned} &0=\\omega^{4}-\\omega^{2}\\left(2 \\kappa\\left(1 / m_{1}+1 / m_{2}\\right)\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}\\left(4-\\left(1+e^{i k a}\\right)\\left(1+e^{-i k a}\\right)\\right) \\\\ &\\left.0=\\omega^{4}-\\omega^{2}\\left(\\frac{2\\left(m_{1}+m_{2}\\right) \\kappa}{m_{1} m_{2}}\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}(2-2 \\cos (k a))\\right) \\end{aligned} \\] and ultimately \\[ \\begin{aligned} \\omega^{2} &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) \\\\ &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{\\left(m_{1}+m_{2}\\right)^{2}-4 m_{1} m_{2} \\sin ^{2}(k a / 2)}\\right) \\end{aligned} \\] Determine the frequencies of the acoustic and optical modes at \\(k=0\\) and at the Brillouin zone boundary At \\(k=0\\) , \\(\\cos(ka)=1\\) and therefore the acoustic mode has zero energy whereas the optical mode has energy \\[ \\omega = \\sqrt{\\frac{2\\kappa(m_1+m_2)}{m_1 m_2}} \\] At the Brilllouin zone boundary, \\(\\cos(ka)=-1\\) and so the energies of the two modes are \\[ \\omega = \\sqrt{\\frac{2\\kappa(m_1)}{m_1 m_2}} \\quad \\sqrt{\\frac{2\\kappa(m_2)}{m_1 m_2}} \\] Determine the sound velocity, and show that the group velocity is zero at the zone boundary () To find the sound velocity, one must expand around \\(k=0\\) for the acoustic mode and then one end with an equation of the from \\(\\omega = v k\\) with \\[ v = a \\sqrt{\\frac{\\kappa}{2(m_1 + m_2)}} \\] The group velocity \\(v_g\\) is given by \\(\\mathrm{d}\\omega/\\mathrm{k}\\) and whilst the form of \\(\\omega\\) is a bit ugly, if we write \\(f = \\omega^2\\) , we are interested in the derivative of the function \\(g = f^{1/2}\\) . So by the chain rule, \\[ \\frac{\\mathrm{d}g}{\\mathrm{k}} = \\frac{\\mathrm{d}g}{\\mathrm{d}f} \\frac{\\mathrm{d}f}{\\mathrm{d}k} \\] which means \\[ v_g = \\frac{1}{2}\\frac{1}{f^{1/2}} \\frac{\\mathrm{d}f}{\\mathrm{d}k}. \\] Now \\(f\\) is well behaved around \\(k = \\pm\\pi/a\\) , so we only need look at \\(\\frac{\\mathrm{d}f}{\\mathrm{d}k}\\) . Again, \\(f\\) is a bit ugly, but is essentially \\[ f = c_1 \\pm \\sqrt{c_2 + c_3 \\cos(k a)} \\] with constants \\(c_i\\) , and therefore, once again using the chain rule \\[ \\mathrm{d}f/\\mathrm{d}k \\sim \\pm \\frac{c_4 \\sin(k a)}{\\sqrt{c_2 + c_3 \\cos(k a)}} \\] which goes to zero for \\(k = \\pi/a\\) and therefore \\(v_g \\rightarrow 0\\) Sketch or plot the dispersion in both the reduced and extended zone scheme The dispersion in the reduced zone scheme: The dispersion in the extended zone scheme: The above plots were computed using the code below: Much code # Define a function to return the dispersion def dispersion_diatomic ( k , kappa = 1 , m1 = 2 , m2 = 1 , acoustic = True ): cons = m1 + m2 sq = np . sqrt (( cons ** 2 ) - ( 4 * m1 * m2 * np . sin ( k * a / 2 ) ** 2 )) if acoustic : sq *= - 1 return np . sqrt ( kappa / ( m1 * m2 ) * ( cons + sq ) / m ) scale = 3 # Set the sclae for plotting past the Brillouin zone a = 2 # Set the lattice constant brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # k values in the Brillouin zone ks = brillouin * scale # k values further afield - obviously less well sampled kappa = 1 # Plot the dispersion fig , ax = plt . subplots () ax . plot ( brillouin , dispersion_diatomic ( brillouin ), color = 'C0' , label = 'Acoustic' ) ax . plot ( brillouin , dispersion_diatomic ( brillouin , acoustic = False ), color = 'C1' , label = 'Optical' ) ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundary xvals = [ - np . pi / a , np . pi / a ] for v in xvals : ax . axvline ( x = v , color = 'black' ) offset = 0.3 if v < 0 : sign = '-' elif v > 0 : sign = '+' offset = - offset # Label the Brillouin range ax . text ( v + offset , .1 , f '$k = { sign } \\pi/a$' , horizontalalignment = 'center' , fontsize = 16 ) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$\\omega$' ) ax . set_xlim ( 1.1 * min ( xvals ), 1.1 * max ( xvals )) plt . legend ( bbox_to_anchor = ( .5 , - .125 ), loc = 'lower center' , ncol = 2 ) draw_classic_axes ( ax ) plt . savefig ( 'A3-2-brillouin.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () # Make arrays for the first and second Brillouin zones # first Bz brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # second Bz # You may be tempted to have a single array here, but if you do this, your plot will be ugly! # Verify this for yourself: you will find the function \"numpy.concatenate\" useful. first_ex = np . linspace ( - 2 * np . pi / a , - np . pi / a , 250 ) second_ex = np . flip ( first_ex * - 1 ) # Plot the Brillouin zones fig , ax = plt . subplots () ax . plot ( brillouin , dispersion_diatomic ( brillouin ), color = 'C0' , label = 'acoustic' ) ax . plot ( first_ex , dispersion_diatomic ( first_ex , acoustic = False ), color = 'C1' , label = 'optical' ) ax . plot ( second_ex , dispersion_diatomic ( second_ex , acoustic = False ), color = 'C1' ) # Only use one label to avoid double-tagging ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundaries - this is painfully manual xvals = [ - 2 * np . pi / a , - np . pi / a , np . pi / a , 2 * np . pi / a ] for n , v in enumerate ( xvals ): ax . axvline ( x = v , color = 'black' , linestyle = '--' ) offset = 0.3 if v < 0 : sign = '-' if n == 0 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' elif v > 0 : sign = '+' offset = - offset if n == 3 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' # Label the Brillouin range text ax . text ( v + offset , .1 , text , horizontalalignment = 'center' , fontsize = 16 ) omega_plus = np . sqrt ( 2 * kappa / m ) omega_minus = np . sqrt ( 2 * kappa / 2 * m ) gap = ( omega_plus + omega_minus ) / 2 # Band gap for arrows # Label the 1st Bz ax . text ( 0 , gap - offset / 2 , '1st Brillouin zone' , horizontalalignment = 'center' , fontsize = 16 ) ax . annotate ( text = '' , xy = ( - np . pi / a , gap ), xytext = ( np . pi / a , gap ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) # Label the 2nd Bz (<0) ax . text ( - 3 * np . pi / ( 2 * a ), gap + 1.75 * offset , '2nd Brillouin \\n zone' , horizontalalignment = 'center' , fontsize = 16 ) ax . annotate ( text = '' , xy = ( - 2 * np . pi / a , gap - .1 ), xytext = ( - np . pi / a , gap - .1 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) # Label the 2nd Bz(>0) ax . text ( 3 * np . pi / ( 2 * a ), gap + 1.75 * offset , '2nd Brillouin \\n zone' , horizontalalignment = 'center' , fontsize = 16 ) ax . annotate ( text = '' , xy = ( np . pi / a , gap - .1 ), xytext = ( 2 * np . pi / a , gap - .1 ), arrowprops = dict ( arrowstyle = '<->' , shrinkA = 0 , shrinkB = 0 )) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$\\omega$' ) ax . set_title ( 'Extended zone scheme' ); plt . legend ( bbox_to_anchor = ( .5 , - .25 ), loc = 'lower center' , ncol = 2 ) plt . savefig ( 'A3-2-extended.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Assuming that there are \\(N\\) unit cells, how many different normal modes are there? And how many branches of excitation are there? If there are \\(N\\) unit cells, therefore \\(2N\\) atoms, there are \\(2N\\) modes. As there are 2 modes for \\(k\\) in the reduced zone scheme, there are two branches What happens when m_1 = m_2 When the masses as equal, the unit cell is now of size \\(a/2\\) to the Brillouin zone is double in size, and the gap between the branches vanishes, and the system looks identical to the monatomic chain (the image from the extended zone scheme works well here)","title":"Exercise 2 - Normal modes of a one-dimensional diatomic chain"},{"location":"solutions/assignment3/#exercise-3-diatomic-tight-binding-chain","text":"We have seen the both the diatomic chain and the tight-binding chain, so we are going to combine the two. Consider the system shown below Suppose that the onsite energy of atom \\(A\\) is different for atom \\(B\\) , that is \\(\\langle n | H | n \\rangle = \\epsilon_A\\) for | n \\rangle being on site \\(A\\) and \\(\\langle n | H | n \\rangle = \\epsilon_B\\) for \\(| n \\rangle\\) being on site \\(B\\) . We assume that the hopping \\(-t\\) is unchanged from the monatomic case. Derive the dispersion curve for electrons The unit cell \\(a\\) is the distance from an \\(A\\) atom to another \\(A\\) atom. Let \\(\\phi_n^A\\) be the amplitude of the wavefunction on the \\(n^{\\mathrm{th}}\\) site of type \\(A\\) and \\(\\phi_n^B\\) be the amplitude of the wavefunction on the \\(n^{\\mathrm{th}}\\) site of type \\(B\\) . We assume a trial wavefunction of the form \\[ | \\psi \\rangle = \\sum_n (\\phi_n^A + \\phi_n^B) | \\psi \\rangle \\] and put this into the Schr\u00f6dinger equation and find an effective Schr\u00f6dinger equation of the form \\[ \\begin{aligned} E \\phi_{n}^{A} &=\\epsilon_{A} \\phi_{n}^{A}-t\\left(\\phi_{n}^{B}+\\phi_{n-1}^{B}\\right) \\\\ E \\phi_{n}^{B} &=\\epsilon_{B} \\phi_{n}^{B}-t\\left(\\phi_{n}^{A}+\\phi_{n+1}^{A}\\right) \\end{aligned} \\] Assuming solutions of the form \\[ \\begin{aligned} \\phi_{n}^{A} &=A e^{i k n a} \\\\ \\phi_{n}^{B} &=B e^{i k n a} \\end{aligned} \\] gives \\[ \\begin{aligned} E A &=\\epsilon_{A} A-t\\left(1+e^{-i k a}\\right) B \\\\ E B &=\\epsilon_{B} B-t\\left(1+e^{i k a}\\right) A \\end{aligned} \\] again giving a \\(2 \\times 2\\) eigenvalue problem. We solve for the roots of the determinant \\[ \\left|\\begin{array}{cc} \\epsilon_{A}-E & -t\\left(1+e^{-i k a}\\right) \\\\ -t\\left(1+e^{i k a}\\right) & \\epsilon_{B}-E \\end{array}\\right| \\] which givens the equation \\[ 0=E^{2}-E\\left(\\epsilon_{A}+\\epsilon_{B}\\right)+\\left(\\epsilon_{A} \\epsilon_{B}-t^{2}(2+2 \\cos (k a))\\right) \\] \\[ E_{\\pm}(k)=\\frac{1}{2}\\left(\\epsilon_{A}+\\epsilon_{B} \\pm \\sqrt{\\left(\\epsilon_{A}-\\epsilon_{B}\\right)^{2}+4 t^{2}(2+2 \\cos (k a))}\\right) \\] Sketch or plot the above dispersion relation in both the reduced and extended zone schemes The dispersion in the reduced zone scheme: The dispersion in the extended zone scheme: The above plots were computed using the code below: Very code def energy ( k , ea = 5 , eb = 3 , t = 1 , low = True ): const = ea - eb sqrt = np . sqrt ( const ** 2 + 4 * t ** 2 * ( 2 + 2 * np . cos ( k * a ))) if low : sqrt *= - 1 return 1 / 2 * ( ea + eb + sqrt ) scale = 3 # Set the sclae for plotting past the Brillouin zone a = 2 # Set the lattice constant brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # k values in the Brillouin zone ks = brillouin * scale # k values further afield - obviously less well sampled # Plot the dispersion fig , ax = plt . subplots () ax . plot ( brillouin , energy ( brillouin ), color = 'C0' , label = 'Low E' ) ax . plot ( brillouin , energy ( brillouin , low = False ), color = 'C1' , label = 'High E' ) ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundary xvals = [ - np . pi / a , np . pi / a ] for v in xvals : ax . axvline ( x = v , color = 'black' ) offset = 0.3 if v < 0 : sign = '-' elif v > 0 : sign = '+' offset = - offset # Label the Brillouin range ax . text ( v + offset , 2 , f '$k = { sign } \\pi/a$' , horizontalalignment = 'center' , fontsize = 16 ) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$E$' ) ax . set_xlim ( 1.1 * min ( xvals ), 1.1 * max ( xvals )) plt . legend ( bbox_to_anchor = ( .5 , - .25 ), loc = 'lower center' , ncol = 2 ) plt . savefig ( 'A3-3-brillouin.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () # Make arrays for the first and second Brillouin zones # first Bz brillouin = np . linspace ( - np . pi / a , np . pi / a , 500 ) # second Bz # You may be tempted to have a single array here, but if you do this, your plot will be ugly! # Verify this for yourself: you will find the function \"numpy.concatenate\" useful. first_ex = np . linspace ( - 2 * np . pi / a , - np . pi / a , 250 ) second_ex = np . flip ( first_ex * - 1 ) # Plot the Brillouin zones fig , ax = plt . subplots () ax . plot ( brillouin , energy ( brillouin ), color = 'C0' , label = 'Low E' ) ax . plot ( first_ex , energy ( first_ex , low = False ), color = 'C1' , label = 'High E' ) ax . plot ( second_ex , energy ( second_ex , low = False ), color = 'C1' ) # Only use one label to avoid double-tagging ## The labelling is very tedious, there is little value to be found here # Plot and annotate the Brillouin zone boundaries - this is painfully manual xvals = [ - 2 * np . pi / a , - np . pi / a , np . pi / a , 2 * np . pi / a ] for n , v in enumerate ( xvals ): ax . axvline ( x = v , color = 'black' , linestyle = '--' ) offset = 0.3 if v < 0 : sign = '-' if n == 0 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' elif v > 0 : sign = '+' offset = - offset if n == 3 : text = f '$ { sign } $' + r '$\\frac{2\\pi} {a} $' else : n = text = f '$ { sign } $' + r '$\\frac{\\pi} {a} $' # Label the Brillouin range text ax . text ( v + offset , 1.75 , text , horizontalalignment = 'center' , fontsize = 16 ) # Make the plot pretty ax . set_xlabel ( '$k$' ) ax . set_ylabel ( '$\\omega$' ) ax . set_title ( 'Extended zone scheme' ); plt . legend ( bbox_to_anchor = ( .5 , - .25 ), loc = 'lower center' , ncol = 2 ) plt . savefig ( 'A3-3-extended.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () What is the effective mass of an electron near the bottom of the lower band? To find the effective mass, we expand the energy around the minimum which gives \\[ E= \\mathrm{ constant }+\\frac{2 t^{2}(k a)^{2}}{\\sqrt{\\left(\\epsilon_{A}-\\epsilon_{B}\\right)^{2}+16 t^{2}}} \\] which set equal to \\(\\hbar^2 k^2 / (2m^*)\\) and find \\[ m^{*}=\\frac{\\hbar^{2} \\sqrt{\\left(\\epsilon_{A}-\\epsilon_{B}\\right)^{2}+16 t^{2}}}{4 t^{2} a^{2}} \\] If each atom ( \\(A\\) and \\(B\\) ) are monovalent, is the system a conductor or insulator? Justify your response If each atom is monovalent, there are now two electrons per unit cell, and this fills exactly the lower band and therefore the system is insulating. Consider the material LiF, and use the above results to justify why it is observed to be an excellent insulator. For LiF we can expect a much lower energy for electrons on F than on Li (F has a large electron affinity, Li has a low ionization energy). So we can set \\(\\epsilon_A \\ll \\epsilon_B\\) . What happens in this limit is that the bands are extremely far apart \u2013 thus a very good insulator. If you are really keen, one can look at the eigenvectors in the lower band, and one will find that they are almost completely on the lower energy atoms. Thus the free electron is transferred almost completely from the higher to the lower energy atom.","title":"Exercise 3 - Diatomic tight binding chain"},{"location":"solutions/assignment4/","text":"Assignment 4: Crystals \u00b6 The fourth assignment can be found here Exercise 1 - Two-dimensional crystal structure \u00b6 Consider the following two-dimensional diatomic crystal: Sketch the Wigner-Seitz unit cell and two other possible primitive unit cells of the crystal An example of two possible primitive primative cells are shown below, along with the Wigner-Seitz cell, which is unique. If the distance between the filled circles is \\(a=2.8\\mathrm{\\unicode{x212B}}\\) , what is the area of the primitive unit cell? How would this area change if all the empty circles and the filled circles were identical? The area of the primitive unit cell is \\(A = a^2\\) . If the filled and empty circles are identical particle, the nearest neighbour distance becomes \\(a^* = \\frac{a}{\\sqrt{2}}\\) and thus the area \\(A^* = {a^*}^2 = \\frac{a^2}{2} = \\frac{A}{2}\\) . Write down one set of primitive lattice vectors and the basis for this crystal. What happens to the number of elements in the basis if all empty and filled circles were identical? One set of primitive lattice vectors is \\[ \\mathbf{a_1} = a \\hat{\\mathbf{x}}, \\quad \\mathbf{a_2} = a \\hat{\\mathbf{y}}. \\] With respect to the primitive lattice vectors, the basis is \\[ \\huge \\bullet ~ \\normalsize[0,0], \\quad \\bigcirc ~ [\\frac{1}{2},\\frac{1}{2}] \\] If all atoms were identical, then the basis only has one element (and consequently the PLVs above would cease to be PLVs) Imagine expanding the lattice into the perpendicular direction \\(z\\) . We can define a new three-dimensional crystal by considering a periodic structure in the \\(z\\) direction, where the filled circles have been displaced by \\(\\frac{a}{2}\\) in both the \\(x\\) and \\(y\\) direction from the empty circles. The figure below shows the new arrangement of the atoms. What lattice do we obtain? Write down the basis of the three-dimensional crystal. The lattice is a cubic lattice and the basis of the crystal is \\[ \\huge \\bullet \\normalsize ~ [0,0,0], \\quad \\bigcirc ~ \\left[\\frac{1}{2},\\frac{1}{2},\\frac{1}{2}\\right]. \\] An example of such a material is Caesium Chloride (CsCl). Exercise 2 - Three-dimensional crystal structure \u00b6 The image below shows the three dimensional structure of zincblende (ZnS) (zinc atoms are yellow, sulphur atoms are grey). How many atoms are in the unit cell? Corner atoms 8 \\times 1/8 + face atoms ( \\(6 \\times 1/2\\) ) + interior atoms ( \\(4 \\times 1\\) ) = \\(1 + 3 + 4 = 8\\) Draw the plan view of the unit cell Identify the lattice type of zincblende The lattice type is Face-centred cubic (FCC) Describe the basis for zincblende The basis can be described as Zn at [0,0,0] and S at [1/4, 1/4, 1/4] Given the unit cell length \\(a=5.41\\mathrm{\\unicode{x212B}}\\) , calculate the nearest-neighbour Zn-Zn, Zn-S, and S-S distances This is just geometry: Zn-Zn is \\(a/\\sqrt{2} = 3.83\\mathrm{\\unicode{x212B}}\\) , Zn-S is \\(a\\sqrt{1/4^2 + 1/4^2 + 1/4^2} = 2.34 \\mathrm{\\unicode{x212B}}\\) , and S-S is \\(a/\\sqrt{2} = 3.83\\mathrm{\\unicode{x212B}}\\) . Exercise 3 - Filing factor \u00b6 Consider a lattice with a sphere at each lattice point, and choose the radius of the spheres to be such that neighbouring spheres just touch. The filling factor (or packing fraction) is the fraction of the volume of all of space which is enclosed by the union of all the spheres (i.e. the ratio of the volume of the spheres to the total volume). Calculate the packing fraction for a simple cubic lattice The volume of a conventional unit cell is \\(V = a^3\\) . Each cell corresponds to a single sphere, and the radius of this sphere is \\(a/2\\) so the volume of the sphere is \\(V_s = 4\\pi/3 \\times (a/2)^3\\) . Therefore the packing fraction \\(V_s/V = \\pi/6 \\approx 0.52\\) Calculate the packing fraction for a BCC lattice The volume of a conventional unit cell is \\(V = a^3\\) . Each conventional cell contains two lattice points which are a distance \\(a\\sqrt{3}/2\\) apart, thus the radius of each sphere is \\(a\\sqrt{3}/4\\) so the volume of the sphere is \\(V_s = 4\\pi/3 \\times (a\\sqrt{3}/4)^3\\) . Therefore the packing fraction \\(2V_s/V = \\pi\\sqrt{3}/8 \\approx 0.68\\) Calculate the packing fraction for an FCC lattice The volume of a conventional unit cell is \\(V = a^3\\) . Each conventional cell contains four lattice points which are a distance \\(a\\sqrt{2}/2\\) apart, thus the radius of each sphere is \\(a\\sqrt{2}/4\\) so the volume of the sphere is \\(V_s = 4\\pi/3 \\times (a\\sqrt{2}/4)^3\\) . Therefore the packing fraction \\(4V_s/V = \\pi/(3\\sqrt{2}) \\approx 0.74\\) Exercise 4 - Reciprocal lattice \u00b6 Show that the reciprocal lattice of a FCC lattice is a BCC lattice. Correspondingly, show that the reciprocal lattice of a BCC lattice is an FCC lattice The BCC has primitive lattice vectors \\[ \\begin{aligned} &\\mathbf{a}_{1}=[1,0,0] ~ a \\\\ &\\mathbf{a}_{2}=[0,1,0] ~ a \\\\ &\\mathbf{a}_{3}=[1 / 2,1 / 2,1 / 2] ~ a \\end{aligned} \\] from which we can construct primitive lattice vectors for the reciprocal lattice via \\[ \\mathbf{b}_{i}=\\frac{2 \\pi \\mathbf{a}_{j} \\times \\mathbf{a}_{k}}{\\mathbf{a}_{1} \\cdot \\mathbf{a}_{2} \\times \\mathbf{a}_{3}} \\] which gives \\[\\begin{equation} \\begin{aligned} \\mathbf{b}_{1} &= (1 / 2,0,-1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{2} &= (0,1 / 2,-1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{3} &= (0,0,1) ~ \\frac{4 \\pi}{a} \\end{aligned} \\end{equation}\\] and they themselves can be transformed into the standard PLVs via \\[ \\begin{aligned} \\mathbf{b}_{1}^{\\prime} &=\\mathbf{b}_{1}+\\mathbf{b}_{3} & = &(1 / 2,0,1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{2}^{\\prime} &=\\mathbf{b}_{2}+\\mathbf{b}_{3} & = &(0,1 / 2,1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{3}^{\\prime} &=\\mathbf{b}_{1}+\\mathbf{b}_{2}+\\mathbf{b}_{3} & = &(1 / 2,1 / 2,0) ~ \\frac{4 \\pi}{a} \\end{aligned} \\] which is fine since we are making integer additions of PLVs. If an FCC lattice has conventional unit cell with lattice constant \\(a\\) , what is the lattice constant for the conventional unit cell of the reciprocal BCC lattice? From above, we can see that the lattice constant is \\(4\\pi/a\\) Consider now an orthorhombic face-centred lattice with conventional lattice constants \\(a_1, a_2, a_3\\) . What is the reciprocal lattice now? Everything from above still holds, except one would have basis vectors scaled to \\(4\\pi/a_i\\)","title":"Assignment 4: Crystals"},{"location":"solutions/assignment4/#assignment-4-crystals","text":"The fourth assignment can be found here","title":"Assignment 4: Crystals"},{"location":"solutions/assignment4/#exercise-1-two-dimensional-crystal-structure","text":"Consider the following two-dimensional diatomic crystal: Sketch the Wigner-Seitz unit cell and two other possible primitive unit cells of the crystal An example of two possible primitive primative cells are shown below, along with the Wigner-Seitz cell, which is unique. If the distance between the filled circles is \\(a=2.8\\mathrm{\\unicode{x212B}}\\) , what is the area of the primitive unit cell? How would this area change if all the empty circles and the filled circles were identical? The area of the primitive unit cell is \\(A = a^2\\) . If the filled and empty circles are identical particle, the nearest neighbour distance becomes \\(a^* = \\frac{a}{\\sqrt{2}}\\) and thus the area \\(A^* = {a^*}^2 = \\frac{a^2}{2} = \\frac{A}{2}\\) . Write down one set of primitive lattice vectors and the basis for this crystal. What happens to the number of elements in the basis if all empty and filled circles were identical? One set of primitive lattice vectors is \\[ \\mathbf{a_1} = a \\hat{\\mathbf{x}}, \\quad \\mathbf{a_2} = a \\hat{\\mathbf{y}}. \\] With respect to the primitive lattice vectors, the basis is \\[ \\huge \\bullet ~ \\normalsize[0,0], \\quad \\bigcirc ~ [\\frac{1}{2},\\frac{1}{2}] \\] If all atoms were identical, then the basis only has one element (and consequently the PLVs above would cease to be PLVs) Imagine expanding the lattice into the perpendicular direction \\(z\\) . We can define a new three-dimensional crystal by considering a periodic structure in the \\(z\\) direction, where the filled circles have been displaced by \\(\\frac{a}{2}\\) in both the \\(x\\) and \\(y\\) direction from the empty circles. The figure below shows the new arrangement of the atoms. What lattice do we obtain? Write down the basis of the three-dimensional crystal. The lattice is a cubic lattice and the basis of the crystal is \\[ \\huge \\bullet \\normalsize ~ [0,0,0], \\quad \\bigcirc ~ \\left[\\frac{1}{2},\\frac{1}{2},\\frac{1}{2}\\right]. \\] An example of such a material is Caesium Chloride (CsCl).","title":"Exercise 1 - Two-dimensional crystal structure"},{"location":"solutions/assignment4/#exercise-2-three-dimensional-crystal-structure","text":"The image below shows the three dimensional structure of zincblende (ZnS) (zinc atoms are yellow, sulphur atoms are grey). How many atoms are in the unit cell? Corner atoms 8 \\times 1/8 + face atoms ( \\(6 \\times 1/2\\) ) + interior atoms ( \\(4 \\times 1\\) ) = \\(1 + 3 + 4 = 8\\) Draw the plan view of the unit cell Identify the lattice type of zincblende The lattice type is Face-centred cubic (FCC) Describe the basis for zincblende The basis can be described as Zn at [0,0,0] and S at [1/4, 1/4, 1/4] Given the unit cell length \\(a=5.41\\mathrm{\\unicode{x212B}}\\) , calculate the nearest-neighbour Zn-Zn, Zn-S, and S-S distances This is just geometry: Zn-Zn is \\(a/\\sqrt{2} = 3.83\\mathrm{\\unicode{x212B}}\\) , Zn-S is \\(a\\sqrt{1/4^2 + 1/4^2 + 1/4^2} = 2.34 \\mathrm{\\unicode{x212B}}\\) , and S-S is \\(a/\\sqrt{2} = 3.83\\mathrm{\\unicode{x212B}}\\) .","title":"Exercise 2 - Three-dimensional crystal structure"},{"location":"solutions/assignment4/#exercise-3-filing-factor","text":"Consider a lattice with a sphere at each lattice point, and choose the radius of the spheres to be such that neighbouring spheres just touch. The filling factor (or packing fraction) is the fraction of the volume of all of space which is enclosed by the union of all the spheres (i.e. the ratio of the volume of the spheres to the total volume). Calculate the packing fraction for a simple cubic lattice The volume of a conventional unit cell is \\(V = a^3\\) . Each cell corresponds to a single sphere, and the radius of this sphere is \\(a/2\\) so the volume of the sphere is \\(V_s = 4\\pi/3 \\times (a/2)^3\\) . Therefore the packing fraction \\(V_s/V = \\pi/6 \\approx 0.52\\) Calculate the packing fraction for a BCC lattice The volume of a conventional unit cell is \\(V = a^3\\) . Each conventional cell contains two lattice points which are a distance \\(a\\sqrt{3}/2\\) apart, thus the radius of each sphere is \\(a\\sqrt{3}/4\\) so the volume of the sphere is \\(V_s = 4\\pi/3 \\times (a\\sqrt{3}/4)^3\\) . Therefore the packing fraction \\(2V_s/V = \\pi\\sqrt{3}/8 \\approx 0.68\\) Calculate the packing fraction for an FCC lattice The volume of a conventional unit cell is \\(V = a^3\\) . Each conventional cell contains four lattice points which are a distance \\(a\\sqrt{2}/2\\) apart, thus the radius of each sphere is \\(a\\sqrt{2}/4\\) so the volume of the sphere is \\(V_s = 4\\pi/3 \\times (a\\sqrt{2}/4)^3\\) . Therefore the packing fraction \\(4V_s/V = \\pi/(3\\sqrt{2}) \\approx 0.74\\)","title":"Exercise 3 - Filing factor"},{"location":"solutions/assignment4/#exercise-4-reciprocal-lattice","text":"Show that the reciprocal lattice of a FCC lattice is a BCC lattice. Correspondingly, show that the reciprocal lattice of a BCC lattice is an FCC lattice The BCC has primitive lattice vectors \\[ \\begin{aligned} &\\mathbf{a}_{1}=[1,0,0] ~ a \\\\ &\\mathbf{a}_{2}=[0,1,0] ~ a \\\\ &\\mathbf{a}_{3}=[1 / 2,1 / 2,1 / 2] ~ a \\end{aligned} \\] from which we can construct primitive lattice vectors for the reciprocal lattice via \\[ \\mathbf{b}_{i}=\\frac{2 \\pi \\mathbf{a}_{j} \\times \\mathbf{a}_{k}}{\\mathbf{a}_{1} \\cdot \\mathbf{a}_{2} \\times \\mathbf{a}_{3}} \\] which gives \\[\\begin{equation} \\begin{aligned} \\mathbf{b}_{1} &= (1 / 2,0,-1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{2} &= (0,1 / 2,-1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{3} &= (0,0,1) ~ \\frac{4 \\pi}{a} \\end{aligned} \\end{equation}\\] and they themselves can be transformed into the standard PLVs via \\[ \\begin{aligned} \\mathbf{b}_{1}^{\\prime} &=\\mathbf{b}_{1}+\\mathbf{b}_{3} & = &(1 / 2,0,1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{2}^{\\prime} &=\\mathbf{b}_{2}+\\mathbf{b}_{3} & = &(0,1 / 2,1 / 2) ~ \\frac{4 \\pi}{a} \\\\ \\mathbf{b}_{3}^{\\prime} &=\\mathbf{b}_{1}+\\mathbf{b}_{2}+\\mathbf{b}_{3} & = &(1 / 2,1 / 2,0) ~ \\frac{4 \\pi}{a} \\end{aligned} \\] which is fine since we are making integer additions of PLVs. If an FCC lattice has conventional unit cell with lattice constant \\(a\\) , what is the lattice constant for the conventional unit cell of the reciprocal BCC lattice? From above, we can see that the lattice constant is \\(4\\pi/a\\) Consider now an orthorhombic face-centred lattice with conventional lattice constants \\(a_1, a_2, a_3\\) . What is the reciprocal lattice now? Everything from above still holds, except one would have basis vectors scaled to \\(4\\pi/a_i\\)","title":"Exercise 4 - Reciprocal lattice"},{"location":"solutions/assignment5/","text":"Assignment 5: the reciprocal lattice and scattering \u00b6 The fifth assignment can be found here Exercise 1 - The reciprocal lattice \u00b6 Following the normal conventions, let us denote \\(\\mathbf{a}_i\\) and \\(\\mathbf{b}_i\\) as the real-space and reciprocal space lattice vectors. A construction of lattice vectors can be achieved using the relation \\mathbf{b}_i = 2\\pi \\frac{\\mathbf{a}_j \\times \\mathbf{a}_k}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} Explicitly compute \\(\\mathbf{a}_1 \\cdot \\mathbf{b}_1\\) , \\(\\mathbf{a}_2 \\cdot \\mathbf{b}_1\\) , and \\(\\mathbf{a}_3 \\cdot \\mathbf{b}_1\\) . Do these computations accord with the definition of the reciprocal lattice? The computation of these vectors is aided by knowledge of properties of the scalar triple product . In calculating the product: \\[ \\mathbf{a}_i \\cdot \\mathbf{b}_1 = 2\\pi \\frac{\\mathbf{a}_i \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} \\] it should be immediately obvious that \\(\\mathbf{a}_2 \\times \\mathbf{a}_3\\) is orthogonal to both \\(\\mathbf{a}_2\\) and \\(\\mathbf{a}_3\\) , so the dot product between \\(\\mathbf{a}_2\\) and \\(\\mathbf{a}_3\\) will be zero. In the case of \\(\\mathbf{a}_1\\) , we then have identical vector products on both numerator and denominator and therefore the product evaluates to \\(2\\pi\\) . The construction of the reciprocal lattice is baser around the identity \\[ e^{i\\mathbf{G}\\cdot\\mathbf{R}} = 1 \\] for any lattice point \\(\\mathbf{R}\\) and any reciprocal lattice point \\(\\mathbf{G}\\) . That relation only holds when \\[ \\mathbf{a}_i \\cdot \\mathbf{b}_j = 2\\pi \\delta_{ij} \\] and hence our relations above are looking good. The volume of a primitive unit cell with lattice vectors \\(\\mathbf{a}_i\\) is given by \\(V = \\left|\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3) \\right|\\) . Find the volume of the corresponding primitive unit cell in reciprocal space. The volume in reciprocal space \\(V'\\) should be computed using the same method as provided: \\[ \\begin{align} V' & = \\left|\\mathbf{b}_1 \\cdot (\\mathbf{b}_2 \\times \\mathbf{b}_3) \\right| \\\\ & = 2\\pi \\left| \\frac{(\\mathbf{a}_2 \\times \\mathbf{a}_3)}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} \\cdot (\\mathbf{b}_2 \\times \\mathbf{b}_3) \\right| \\\\ & = \\frac{2\\pi}{V}\\left| (\\mathbf{a}_2 \\times \\mathbf{a}_3) \\cdot (\\mathbf{b}_2 \\times \\mathbf{b}_3) \\right| \\\\ & = \\frac{2\\pi}{V}\\left| (\\mathbf{a}_2 \\cdot \\mathbf{b}_2)(\\mathbf{a}_3 \\cdot \\mathbf{b}_3) - ( \\mathbf{a}_2 \\cdot \\mathbf{b}_3)( \\mathbf{a}_3 \\cdot \\mathbf{b}_2) \\right| \\\\ & = \\frac{(2\\pi)^3}{V} \\end{align} \\] Show that the general direction \\([hkl]\\) in a cubic crystal is normal to the planes with Miller indices \\((hkl)\\) . Consider a (real-space) lattice with basis vectors \\(\\mathbf{a}\\) , \\(\\mathbf{b}\\) , and \\(\\mathbf{c}\\) which are assumed orthogonal (cubic crystal). Let the lengths of these vectors be \\(a\\) , \\(b\\) , and \\(c\\) respectively. The plane \\((hkl)\\) will have intercepts with the axes at (a/h, 0, 0), (0, b/k, 0), (0, 0, c/l), and from these 3 points, one can construct a vector normal to the plane (which defines the plane) by taking the cross products between any two vectors between the points above. For example, consider \\[ \\begin{align} \\mathbf{n} & = (\\mathbf{a}/h - \\mathbf{b}/k) \\times (\\mathbf{a}/h - \\mathbf{c}/k) \\\\ & = \\frac{abc}{hkl} \\left( \\frac{h}{a^2}\\mathbf{a} + \\frac{k}{b^2}\\mathbf{b} + \\frac{l}{c^2}\\mathbf{c} \\right) \\end{align} \\] and this is only parallel to the vector \\([hkl]\\) in the case of \\(a = b = c\\) . Is the above statement true for an orthorhombic crystal? Justify your response. No, it is not true, see the question above! Show that the distance between two adjacent Miller planes \\((hkl)\\) of any lattice is \\(d=2\\pi/|\\mathbf{G}_{\\textrm{min}}|\\) , where \\(\\mathbf{G}_{\\textrm{min}}\\) is the shortest reciprocal lattice vector perpendicular to these Miller planes. The unit vector normal to the plane can be computed via \\[ \\hat{\\mathbf{n}} = \\frac{\\mathbf{G}}{|\\mathbf{G}|}. \\] Let us consider a very simple case in which we have the miller planes \\((h00)\\) . For lattice planes, there is always a plane intersecting the zero lattice point \\((0,0,0)\\) . As such, the distance from this plane to the closest next one is given by \\[ d = \\hat{\\mathbf{n}} \\cdot \\frac{\\mathbf{a_1}}{h} = \\frac{2\\pi}{|\\mathbf{G}|} \\] Find the family of Miller planes of the BCC lattice that has the highest density of lattice points. It may of useful to think about the density of lattice points per unit area on a Miller plane which is given by \\(\\rho=d/V\\) . Since \\(\\rho=d/V\\) , to maximise \\(\\rho\\) me must either must maximize \\(d\\) or minimise \\(V\\) , the latter of which is fixed. Therefore, to maximise \\(d\\) , we minimize must \\(|\\mathbf{G}|\\) and thus the smallest possible reciprocal lattice vectors are the (100) family of planes (in terms of FCC primitive lattice vectors). Exercise 2 - Lattice planes \u00b6 In assignment four, you looked at the structure of zincblende (ZnS) (zinc atoms are yellow, sulphur atoms are grey). Draw a simplified plan view (don't worry about indicating heights) down the [001] axis, and indicate the [210] direction and the (210) family of planes The plan, planes and reciprocal lattice vector are shown below: The confidence tester: explain why the family of planes above is or is not a family of lattice planes. If it is a family of lattice planes, do nothing and be content with your decision If it is not a family of lattice planes, what would be a family of lattice planes in the same direction? The lattice type is a Face-centred cubic (FCC), and clearly the lattice planes do capture all atoms, and thus the spacing must be decreased, or the reciprocal lattice vector doubled, so (420) would define a family of lattice planes. Exercise 3 - Scattering \u00b6 What is the origin of the Laue condition? That is, why is the amplitude of a scattered wave zero if \\(\\mathbf{k'} - \\mathbf{k} \\ne \\mathbf{G}\\) ? If \\(\\mathbf{k'} - \\mathbf{k} \\ne \\mathbf{G}\\) , then the argument of the exponent has a phase factor dependent on the real-space lattice points. Because we sum over each of these lattice points, each argument has a different phase. Summing over all these phases results in an average amplitude of 0, resulting in no intensity peaks. Consider a two-dimensional crystal with a rectangular lattice and lattice vectors \\(\\mathbf{a}_1 = (0.468, 0) \\mathrm{nm}\\) and \\(\\mathbf{a}_2 = (0, 0.342) \\mathrm{nm}\\) (so that \\(\\mathbf{a}_1\\) points along \\(x\\) -axis and \\(\\mathbf{a}_2\\) points along \\(y\\) -axis) Sketch the reciprocal lattice of this crystal Consider an X-ray diffraction experiment performed on this crystal using monochromatic X-rays with wavelength \\(0.166\\mathrm{nm}\\) . Assuming elastic scattering, find the magnitude of the wave vectors of the incident and reflected X-rays With elastic scattering, we have \\(|k| = |k'| = 2\\pi\\lambda = 37.9 \\mathrm{nm^{-1}}\\) On your sketch of the reciprocal lattice, draw the \"scattering triangle\" corresponding to the diffraction from (210) planes. Explicitly, use the Laue condition \\(\\Delta \\mathbf{k} = \\mathbf{G}\\) for constructive interference of diffracted X-rays Exercise 4 - Diffraction and structure \u00b6 Compute the structure factor \\(S\\) of the BCC lattice The structure factor \\(S(\\mathbf{G})\\) is given by \\[ \\sum_j f_j e^{i\\mathbf{G} \\cdot \\mathbf{r}_j} \\] where the sum over \\(j\\) is the atoms in the unit cell. We can write this explicitly as \\[ \\sum_j f_j e^{2\\pi i hu_j + kv_j + lw_j} f_j \\] where \\((hkl)\\) are the miller indices of \\(\\mathbf{G}\\) and \\([u_j, v_j, w_j]\\) are the positions of atom \\(j\\) in the unit cell. To compute this, we write a BCC lattice as a simple cubic with a basis [0,0,0] and [1/2, 1/2, 1/2], and therefore we get the structure factor \\[ \\begin{align} S & = f_{\\textrm{Cr}} + f_{\\textrm{Cr}} e^{2\\pi i(h/2 + k/2 + l/2)} \\\\ & = f_{\\textrm{Cr}}\\left(1 + (-1)^{h+k+l}\\right) \\end{align} \\] Which diffraction peaks are missing? From above, it is clear that the structure vanishes whenever \\(h+k+l\\) is odd, and we can write \\[ S = \\left\\{ \\begin{array}{ll} 2f_{\\textrm{Cr}} \\quad h+k+l~\\textrm{even} \\\\ 0 \\quad h+k+l~\\textrm{odd} \\end{array} \\right. \\] How does this structure factor change if the atoms in the centre of the conventional unit cell have a different form factor from the atoms at the corner of the conventional unit cell? If we write the atomic form factors of the different atoms \\(f_1\\) and \\(f_2\\) \\[ S = \\left\\{ \\begin{array}{ll} f_1 + f_2 \\quad h+k+l~\\textrm{even} \\\\ f_1 - f_2 \\quad h+k+l~\\textrm{odd} \\end{array} \\right. \\] A student carried out X-ray powder diffraction on chromium (Cr) which is known to have a BCC structure, and the first five diffraction peaks are given below. Delightfully, the student took the liberty of assigning Miller indices to the peaks. Were the peaks assigned correctly? Fix any mistakes and explain your reasoning. The values of \\((hkl)\\) must satisfy the selection rules above, which means that the peaks should be \\((110), (200), (211), (220), (310)\\) from lowest angle to highest angle. The X-ray diffraction was carried out using Cu \\(K_\\alpha\\) radiation ( \\(\\lambda = 1.5406 \\mathrm{\\unicode{x212B}}\\) ). Use this information to calculate the lattice constant \\(a\\) of the chromium BCC unit cell, and provide an estimate for uncertainty of this value. To calculate the lattice spacing, one must use the relations that for a given lattice spacing \\(d_{(h,k,l)}\\) , the Bragg condition holds: \\[ d_{(h,k,l)} = \\frac{\\lambda}{2 \\sin\\theta} \\] In a cubic lattice, one also has the relation that \\[ d_{(h,k,l)} = \\frac{a}{\\sqrt{h^2 + k^2 + l^2}} \\] so then the lattice constant \\(a\\) can be calculated through \\[ a = \\frac{\\lambda\\sqrt{h^2 + k^2 + l^2}}{2 \\sin\\theta} \\] One can the calculate a value for each angle (and Miller index) to return a list of lattice constants, from which a range an uncertainty can be derived. I have just used the mean and standard deviation - no weighted means, no uncertainty in peak location, just raw statistical deviation from my very rough extraction of the scattering angle. lamb = 1.5406 #[\\unicode{x212B}] def lat ( h , k , l , t ): return ( np . sqrt ( h ** 2 + k ** 2 + l ** 2 ) * lamb ) / ( 2 * np . sin ( t )) angles = np . array ([ 44 , 63 , 81 , 97 , 113 ]) miller = np . array ([[ 1 , 1 , 0 ], [ 2 , 0 , 0 ], [ 2 , 1 , 1 ], [ 2 , 2 , 0 ], [ 3 , 1 , 0 ]]) touse = [] for ( n , p ) in enumerate ( miller ): touse . append ( np . append ( p , np . deg2rad ( angles [ n ] / 2 ))) avals = [] for d in touse : avals . append ( lat ( * d )) print ( f \"The lattice spacing was determined to be { np . mean ( avals ) : .3f } with a standard deviation of { np . std ( avals ) : .3f } \" ) My result was \\(a = 2.918 \\pm 0.016 \\mathrm{\\unicode{x212B}}\\)","title":"Assignment 5: the reciprocal lattice and scattering"},{"location":"solutions/assignment5/#assignment-5-the-reciprocal-lattice-and-scattering","text":"The fifth assignment can be found here","title":"Assignment 5: the reciprocal lattice and scattering"},{"location":"solutions/assignment5/#exercise-1-the-reciprocal-lattice","text":"Following the normal conventions, let us denote \\(\\mathbf{a}_i\\) and \\(\\mathbf{b}_i\\) as the real-space and reciprocal space lattice vectors. A construction of lattice vectors can be achieved using the relation \\mathbf{b}_i = 2\\pi \\frac{\\mathbf{a}_j \\times \\mathbf{a}_k}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} Explicitly compute \\(\\mathbf{a}_1 \\cdot \\mathbf{b}_1\\) , \\(\\mathbf{a}_2 \\cdot \\mathbf{b}_1\\) , and \\(\\mathbf{a}_3 \\cdot \\mathbf{b}_1\\) . Do these computations accord with the definition of the reciprocal lattice? The computation of these vectors is aided by knowledge of properties of the scalar triple product . In calculating the product: \\[ \\mathbf{a}_i \\cdot \\mathbf{b}_1 = 2\\pi \\frac{\\mathbf{a}_i \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} \\] it should be immediately obvious that \\(\\mathbf{a}_2 \\times \\mathbf{a}_3\\) is orthogonal to both \\(\\mathbf{a}_2\\) and \\(\\mathbf{a}_3\\) , so the dot product between \\(\\mathbf{a}_2\\) and \\(\\mathbf{a}_3\\) will be zero. In the case of \\(\\mathbf{a}_1\\) , we then have identical vector products on both numerator and denominator and therefore the product evaluates to \\(2\\pi\\) . The construction of the reciprocal lattice is baser around the identity \\[ e^{i\\mathbf{G}\\cdot\\mathbf{R}} = 1 \\] for any lattice point \\(\\mathbf{R}\\) and any reciprocal lattice point \\(\\mathbf{G}\\) . That relation only holds when \\[ \\mathbf{a}_i \\cdot \\mathbf{b}_j = 2\\pi \\delta_{ij} \\] and hence our relations above are looking good. The volume of a primitive unit cell with lattice vectors \\(\\mathbf{a}_i\\) is given by \\(V = \\left|\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3) \\right|\\) . Find the volume of the corresponding primitive unit cell in reciprocal space. The volume in reciprocal space \\(V'\\) should be computed using the same method as provided: \\[ \\begin{align} V' & = \\left|\\mathbf{b}_1 \\cdot (\\mathbf{b}_2 \\times \\mathbf{b}_3) \\right| \\\\ & = 2\\pi \\left| \\frac{(\\mathbf{a}_2 \\times \\mathbf{a}_3)}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} \\cdot (\\mathbf{b}_2 \\times \\mathbf{b}_3) \\right| \\\\ & = \\frac{2\\pi}{V}\\left| (\\mathbf{a}_2 \\times \\mathbf{a}_3) \\cdot (\\mathbf{b}_2 \\times \\mathbf{b}_3) \\right| \\\\ & = \\frac{2\\pi}{V}\\left| (\\mathbf{a}_2 \\cdot \\mathbf{b}_2)(\\mathbf{a}_3 \\cdot \\mathbf{b}_3) - ( \\mathbf{a}_2 \\cdot \\mathbf{b}_3)( \\mathbf{a}_3 \\cdot \\mathbf{b}_2) \\right| \\\\ & = \\frac{(2\\pi)^3}{V} \\end{align} \\] Show that the general direction \\([hkl]\\) in a cubic crystal is normal to the planes with Miller indices \\((hkl)\\) . Consider a (real-space) lattice with basis vectors \\(\\mathbf{a}\\) , \\(\\mathbf{b}\\) , and \\(\\mathbf{c}\\) which are assumed orthogonal (cubic crystal). Let the lengths of these vectors be \\(a\\) , \\(b\\) , and \\(c\\) respectively. The plane \\((hkl)\\) will have intercepts with the axes at (a/h, 0, 0), (0, b/k, 0), (0, 0, c/l), and from these 3 points, one can construct a vector normal to the plane (which defines the plane) by taking the cross products between any two vectors between the points above. For example, consider \\[ \\begin{align} \\mathbf{n} & = (\\mathbf{a}/h - \\mathbf{b}/k) \\times (\\mathbf{a}/h - \\mathbf{c}/k) \\\\ & = \\frac{abc}{hkl} \\left( \\frac{h}{a^2}\\mathbf{a} + \\frac{k}{b^2}\\mathbf{b} + \\frac{l}{c^2}\\mathbf{c} \\right) \\end{align} \\] and this is only parallel to the vector \\([hkl]\\) in the case of \\(a = b = c\\) . Is the above statement true for an orthorhombic crystal? Justify your response. No, it is not true, see the question above! Show that the distance between two adjacent Miller planes \\((hkl)\\) of any lattice is \\(d=2\\pi/|\\mathbf{G}_{\\textrm{min}}|\\) , where \\(\\mathbf{G}_{\\textrm{min}}\\) is the shortest reciprocal lattice vector perpendicular to these Miller planes. The unit vector normal to the plane can be computed via \\[ \\hat{\\mathbf{n}} = \\frac{\\mathbf{G}}{|\\mathbf{G}|}. \\] Let us consider a very simple case in which we have the miller planes \\((h00)\\) . For lattice planes, there is always a plane intersecting the zero lattice point \\((0,0,0)\\) . As such, the distance from this plane to the closest next one is given by \\[ d = \\hat{\\mathbf{n}} \\cdot \\frac{\\mathbf{a_1}}{h} = \\frac{2\\pi}{|\\mathbf{G}|} \\] Find the family of Miller planes of the BCC lattice that has the highest density of lattice points. It may of useful to think about the density of lattice points per unit area on a Miller plane which is given by \\(\\rho=d/V\\) . Since \\(\\rho=d/V\\) , to maximise \\(\\rho\\) me must either must maximize \\(d\\) or minimise \\(V\\) , the latter of which is fixed. Therefore, to maximise \\(d\\) , we minimize must \\(|\\mathbf{G}|\\) and thus the smallest possible reciprocal lattice vectors are the (100) family of planes (in terms of FCC primitive lattice vectors).","title":"Exercise 1 - The reciprocal lattice"},{"location":"solutions/assignment5/#exercise-2-lattice-planes","text":"In assignment four, you looked at the structure of zincblende (ZnS) (zinc atoms are yellow, sulphur atoms are grey). Draw a simplified plan view (don't worry about indicating heights) down the [001] axis, and indicate the [210] direction and the (210) family of planes The plan, planes and reciprocal lattice vector are shown below: The confidence tester: explain why the family of planes above is or is not a family of lattice planes. If it is a family of lattice planes, do nothing and be content with your decision If it is not a family of lattice planes, what would be a family of lattice planes in the same direction? The lattice type is a Face-centred cubic (FCC), and clearly the lattice planes do capture all atoms, and thus the spacing must be decreased, or the reciprocal lattice vector doubled, so (420) would define a family of lattice planes.","title":"Exercise 2 - Lattice planes"},{"location":"solutions/assignment5/#exercise-3-scattering","text":"What is the origin of the Laue condition? That is, why is the amplitude of a scattered wave zero if \\(\\mathbf{k'} - \\mathbf{k} \\ne \\mathbf{G}\\) ? If \\(\\mathbf{k'} - \\mathbf{k} \\ne \\mathbf{G}\\) , then the argument of the exponent has a phase factor dependent on the real-space lattice points. Because we sum over each of these lattice points, each argument has a different phase. Summing over all these phases results in an average amplitude of 0, resulting in no intensity peaks. Consider a two-dimensional crystal with a rectangular lattice and lattice vectors \\(\\mathbf{a}_1 = (0.468, 0) \\mathrm{nm}\\) and \\(\\mathbf{a}_2 = (0, 0.342) \\mathrm{nm}\\) (so that \\(\\mathbf{a}_1\\) points along \\(x\\) -axis and \\(\\mathbf{a}_2\\) points along \\(y\\) -axis) Sketch the reciprocal lattice of this crystal Consider an X-ray diffraction experiment performed on this crystal using monochromatic X-rays with wavelength \\(0.166\\mathrm{nm}\\) . Assuming elastic scattering, find the magnitude of the wave vectors of the incident and reflected X-rays With elastic scattering, we have \\(|k| = |k'| = 2\\pi\\lambda = 37.9 \\mathrm{nm^{-1}}\\) On your sketch of the reciprocal lattice, draw the \"scattering triangle\" corresponding to the diffraction from (210) planes. Explicitly, use the Laue condition \\(\\Delta \\mathbf{k} = \\mathbf{G}\\) for constructive interference of diffracted X-rays","title":"Exercise 3 - Scattering"},{"location":"solutions/assignment5/#exercise-4-diffraction-and-structure","text":"Compute the structure factor \\(S\\) of the BCC lattice The structure factor \\(S(\\mathbf{G})\\) is given by \\[ \\sum_j f_j e^{i\\mathbf{G} \\cdot \\mathbf{r}_j} \\] where the sum over \\(j\\) is the atoms in the unit cell. We can write this explicitly as \\[ \\sum_j f_j e^{2\\pi i hu_j + kv_j + lw_j} f_j \\] where \\((hkl)\\) are the miller indices of \\(\\mathbf{G}\\) and \\([u_j, v_j, w_j]\\) are the positions of atom \\(j\\) in the unit cell. To compute this, we write a BCC lattice as a simple cubic with a basis [0,0,0] and [1/2, 1/2, 1/2], and therefore we get the structure factor \\[ \\begin{align} S & = f_{\\textrm{Cr}} + f_{\\textrm{Cr}} e^{2\\pi i(h/2 + k/2 + l/2)} \\\\ & = f_{\\textrm{Cr}}\\left(1 + (-1)^{h+k+l}\\right) \\end{align} \\] Which diffraction peaks are missing? From above, it is clear that the structure vanishes whenever \\(h+k+l\\) is odd, and we can write \\[ S = \\left\\{ \\begin{array}{ll} 2f_{\\textrm{Cr}} \\quad h+k+l~\\textrm{even} \\\\ 0 \\quad h+k+l~\\textrm{odd} \\end{array} \\right. \\] How does this structure factor change if the atoms in the centre of the conventional unit cell have a different form factor from the atoms at the corner of the conventional unit cell? If we write the atomic form factors of the different atoms \\(f_1\\) and \\(f_2\\) \\[ S = \\left\\{ \\begin{array}{ll} f_1 + f_2 \\quad h+k+l~\\textrm{even} \\\\ f_1 - f_2 \\quad h+k+l~\\textrm{odd} \\end{array} \\right. \\] A student carried out X-ray powder diffraction on chromium (Cr) which is known to have a BCC structure, and the first five diffraction peaks are given below. Delightfully, the student took the liberty of assigning Miller indices to the peaks. Were the peaks assigned correctly? Fix any mistakes and explain your reasoning. The values of \\((hkl)\\) must satisfy the selection rules above, which means that the peaks should be \\((110), (200), (211), (220), (310)\\) from lowest angle to highest angle. The X-ray diffraction was carried out using Cu \\(K_\\alpha\\) radiation ( \\(\\lambda = 1.5406 \\mathrm{\\unicode{x212B}}\\) ). Use this information to calculate the lattice constant \\(a\\) of the chromium BCC unit cell, and provide an estimate for uncertainty of this value. To calculate the lattice spacing, one must use the relations that for a given lattice spacing \\(d_{(h,k,l)}\\) , the Bragg condition holds: \\[ d_{(h,k,l)} = \\frac{\\lambda}{2 \\sin\\theta} \\] In a cubic lattice, one also has the relation that \\[ d_{(h,k,l)} = \\frac{a}{\\sqrt{h^2 + k^2 + l^2}} \\] so then the lattice constant \\(a\\) can be calculated through \\[ a = \\frac{\\lambda\\sqrt{h^2 + k^2 + l^2}}{2 \\sin\\theta} \\] One can the calculate a value for each angle (and Miller index) to return a list of lattice constants, from which a range an uncertainty can be derived. I have just used the mean and standard deviation - no weighted means, no uncertainty in peak location, just raw statistical deviation from my very rough extraction of the scattering angle. lamb = 1.5406 #[\\unicode{x212B}] def lat ( h , k , l , t ): return ( np . sqrt ( h ** 2 + k ** 2 + l ** 2 ) * lamb ) / ( 2 * np . sin ( t )) angles = np . array ([ 44 , 63 , 81 , 97 , 113 ]) miller = np . array ([[ 1 , 1 , 0 ], [ 2 , 0 , 0 ], [ 2 , 1 , 1 ], [ 2 , 2 , 0 ], [ 3 , 1 , 0 ]]) touse = [] for ( n , p ) in enumerate ( miller ): touse . append ( np . append ( p , np . deg2rad ( angles [ n ] / 2 ))) avals = [] for d in touse : avals . append ( lat ( * d )) print ( f \"The lattice spacing was determined to be { np . mean ( avals ) : .3f } with a standard deviation of { np . std ( avals ) : .3f } \" ) My result was \\(a = 2.918 \\pm 0.016 \\mathrm{\\unicode{x212B}}\\)","title":"Exercise 4 - Diffraction and structure"},{"location":"solutions/assignment6/","text":"Assignment 6: Waves in three-dimensional solids and applications \u00b6 The first assignment can be found here Exercise 1 - Structure determination \u00b6 A diffraction experiment with an unknown crystalline powder sample was performed using a tungsten X-ray tube. Tungsten has \\(K_{\\alpha}\\) emission lines \\(K_{\\alpha_1} = 59 318.8\\mathrm{eV}\\) and \\(K_{\\alpha_2} = 57 981.9\\mathrm{eV}\\) , and the ratio of intensities of the emissions lines is \\(\\alpha_2/\\alpha_1 \\approx 0.115\\) . Explain how X-ray tubes produce X-rays, and describe how one would go about performing a powder diffraction experiment. This is a more detailed response than I would expect, but for a complete picutre: in an X-ray tube, electrons are emitted from the filament and accelerated towards the anode, and two forms of radiation are produced from the interaction between the electrons and the anode. The first kind is Bremsstrahlung radiation, which will be emitted as the electron is decelerated by the atomic nuclei of the anode. The emission spectrum is continuous, with the approximate shape described by Kramers' Law: \\[ I(\\lambda)d\\lambda = K \\left(\\frac{\\lambda}{\\lambda_{\\textrm{min}}}-1\\right)\\frac{1}{\\lambda^2}d\\lambda \\] where the cutoff wavelength, \\(\\lambda_{\\textrm{min}}\\) is given by the Duane-Hunt law: \\[ \\lambda_{\\textrm{min}} = \\frac{hc}{eV}. \\] The key point relating to the distribution is that with an increased acceleration voltage, the Bremsstrahlung radiation intensity increases and shifts towards higher frequencies. The second kind of radiation is the characteristic X-ray emission, which occurs when a high-lying electron decays to a (vacant) lower energy level, resulting in the emission of a photon. The bombardment of the anode by energetic electrons results in the emission of inner-shell electrons from the atoms in the anode. Such vacancies are filled by the decay of outer-shell electrons and due to the unique energy structure of each element, each atom emits photons of distinct frequencies, completely analogous to atomic optical spectra. The combination of these effects means that the expected emission spectrum would expect a smooth, continuous spectrum punctuated by emissions of characteristic X-rays. Powder diffraction experiments are performed by placing a crystalline sample in powdered form in an X-ray beamline and collecting the scattered radiation from the sample. The diffraction pattern will by design form rings rather than spots, as every possible crystal orientation is assured by using a powder rather than a monocrystalline sample. A plot of the data measured from the experiment when \\(K_{\\alpha_1}\\) emission was used is shown below: Following the recipe discussed in class, produce a table with columns of angle, plane separation, ratio of the square of first plane separation to plane separation, \\(N = h^2 + k^2 + l^2\\) , \\({hkl}\\) , and \\(a\\) (assuming some kind of cubic lattice) This should be relatively straightforward, given the example we did in class was trickier and the code used to do the analysis was freely distributed. The peaks as found from the data are shown below: Peak finding code peaks , _ = find_peaks ( data [ 'Intensity' ]) fig , ax = plt . subplots () ax . plot ( data [ 'Angle' ], data [ 'Intensity' ] / maxamp , label = r 'W $K_{\\alpha_1}$' , color = 'C0' ) ax . plot ( data [ 'Angle' ][ peaks ], data [ 'Intensity' ][ peaks ] / maxamp , \"x\" , color = 'C1' , label = 'Peaks' ) ax . set_xlabel ( r 'Angle [2$\\theta$]' ) ax . set_xlim (( 19 , 82 )) ax . set_ylabel ( 'Intensity [arb]' ) ax . set_title ( 'X-ray scattering of unknown material' ); plt . legend () loc = matplotlib . ticker . MultipleLocator ( 1 ) ax . xaxis . set_minor_locator ( loc ) ax . tick_params ( which = 'minor' ) if True : plt . savefig ( 'A-6-peaks.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () from which the following data table can be constructed: Peak number \\(2\\theta\\) \\(d~[\\mathrm{pm}]\\) \\(d_a^2/d^2\\) \\(N\\) \\({hkl}\\) \\(a~[\\mathrm{pm}]\\) 1 20.461 58.84 1.00 1 [1, 0, 0] 58.84 2 29.086 41.61 1.99 2 [1, 1, 0] 58.84 3 35.828 33.97 2.99 3 [1, 1, 1] 58.84 4 41.609 29.42 3.99 4 [2, 0, 0] 58.84 5 46.788 26.32 4.99 5 [2, 1, 0] 58.84 6 51.567 24.02 5.99 6 [2, 1, 1] 58.84 7 60.302 20.80 7.99 8 [2, 2, 0] 58.84 8 64.380 19.61 8.99 9 [2, 2, 1] 58.84 9 68.327 18.61 9.99 10 [3, 0, 0] 58.84 10 72.164 17.74 10.99 11 [3, 1, 0] 58.84 11 75.920 16.98 11.99 12 [3, 1, 1] 58.84 12 79.617 16.32 12.99 13 [2, 2, 2] 58.84 The difficulty of finding the multiplier to make all values of \\(d_a^2/d^2\\) an integer is not present in this example, so the process should be straightforward to find \\(a=58.84 \\mathrm{pm}\\) Use the table above to determine the lattice structure of the crystal The lattice is a simple cubic lattice, which can be inferred by the calculated values of N above and the selection rule for simple cubic lattices ( \\(N\\) is all integers excluding \\(7, 15, 23, \\ldots\\) ), and this is directly visible from the diffraction data: peak 7 is clearly missing. The basis of the lattice is given by \\(X = [0,0,0]\\) and \\(Y = [1/2, 1/2, \\beta], [1/2, 1/2, (1 - \\beta)] , [1/2, \\beta, 1/2], [(1 - \\beta), 1/2, 1/2], [1/2, 1/2, \\beta],\\) and \\([(1 - \\beta), 1/2, 1/2]\\) where \\(X\\) and \\(Y\\) are different atomic species, and \\(\\beta \\approx 0.2\\) . Draw the unit cell for the crystal using your lattice and the basis specified above. Below is the crystal structure (many unit cells) and can be well described as a simple cubic with a neat prism inside. The material is \\(\\textrm{LaB}_6\\) , which is the most gorgeous shade of pink, and is a neat material for making hot cathode emitters (electron sources). Explain how the intensity of the peaks could be used to determine \\(\\beta\\) , and obtain an expression for the ratio of the first two diffraction peaks. Note: You do not need to solve this equation for \\(\\beta\\) , just arrive at something that could be used to calculate \\(\\beta\\) . The intensity of the peaks is related to the square (well, modulus squared) of the structure factor \\(S\\) . As we have been using it in class, the structure factor is \\[ S_{(hkl)} = \\sum_\\alpha f_\\alpha e^{i\\mathbf{G}\\cdot\\mathbf{R}_\\alpha} \\] which in reality means that one must compute \\[ S_{(hkl)} = \\sum_\\alpha f_\\alpha e^{2\\pi i(hkl)\\cdot[xyz]_\\alpha} \\] This is not so difficult, but can be a bit tedious depending on the basis of the unit cell. Given we are looking at the intensities of the first two peaks, this means we will need to look at \\(S_{(100)}\\) : \\[ \\begin{aligned} S_{(100)} & = f_\\textrm{X} + f_\\textrm{Y}\\left( e^{i\\pi} + e^{i\\pi} + e^{2\\pi i \\beta} + e^{2\\pi i (1-\\beta)} + e^{i\\pi} + e^{i\\pi} \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( e^{2\\pi i \\beta} + e^{-2\\pi i \\beta} e^{2\\pi i} - 4 \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 2\\cos(2\\pi\\beta) - 4 \\right) \\\\ & = f_\\textrm{X} - 2 f_\\textrm{Y}\\left( 1 + \\sin^2(\\pi\\beta) \\right) \\\\ \\end{aligned} \\] and \\(S_{(110)}\\) : \\[ \\begin{aligned} S_{(110)} & = f_\\textrm{X} + f_\\textrm{Y}\\left( e^{2\\pi i} + e^{2\\pi i} + 2\\left( e^{2\\pi i \\beta}e^{i\\pi} + e^{2\\pi i (1-\\beta)}e^{i\\pi} \\right) \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 2 - 2\\left( e^{2\\pi i \\beta} + e^{-2\\pi i \\beta} e^{2\\pi i} \\right) \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 2 - \\cos(2\\pi\\beta) \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 1 - 2\\sin^2(\\pi\\beta) \\right) \\\\ \\end{aligned} \\] One could then look at the ratio \\(I_{(100)}/I_{(110)} = |S_{(100)}|^2/|S_{(110)}|^2\\) and try and solve for \\(\\beta\\) , but that will be a mess, so one should solve it numerically. The real value is \\(\\beta = 0.1981\\) , although I am not sure exactly what the ratio of \\(I_{(100)}/I_{(110)}\\) would return. Imagine the experiment was altered such that both \\(K_{\\alpha_1}\\) and \\(K_{\\alpha_2}\\) emission lines were present. How would this alter the data as recorded above? Would you expect that one could still uniquely determine the crystal structure of the sample? Shown below is the spectrum with both emission lines: With two emission lines, one would expect to have essentially to diffraction patterns superimposed, but as there is sufficient energy separation between the two emission lines, one can resolve the two peaks (well, in simulated data). The question explicitly states that the ratio of intensities for emission from the different transitions is \\(\\alpha_2/\\alpha_1 \\approx 0.115\\) , meaning the \\(K_{\\alpha_2}\\) peaks will be noticeably smaller. The main point is that there will be two distinct diffraction patterns, and provided one can uniquely distinguish from which emission line the peak comes, one would actually be able to better determine the crystal structure, as one effectively has double the number of peaks. This method is used more broadly, that is, not using monochromatic X-rays but rather polychromatic X-rays in order to get more information per unit diffraction, but one must know well the illuminating radiation. This is usually called \"pink\" beam illumination. Now imagine that the experiment were altered such that only \\(K_{\\alpha_1}\\) radiation were used, but a monocrystalline sample were used. What would be the difference in the recorded diffraction pattern? If one were to use a monocrystalline sample, the diffraction pattern would have distinct Bragg spots rather than rings, but then we need to care much more about crystal orientation (it also usually very difficult to get large monocrystalline samples). The image below shows diffraction from monocrystalline silicon: Unfortunately, the beautiful single crystal was dropped before it could be used, resulting in a sample that is neither amorphous nor monocrystalline, rather something between the two. How would this alter the appearance of the diffraction pattern? With a sample between monocrystalline and amorphous, there are extended regions of order and one can imagine either the Bragg spots blurring out around the optical axis (around \\(\\theta\\) in polar coordinates), or the rings \"sharpening up\", that is still ring-like but with more intensity at the Bragg spots. The image below shows both powder and grain-oriented diffraction from aluminium: Exercise 2 - The nearly-free electron model \u00b6 Consider an electron in a weak periodic potential in one dimension \\(V(X) = V(x+a)\\) . It is natural to write the potential as V(x) = \\sum_G e^{iGx} V_G where the sum is over the reciprocal lattice \\(G = 2\\pi n/a\\) and \\(V_G* = V_{-G}\\) assures the potential \\(V(x)\\) is real. Explain why for k near to a Brillouin zone boundary (such as \\(k\\) near \\(\\pi/a\\) ) the electron wavefunction should be taken to be \\psi = A e^{ikx} + B e^{i(k+G)x} where \\(G\\) is a reciprocal lattice vector such that \\(|k|\\) is close to \\(|k+G|\\) . A periodic lattice can only scatter a wave by a reciprocal lattice vector (Bragg diffraction). In the nearly free electron picture, the scattering perturbation is weak, so that we can treat the scattered wave in perturbation theory. In this case, there is an energy denominator which suppresses mixing of \\(k\\) -vectors which have greatly different unperturbed energies. Thus, the only mixing that can occur is between two states with similar energies that are separated by a reciprocal lattice vector. Degenerate perturbation theory tells us that we should first diagonalize within the degenerate space spanned by only these two eigenstates. We have seen that with the above wavefunction, the energy (that is, the eigenvalues) at this wavevector are given by E = \\frac{\\hbar^2 k^2}{2m} + V_0 \\pm |V_G| where \\(G\\) is chosen such that \\(|k| = |k+G|\\) . Give a qualitative explanation of why these two states are separated in energy by \\(2|V_G|\\) If we consider only the \\(V_{2n\\pi/a}\\) and \\(V_{-2n\\pi/a}\\) Fourier modes of the potential then we have \\(V = 2 V_{2n\\pi/a} \\cos(2n\\pi r/a)\\) . Assuming \\(V_{2n\\pi/a} > 0\\) , then the higher energy state is the \\(\\psi = \\cos(2n\\pi r/a)\\) which puts the maximum amplitude of the wavefunction exactly at the maxima of the potential. Similarly, the lower energy wavefunction is the \\(\\sin(2n\\pi r/a)\\) which has the minimum amplitude of the wavefunction at the maximum of the potential. In the case of \\(V_{2n\\pi /a} < 0\\) the sin is the higher energy wavefunction. Provide a sketch or plot of the energy as a function of \\(k\\) in both the extended and reduced zone schemes. Note that one need not compute \\(E\\) for all \\(k\\) , emphasis should be on the general features of the energy spectrum. These plots below are actually calculated by solving the eigenvalue problem as outlined in the next question for all \\(k\\) (where the perturbation is valid, that is where the term in \\(\\delta k\\) to second order is small compared \\(|V_{2n\\pi/a}|^2\\) ). In the reduced zone scheme, one should have something like: Reduced-zone scheme code # Use colors from the default color cycle default_colors = plt . rcParams [ 'axes.prop_cycle' ] . by_key ()[ 'color' ] blue , orange , * _ = default_colors def energy ( k , V = 1 ): k = ( k + np . pi ) % ( 2 * np . pi ) - np . pi k_vals = k + 2 * np . pi * np . arange ( - 1 , 2 ) h = np . diag ( k_vals ** 2 ) + V * ( 1 - np . identity ( 3 )) return np . linalg . eigvalsh ( h ) energy = np . vectorize ( energy , signature = \"(),()->(m)\" ) fig , ax = plt . subplots ( 1 , 1 ) momenta = np . linspace ( - np . pi , np . pi , 400 ) energies = energy ( momenta , 0 ) max_en = 41 energies [ energies > max_en ] = np . nan ax . plot ( momenta , energies , c = blue , label = 'Free electron' ) energies = energy ( momenta , 2 ) max_en = 41 energies [ energies > max_en ] = np . nan ax . plot ( momenta , energies , c = orange , label = 'Nearly free electron' ) ax . set_xlabel ( \"$ka$\" ) ax . set_ylabel ( \"$E$\" ) ax . set_ylim ( - .5 , max_en + 5 ) ax . set_xticks ( np . pi * np . arange ( - 1 , 2 )) ax . set_xticklabels ( r \"$-\\pi$ $0$ $\\pi$\" . split ()) def legend_without_duplicate_labels ( ax ): handles , labels = ax . get_legend_handles_labels () unique = [( h , l ) for i , ( h , l ) in enumerate ( zip ( handles , labels )) if l not in labels [: i ]] ax . legend ( * zip ( * unique )) legend_without_duplicate_labels ( ax ) if True : plt . savefig ( 'A-6-reduced.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Whereas in the extended zone scheme, one should have: Extended-zone scheme code fig , ax = plt . subplots ( 1 , 1 ) momenta = np . linspace ( - 3 * np . pi , 3 * np . pi , 400 ) energies = energy ( momenta , 0 ) max_en = 41 energies [ energies > max_en ] = np . nan energies [ ~ (( abs ( momenta ) // np . pi ) . reshape ( - 1 , 1 ) == np . arange ( 3 ) . reshape ( 1 , - 1 ))] = np . nan ax . plot ( momenta , energies , c = blue , label = 'Free electron' ) energies = energy ( momenta , 2 ) max_en = 41 energies [ energies > max_en ] = np . nan energies [ ~ (( abs ( momenta ) // np . pi ) . reshape ( - 1 , 1 ) == np . arange ( 3 ) . reshape ( 1 , - 1 ))] = np . nan ax . plot ( momenta , energies , c = orange , label = 'Nearly free electron' ) ax . set_xlabel ( \"$ka$\" ) ax . set_ylabel ( \"$E$\" ) ax . set_ylim ( - .5 , max_en + 5 ) ax . set_xticks ( np . pi * np . arange ( - 3 , 4 )) ax . set_xticklabels ( fr \"$ { i } \\pi$\" . replace ( \"1\" , \"\" ) if i else \"$0$\" for i in range ( - 3 , 4 )) legend_without_duplicate_labels ( ax ) if True : plt . savefig ( 'A-6-extended.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Let us look at the case where \\(k\\) is not at the Brillouin zone boundary, but rather close to the boundary. Following the same method as used to achieve the above result, show that at the point \\(k = n\\pi/a + \\delta k\\) the energy to second order in \\(\\delta k\\) is given by E_{\\pm}=\\frac{\\hbar^{2}(n \\pi / a)^{2}}{2 m}+V_{0} \\pm\\left|V_{2 n \\pi / a}\\right|+\\frac{\\hbar^{2}(\\delta k)^{2}}{2 m}\\left(1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}\\right) Technically the wavefunction should have a normalisation \\[ \\psi = (A e^{ikx} + B e^{i(k+G)x})/\\sqrt{L} \\] but it is rarely the case that one is actually probing for normalisation compliance, and in any case, to maintain normalization we can insist that \\(|A|^2 + |B|^2 = 1\\) . Taking \\(k\\) and \\(k+G\\) both on a Brillouin zone boundary we have \\(k = n\\pi/a\\) and \\(k+G = -n\\pi/a\\) , where here we have chosen the \\(n^{\\textrm{th}}\\) zone boundary, and we must have \\(G = -2n\\pi/a\\) the reciprocal lattice vector. The Hamiltonian \\(H\\) in question is the usual Kinetic term plus \\(V(x)\\) . From here, one can either use the variational method or diagonalise the Hamiltonian the degenerate space, the latter of which was done in class and is done here. We must compute the matrix elements: \\[ \\begin{aligned} \\langle k|H| k\\rangle &=\\hbar^{2}(\\delta k+n \\pi / a)^{2} /(2 m)+V_{0} \\\\ \\langle k+G|H| k+G\\rangle &=\\hbar^{2}(\\delta k-n \\pi / a)^{2} /(2 m)+V_{0} \\\\ \\langle k|H| k+G\\rangle &=V_{2 n \\pi / a} \\\\ \\langle k+G|H| k\\rangle &=V_{-2 n \\pi / a} \\end{aligned} \\] which means that me must diagonalise the matrix \\[ \\left(\\begin{array}{cc} \\hbar^{2}(\\delta k+n \\pi / a)^{2} /(2 m)+V_{0} & V_{2 n \\pi / a} \\\\ V_{-2 n \\pi / a} & \\hbar^{2}(\\delta k-n \\pi / a)^{2} /(2 m)+V_{0} \\end{array}\\right). \\] Performing the diagonalisation, one finds \\[ E_{\\pm}=\\frac{\\hbar^{2}\\left[(\\delta k)^{2}+(n \\pi / a)^{2}\\right]}{2 m}+V_{0} \\pm \\sqrt{\\left[\\frac{\\hbar^{2} 2(\\delta k) n \\pi / a}{2 m}\\right]^{2}+\\left|V_{2 n \\pi / a}\\right|^{2}} \\] and the square root should be expanded and the common terms in \\(\\delta k\\) collected to obtain the result \\[ E_{\\pm}=\\frac{\\hbar^{2}(n \\pi / a)^{2}}{2 m}+V_{0} \\pm\\left|V_{2 n \\pi / a}\\right|+\\frac{\\hbar^{2}(\\delta k)^{2}}{2 m}\\left(1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}\\right) \\] as required. Calculate the effective mass of an electron at this wavevector The effective mass can be obtained from \\[ \\frac{1}{2m^*} = \\frac{1}{2m}\\left(1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}\\right) \\] or equivalently \\[ m^{*}=\\left|\\frac{m}{1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}}\\right| \\] Exercise 3 - Fermi surfaces \u00b6 Consider a tight binding model of atoms on a (two-dimensional) square lattice where each atom has a single atomic orbital. If these atoms are monovalent, describe the shape of the Fermi surface. The dispersion of the tight binding model is given by \\[ \\epsilon_{k_x, k_y} = -2t \\left( \\cos(k_x a) + \\cos(k_y a) \\right) \\] and a plot of the dispersion is shown below Fermi surface code from matplotlib import cm from mpl_toolkits.mplot3d import Axes3D # Axes3D import has side effects, it enables using projection='3d' in add_subplot a = 1 t = 2 def ep ( kx , ky ): return - 2 * t * ( np . cos ( kx * a ) + np . cos ( ky * a )) fig = plt . figure () ax = fig . add_subplot ( 111 , projection = '3d' ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.05 ) X , Y = np . meshgrid ( x , y ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) surf = ax . plot_surface ( X , Y , Z , cmap = cm . coolwarm ) ax . set_xlabel ( r '$k_x$' ) ax . set_ylabel ( r '$k_y$' ) ax . set_zlabel ( r '$\\epsilon$' ) fig . colorbar ( surf , shrink = 0.5 , aspect = 5 ) if True : plt . savefig ( 'A-6-3-tightbindingdisp.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () which although it looks cool, it is much more useful to look at a contour plot of the energy: Contour plot code fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.05 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) cp = ax . contourf ( X , Y , Z , 11 , cmap = cm . coolwarm ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Tight binding model dispersion' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingcontour.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () If we are considering a monovalent unit cell, then the Brillouin zone is half filled: Filled cell code fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.1 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) maxfilled = np . sort ( zs )[ int ( len ( zs ) / 2 )] for z in Z : z [ z > round ( maxfilled )] = None cp = ax . contourf ( X , Y , Z , 11 , cmap = 'binary' ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Monovalent tight binding system' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingmonovalent.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Now suppose the lattice is not square, but is instead rectangular with primitive lattice vectors of length \\(a_x\\) and \\(a_y\\) in the \\(x\\) and \\(y\\) directions respectively, where \\(a_x > a_y\\) . Imagine that the hopping have a value \\(-t_x\\) in the \\(x-\\) direction and a value \\(-t_y\\) in the \\(y-\\) direction, with \\(t_y > t_x\\) . Given that \\(a_x > a_y\\) , why would one expect \\(t_y > t_x\\) ? If \\(a_x > a_y\\) one expects the hopping magnitude to be smaller in the \\(x\\) direction since the atoms are further apart (although this is not holy, as the orbitals, such as \\(p_x\\) orbitals, may not be isotropic). Write an expression for the dispersion of the electronic states \\(\\epsilon(\\mathbf{k})\\) Basically the same as above, but with anisotropy: \\[ \\epsilon_{k_x, k_y} = -2t_x \\cos(k_x a_y) - 2t_y \\cos(k_y a_y) \\] Suppose once again that the atoms are monovalent. What is the shape of the Fermi surface? As an example, let us choose \\(t_y = 3t_x\\) but \\(a_x = ay = a\\) for simplicity. A contour plot of this energy is given shown below: Contour plot code a = 1 t_x = 2 t_y = 2 * t_x def ep ( kx , ky ): return - 2 * t_x * np . cos ( kx * a ) - 2 * t_y * np . cos ( ky * a ) fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.05 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) cp = ax . contourf ( X , Y , Z , 11 , cmap = cm . coolwarm ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Tight binding model dispersion' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingcontour_noniso.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () If we are considering a monovalent unit cell, then the Brillouin zone is half filled: Filled cell code fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.1 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) maxfilled = np . sort ( zs )[ int ( len ( zs ) / 2 )] for z in Z : z [ z > round ( maxfilled )] = None cp = ax . contourf ( X , Y , Z , 11 , cmap = 'binary' ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Monovalent tight binding system' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingmonovalent_noniso.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Exercise 4 - Semiconductors: holes \u00b6 In the context of semiconductor physics, what is meant by a hole and why is it useful? A hole is the absence of an electron in an otherwise filled valence band. This is useful since instead of describing the dynamics of all the (many) electrons in the band, it is equivalent to describe the dynamics of just the (few) holes. An electron near the top of the valence band in a semiconductor has energy E = -10^{-37}|k|^2 where \\(E\\) is in Joules, and \\(k\\) is in \\(\\mathrm{m^{-1}}\\) . An electron is removed from a state \\(k = 2 \\times 10^8 \\mathrm{m^{-1}} \\hat{x}\\) , where \\(\\hat{x}\\) is the unit vector in the \\(x-\\) direction. For a hole, calculate (including the sign) the effective mass Effective mass \\(\\hbar^2 k^2/(2m^\u2217) = 10^{-37} k^2\\) . So \\(m^\u2217 = 5 \\times 10^{-32} \\mathrm{kg}\\) or \\(.05\\) the mass of the electron. This mass is positive in the usual convention. the energy The energy is \\(E = 10^{-37} k^2 = 4\\times 10^{-21} \\mathrm{J}\\) , or about \\(0.025\\mathrm{eV}\\) . This energy is positive (it takes energy to \"push\" the hole down into the fermi sea, like pushing a balloon under water). the velocity Getting the velocity (and momentum) right are tricky. First, note that the velocity of an eigenstate is the same whether or not the state is filled with an electron. It is always true that the velocity of an electron in a state is \\(\\nabla_k E_k/\\hbar\\) where \\(E_k\\) is the electron energy. Thus the hole velocity here is negative \\(v = -\\hbar k/m^\u2217 = -3.8 \\times 10^5 \\mathrm{m/s}\\) (i.e. the velocity is in the negative \\(\\hat{x}\\) ) direction. the momentum For momentum, since a filled band carries no (crystal) momentum, and for electrons crystal momentum is always \\(\\hbar k\\) , the removal of an electron leaves the band with net momentum \\(-\\hbar k\\) which we assign as the momentum of the hole. Thus we obtain hole momentum \\(-\\hbar k = -2.1 \\times 10^{-26} \\mathrm{kg ~ m/s}\\) which is also in the negative \\hat{x} direction (this matches well to the intuition that \\(p = mv\\) with a positive effective mass for holes). If there is a density \\(p = 10^5 \\mathrm{m^{-3}}\\) of such holes all having almost exactly this same momentum, calculate the current density and its sign. With \\(p\\) the density of such holes, the total current density is \\(p e v = -6 \\times 10^{-9} \\mathrm{A/m^2}\\) also in the negative \\hat{x} direction (noting that the charge of the hole is positive). Exercise 5 - Semiconductor devices \u00b6 Choose a semiconductor device of interest (a few examples are provided below, but choose anything), research it, and explain what the device is and how it functions, with an emphasis on the material covered in this course. Zener diode Laser diode Solar cell Hall effect sensor No solution provided.","title":"Assignment 6: Waves in three-dimensional solids and applications"},{"location":"solutions/assignment6/#assignment-6-waves-in-three-dimensional-solids-and-applications","text":"The first assignment can be found here","title":"Assignment 6: Waves in three-dimensional solids and applications"},{"location":"solutions/assignment6/#exercise-1-structure-determination","text":"A diffraction experiment with an unknown crystalline powder sample was performed using a tungsten X-ray tube. Tungsten has \\(K_{\\alpha}\\) emission lines \\(K_{\\alpha_1} = 59 318.8\\mathrm{eV}\\) and \\(K_{\\alpha_2} = 57 981.9\\mathrm{eV}\\) , and the ratio of intensities of the emissions lines is \\(\\alpha_2/\\alpha_1 \\approx 0.115\\) . Explain how X-ray tubes produce X-rays, and describe how one would go about performing a powder diffraction experiment. This is a more detailed response than I would expect, but for a complete picutre: in an X-ray tube, electrons are emitted from the filament and accelerated towards the anode, and two forms of radiation are produced from the interaction between the electrons and the anode. The first kind is Bremsstrahlung radiation, which will be emitted as the electron is decelerated by the atomic nuclei of the anode. The emission spectrum is continuous, with the approximate shape described by Kramers' Law: \\[ I(\\lambda)d\\lambda = K \\left(\\frac{\\lambda}{\\lambda_{\\textrm{min}}}-1\\right)\\frac{1}{\\lambda^2}d\\lambda \\] where the cutoff wavelength, \\(\\lambda_{\\textrm{min}}\\) is given by the Duane-Hunt law: \\[ \\lambda_{\\textrm{min}} = \\frac{hc}{eV}. \\] The key point relating to the distribution is that with an increased acceleration voltage, the Bremsstrahlung radiation intensity increases and shifts towards higher frequencies. The second kind of radiation is the characteristic X-ray emission, which occurs when a high-lying electron decays to a (vacant) lower energy level, resulting in the emission of a photon. The bombardment of the anode by energetic electrons results in the emission of inner-shell electrons from the atoms in the anode. Such vacancies are filled by the decay of outer-shell electrons and due to the unique energy structure of each element, each atom emits photons of distinct frequencies, completely analogous to atomic optical spectra. The combination of these effects means that the expected emission spectrum would expect a smooth, continuous spectrum punctuated by emissions of characteristic X-rays. Powder diffraction experiments are performed by placing a crystalline sample in powdered form in an X-ray beamline and collecting the scattered radiation from the sample. The diffraction pattern will by design form rings rather than spots, as every possible crystal orientation is assured by using a powder rather than a monocrystalline sample. A plot of the data measured from the experiment when \\(K_{\\alpha_1}\\) emission was used is shown below: Following the recipe discussed in class, produce a table with columns of angle, plane separation, ratio of the square of first plane separation to plane separation, \\(N = h^2 + k^2 + l^2\\) , \\({hkl}\\) , and \\(a\\) (assuming some kind of cubic lattice) This should be relatively straightforward, given the example we did in class was trickier and the code used to do the analysis was freely distributed. The peaks as found from the data are shown below: Peak finding code peaks , _ = find_peaks ( data [ 'Intensity' ]) fig , ax = plt . subplots () ax . plot ( data [ 'Angle' ], data [ 'Intensity' ] / maxamp , label = r 'W $K_{\\alpha_1}$' , color = 'C0' ) ax . plot ( data [ 'Angle' ][ peaks ], data [ 'Intensity' ][ peaks ] / maxamp , \"x\" , color = 'C1' , label = 'Peaks' ) ax . set_xlabel ( r 'Angle [2$\\theta$]' ) ax . set_xlim (( 19 , 82 )) ax . set_ylabel ( 'Intensity [arb]' ) ax . set_title ( 'X-ray scattering of unknown material' ); plt . legend () loc = matplotlib . ticker . MultipleLocator ( 1 ) ax . xaxis . set_minor_locator ( loc ) ax . tick_params ( which = 'minor' ) if True : plt . savefig ( 'A-6-peaks.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () from which the following data table can be constructed: Peak number \\(2\\theta\\) \\(d~[\\mathrm{pm}]\\) \\(d_a^2/d^2\\) \\(N\\) \\({hkl}\\) \\(a~[\\mathrm{pm}]\\) 1 20.461 58.84 1.00 1 [1, 0, 0] 58.84 2 29.086 41.61 1.99 2 [1, 1, 0] 58.84 3 35.828 33.97 2.99 3 [1, 1, 1] 58.84 4 41.609 29.42 3.99 4 [2, 0, 0] 58.84 5 46.788 26.32 4.99 5 [2, 1, 0] 58.84 6 51.567 24.02 5.99 6 [2, 1, 1] 58.84 7 60.302 20.80 7.99 8 [2, 2, 0] 58.84 8 64.380 19.61 8.99 9 [2, 2, 1] 58.84 9 68.327 18.61 9.99 10 [3, 0, 0] 58.84 10 72.164 17.74 10.99 11 [3, 1, 0] 58.84 11 75.920 16.98 11.99 12 [3, 1, 1] 58.84 12 79.617 16.32 12.99 13 [2, 2, 2] 58.84 The difficulty of finding the multiplier to make all values of \\(d_a^2/d^2\\) an integer is not present in this example, so the process should be straightforward to find \\(a=58.84 \\mathrm{pm}\\) Use the table above to determine the lattice structure of the crystal The lattice is a simple cubic lattice, which can be inferred by the calculated values of N above and the selection rule for simple cubic lattices ( \\(N\\) is all integers excluding \\(7, 15, 23, \\ldots\\) ), and this is directly visible from the diffraction data: peak 7 is clearly missing. The basis of the lattice is given by \\(X = [0,0,0]\\) and \\(Y = [1/2, 1/2, \\beta], [1/2, 1/2, (1 - \\beta)] , [1/2, \\beta, 1/2], [(1 - \\beta), 1/2, 1/2], [1/2, 1/2, \\beta],\\) and \\([(1 - \\beta), 1/2, 1/2]\\) where \\(X\\) and \\(Y\\) are different atomic species, and \\(\\beta \\approx 0.2\\) . Draw the unit cell for the crystal using your lattice and the basis specified above. Below is the crystal structure (many unit cells) and can be well described as a simple cubic with a neat prism inside. The material is \\(\\textrm{LaB}_6\\) , which is the most gorgeous shade of pink, and is a neat material for making hot cathode emitters (electron sources). Explain how the intensity of the peaks could be used to determine \\(\\beta\\) , and obtain an expression for the ratio of the first two diffraction peaks. Note: You do not need to solve this equation for \\(\\beta\\) , just arrive at something that could be used to calculate \\(\\beta\\) . The intensity of the peaks is related to the square (well, modulus squared) of the structure factor \\(S\\) . As we have been using it in class, the structure factor is \\[ S_{(hkl)} = \\sum_\\alpha f_\\alpha e^{i\\mathbf{G}\\cdot\\mathbf{R}_\\alpha} \\] which in reality means that one must compute \\[ S_{(hkl)} = \\sum_\\alpha f_\\alpha e^{2\\pi i(hkl)\\cdot[xyz]_\\alpha} \\] This is not so difficult, but can be a bit tedious depending on the basis of the unit cell. Given we are looking at the intensities of the first two peaks, this means we will need to look at \\(S_{(100)}\\) : \\[ \\begin{aligned} S_{(100)} & = f_\\textrm{X} + f_\\textrm{Y}\\left( e^{i\\pi} + e^{i\\pi} + e^{2\\pi i \\beta} + e^{2\\pi i (1-\\beta)} + e^{i\\pi} + e^{i\\pi} \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( e^{2\\pi i \\beta} + e^{-2\\pi i \\beta} e^{2\\pi i} - 4 \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 2\\cos(2\\pi\\beta) - 4 \\right) \\\\ & = f_\\textrm{X} - 2 f_\\textrm{Y}\\left( 1 + \\sin^2(\\pi\\beta) \\right) \\\\ \\end{aligned} \\] and \\(S_{(110)}\\) : \\[ \\begin{aligned} S_{(110)} & = f_\\textrm{X} + f_\\textrm{Y}\\left( e^{2\\pi i} + e^{2\\pi i} + 2\\left( e^{2\\pi i \\beta}e^{i\\pi} + e^{2\\pi i (1-\\beta)}e^{i\\pi} \\right) \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 2 - 2\\left( e^{2\\pi i \\beta} + e^{-2\\pi i \\beta} e^{2\\pi i} \\right) \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 2 - \\cos(2\\pi\\beta) \\right) \\\\ & = f_\\textrm{X} + f_\\textrm{Y}\\left( 1 - 2\\sin^2(\\pi\\beta) \\right) \\\\ \\end{aligned} \\] One could then look at the ratio \\(I_{(100)}/I_{(110)} = |S_{(100)}|^2/|S_{(110)}|^2\\) and try and solve for \\(\\beta\\) , but that will be a mess, so one should solve it numerically. The real value is \\(\\beta = 0.1981\\) , although I am not sure exactly what the ratio of \\(I_{(100)}/I_{(110)}\\) would return. Imagine the experiment was altered such that both \\(K_{\\alpha_1}\\) and \\(K_{\\alpha_2}\\) emission lines were present. How would this alter the data as recorded above? Would you expect that one could still uniquely determine the crystal structure of the sample? Shown below is the spectrum with both emission lines: With two emission lines, one would expect to have essentially to diffraction patterns superimposed, but as there is sufficient energy separation between the two emission lines, one can resolve the two peaks (well, in simulated data). The question explicitly states that the ratio of intensities for emission from the different transitions is \\(\\alpha_2/\\alpha_1 \\approx 0.115\\) , meaning the \\(K_{\\alpha_2}\\) peaks will be noticeably smaller. The main point is that there will be two distinct diffraction patterns, and provided one can uniquely distinguish from which emission line the peak comes, one would actually be able to better determine the crystal structure, as one effectively has double the number of peaks. This method is used more broadly, that is, not using monochromatic X-rays but rather polychromatic X-rays in order to get more information per unit diffraction, but one must know well the illuminating radiation. This is usually called \"pink\" beam illumination. Now imagine that the experiment were altered such that only \\(K_{\\alpha_1}\\) radiation were used, but a monocrystalline sample were used. What would be the difference in the recorded diffraction pattern? If one were to use a monocrystalline sample, the diffraction pattern would have distinct Bragg spots rather than rings, but then we need to care much more about crystal orientation (it also usually very difficult to get large monocrystalline samples). The image below shows diffraction from monocrystalline silicon: Unfortunately, the beautiful single crystal was dropped before it could be used, resulting in a sample that is neither amorphous nor monocrystalline, rather something between the two. How would this alter the appearance of the diffraction pattern? With a sample between monocrystalline and amorphous, there are extended regions of order and one can imagine either the Bragg spots blurring out around the optical axis (around \\(\\theta\\) in polar coordinates), or the rings \"sharpening up\", that is still ring-like but with more intensity at the Bragg spots. The image below shows both powder and grain-oriented diffraction from aluminium:","title":"Exercise 1 - Structure determination"},{"location":"solutions/assignment6/#exercise-2-the-nearly-free-electron-model","text":"Consider an electron in a weak periodic potential in one dimension \\(V(X) = V(x+a)\\) . It is natural to write the potential as V(x) = \\sum_G e^{iGx} V_G where the sum is over the reciprocal lattice \\(G = 2\\pi n/a\\) and \\(V_G* = V_{-G}\\) assures the potential \\(V(x)\\) is real. Explain why for k near to a Brillouin zone boundary (such as \\(k\\) near \\(\\pi/a\\) ) the electron wavefunction should be taken to be \\psi = A e^{ikx} + B e^{i(k+G)x} where \\(G\\) is a reciprocal lattice vector such that \\(|k|\\) is close to \\(|k+G|\\) . A periodic lattice can only scatter a wave by a reciprocal lattice vector (Bragg diffraction). In the nearly free electron picture, the scattering perturbation is weak, so that we can treat the scattered wave in perturbation theory. In this case, there is an energy denominator which suppresses mixing of \\(k\\) -vectors which have greatly different unperturbed energies. Thus, the only mixing that can occur is between two states with similar energies that are separated by a reciprocal lattice vector. Degenerate perturbation theory tells us that we should first diagonalize within the degenerate space spanned by only these two eigenstates. We have seen that with the above wavefunction, the energy (that is, the eigenvalues) at this wavevector are given by E = \\frac{\\hbar^2 k^2}{2m} + V_0 \\pm |V_G| where \\(G\\) is chosen such that \\(|k| = |k+G|\\) . Give a qualitative explanation of why these two states are separated in energy by \\(2|V_G|\\) If we consider only the \\(V_{2n\\pi/a}\\) and \\(V_{-2n\\pi/a}\\) Fourier modes of the potential then we have \\(V = 2 V_{2n\\pi/a} \\cos(2n\\pi r/a)\\) . Assuming \\(V_{2n\\pi/a} > 0\\) , then the higher energy state is the \\(\\psi = \\cos(2n\\pi r/a)\\) which puts the maximum amplitude of the wavefunction exactly at the maxima of the potential. Similarly, the lower energy wavefunction is the \\(\\sin(2n\\pi r/a)\\) which has the minimum amplitude of the wavefunction at the maximum of the potential. In the case of \\(V_{2n\\pi /a} < 0\\) the sin is the higher energy wavefunction. Provide a sketch or plot of the energy as a function of \\(k\\) in both the extended and reduced zone schemes. Note that one need not compute \\(E\\) for all \\(k\\) , emphasis should be on the general features of the energy spectrum. These plots below are actually calculated by solving the eigenvalue problem as outlined in the next question for all \\(k\\) (where the perturbation is valid, that is where the term in \\(\\delta k\\) to second order is small compared \\(|V_{2n\\pi/a}|^2\\) ). In the reduced zone scheme, one should have something like: Reduced-zone scheme code # Use colors from the default color cycle default_colors = plt . rcParams [ 'axes.prop_cycle' ] . by_key ()[ 'color' ] blue , orange , * _ = default_colors def energy ( k , V = 1 ): k = ( k + np . pi ) % ( 2 * np . pi ) - np . pi k_vals = k + 2 * np . pi * np . arange ( - 1 , 2 ) h = np . diag ( k_vals ** 2 ) + V * ( 1 - np . identity ( 3 )) return np . linalg . eigvalsh ( h ) energy = np . vectorize ( energy , signature = \"(),()->(m)\" ) fig , ax = plt . subplots ( 1 , 1 ) momenta = np . linspace ( - np . pi , np . pi , 400 ) energies = energy ( momenta , 0 ) max_en = 41 energies [ energies > max_en ] = np . nan ax . plot ( momenta , energies , c = blue , label = 'Free electron' ) energies = energy ( momenta , 2 ) max_en = 41 energies [ energies > max_en ] = np . nan ax . plot ( momenta , energies , c = orange , label = 'Nearly free electron' ) ax . set_xlabel ( \"$ka$\" ) ax . set_ylabel ( \"$E$\" ) ax . set_ylim ( - .5 , max_en + 5 ) ax . set_xticks ( np . pi * np . arange ( - 1 , 2 )) ax . set_xticklabels ( r \"$-\\pi$ $0$ $\\pi$\" . split ()) def legend_without_duplicate_labels ( ax ): handles , labels = ax . get_legend_handles_labels () unique = [( h , l ) for i , ( h , l ) in enumerate ( zip ( handles , labels )) if l not in labels [: i ]] ax . legend ( * zip ( * unique )) legend_without_duplicate_labels ( ax ) if True : plt . savefig ( 'A-6-reduced.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Whereas in the extended zone scheme, one should have: Extended-zone scheme code fig , ax = plt . subplots ( 1 , 1 ) momenta = np . linspace ( - 3 * np . pi , 3 * np . pi , 400 ) energies = energy ( momenta , 0 ) max_en = 41 energies [ energies > max_en ] = np . nan energies [ ~ (( abs ( momenta ) // np . pi ) . reshape ( - 1 , 1 ) == np . arange ( 3 ) . reshape ( 1 , - 1 ))] = np . nan ax . plot ( momenta , energies , c = blue , label = 'Free electron' ) energies = energy ( momenta , 2 ) max_en = 41 energies [ energies > max_en ] = np . nan energies [ ~ (( abs ( momenta ) // np . pi ) . reshape ( - 1 , 1 ) == np . arange ( 3 ) . reshape ( 1 , - 1 ))] = np . nan ax . plot ( momenta , energies , c = orange , label = 'Nearly free electron' ) ax . set_xlabel ( \"$ka$\" ) ax . set_ylabel ( \"$E$\" ) ax . set_ylim ( - .5 , max_en + 5 ) ax . set_xticks ( np . pi * np . arange ( - 3 , 4 )) ax . set_xticklabels ( fr \"$ { i } \\pi$\" . replace ( \"1\" , \"\" ) if i else \"$0$\" for i in range ( - 3 , 4 )) legend_without_duplicate_labels ( ax ) if True : plt . savefig ( 'A-6-extended.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Let us look at the case where \\(k\\) is not at the Brillouin zone boundary, but rather close to the boundary. Following the same method as used to achieve the above result, show that at the point \\(k = n\\pi/a + \\delta k\\) the energy to second order in \\(\\delta k\\) is given by E_{\\pm}=\\frac{\\hbar^{2}(n \\pi / a)^{2}}{2 m}+V_{0} \\pm\\left|V_{2 n \\pi / a}\\right|+\\frac{\\hbar^{2}(\\delta k)^{2}}{2 m}\\left(1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}\\right) Technically the wavefunction should have a normalisation \\[ \\psi = (A e^{ikx} + B e^{i(k+G)x})/\\sqrt{L} \\] but it is rarely the case that one is actually probing for normalisation compliance, and in any case, to maintain normalization we can insist that \\(|A|^2 + |B|^2 = 1\\) . Taking \\(k\\) and \\(k+G\\) both on a Brillouin zone boundary we have \\(k = n\\pi/a\\) and \\(k+G = -n\\pi/a\\) , where here we have chosen the \\(n^{\\textrm{th}}\\) zone boundary, and we must have \\(G = -2n\\pi/a\\) the reciprocal lattice vector. The Hamiltonian \\(H\\) in question is the usual Kinetic term plus \\(V(x)\\) . From here, one can either use the variational method or diagonalise the Hamiltonian the degenerate space, the latter of which was done in class and is done here. We must compute the matrix elements: \\[ \\begin{aligned} \\langle k|H| k\\rangle &=\\hbar^{2}(\\delta k+n \\pi / a)^{2} /(2 m)+V_{0} \\\\ \\langle k+G|H| k+G\\rangle &=\\hbar^{2}(\\delta k-n \\pi / a)^{2} /(2 m)+V_{0} \\\\ \\langle k|H| k+G\\rangle &=V_{2 n \\pi / a} \\\\ \\langle k+G|H| k\\rangle &=V_{-2 n \\pi / a} \\end{aligned} \\] which means that me must diagonalise the matrix \\[ \\left(\\begin{array}{cc} \\hbar^{2}(\\delta k+n \\pi / a)^{2} /(2 m)+V_{0} & V_{2 n \\pi / a} \\\\ V_{-2 n \\pi / a} & \\hbar^{2}(\\delta k-n \\pi / a)^{2} /(2 m)+V_{0} \\end{array}\\right). \\] Performing the diagonalisation, one finds \\[ E_{\\pm}=\\frac{\\hbar^{2}\\left[(\\delta k)^{2}+(n \\pi / a)^{2}\\right]}{2 m}+V_{0} \\pm \\sqrt{\\left[\\frac{\\hbar^{2} 2(\\delta k) n \\pi / a}{2 m}\\right]^{2}+\\left|V_{2 n \\pi / a}\\right|^{2}} \\] and the square root should be expanded and the common terms in \\(\\delta k\\) collected to obtain the result \\[ E_{\\pm}=\\frac{\\hbar^{2}(n \\pi / a)^{2}}{2 m}+V_{0} \\pm\\left|V_{2 n \\pi / a}\\right|+\\frac{\\hbar^{2}(\\delta k)^{2}}{2 m}\\left(1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}\\right) \\] as required. Calculate the effective mass of an electron at this wavevector The effective mass can be obtained from \\[ \\frac{1}{2m^*} = \\frac{1}{2m}\\left(1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}\\right) \\] or equivalently \\[ m^{*}=\\left|\\frac{m}{1 \\pm \\frac{\\hbar^{2}(n \\pi / a)^{2}}{m\\left|V_{2 n \\pi / a}\\right|}}\\right| \\]","title":"Exercise 2 - The nearly-free electron model"},{"location":"solutions/assignment6/#exercise-3-fermi-surfaces","text":"Consider a tight binding model of atoms on a (two-dimensional) square lattice where each atom has a single atomic orbital. If these atoms are monovalent, describe the shape of the Fermi surface. The dispersion of the tight binding model is given by \\[ \\epsilon_{k_x, k_y} = -2t \\left( \\cos(k_x a) + \\cos(k_y a) \\right) \\] and a plot of the dispersion is shown below Fermi surface code from matplotlib import cm from mpl_toolkits.mplot3d import Axes3D # Axes3D import has side effects, it enables using projection='3d' in add_subplot a = 1 t = 2 def ep ( kx , ky ): return - 2 * t * ( np . cos ( kx * a ) + np . cos ( ky * a )) fig = plt . figure () ax = fig . add_subplot ( 111 , projection = '3d' ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.05 ) X , Y = np . meshgrid ( x , y ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) surf = ax . plot_surface ( X , Y , Z , cmap = cm . coolwarm ) ax . set_xlabel ( r '$k_x$' ) ax . set_ylabel ( r '$k_y$' ) ax . set_zlabel ( r '$\\epsilon$' ) fig . colorbar ( surf , shrink = 0.5 , aspect = 5 ) if True : plt . savefig ( 'A-6-3-tightbindingdisp.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () which although it looks cool, it is much more useful to look at a contour plot of the energy: Contour plot code fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.05 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) cp = ax . contourf ( X , Y , Z , 11 , cmap = cm . coolwarm ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Tight binding model dispersion' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingcontour.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () If we are considering a monovalent unit cell, then the Brillouin zone is half filled: Filled cell code fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.1 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) maxfilled = np . sort ( zs )[ int ( len ( zs ) / 2 )] for z in Z : z [ z > round ( maxfilled )] = None cp = ax . contourf ( X , Y , Z , 11 , cmap = 'binary' ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Monovalent tight binding system' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingmonovalent.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () Now suppose the lattice is not square, but is instead rectangular with primitive lattice vectors of length \\(a_x\\) and \\(a_y\\) in the \\(x\\) and \\(y\\) directions respectively, where \\(a_x > a_y\\) . Imagine that the hopping have a value \\(-t_x\\) in the \\(x-\\) direction and a value \\(-t_y\\) in the \\(y-\\) direction, with \\(t_y > t_x\\) . Given that \\(a_x > a_y\\) , why would one expect \\(t_y > t_x\\) ? If \\(a_x > a_y\\) one expects the hopping magnitude to be smaller in the \\(x\\) direction since the atoms are further apart (although this is not holy, as the orbitals, such as \\(p_x\\) orbitals, may not be isotropic). Write an expression for the dispersion of the electronic states \\(\\epsilon(\\mathbf{k})\\) Basically the same as above, but with anisotropy: \\[ \\epsilon_{k_x, k_y} = -2t_x \\cos(k_x a_y) - 2t_y \\cos(k_y a_y) \\] Suppose once again that the atoms are monovalent. What is the shape of the Fermi surface? As an example, let us choose \\(t_y = 3t_x\\) but \\(a_x = ay = a\\) for simplicity. A contour plot of this energy is given shown below: Contour plot code a = 1 t_x = 2 t_y = 2 * t_x def ep ( kx , ky ): return - 2 * t_x * np . cos ( kx * a ) - 2 * t_y * np . cos ( ky * a ) fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.05 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) cp = ax . contourf ( X , Y , Z , 11 , cmap = cm . coolwarm ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Tight binding model dispersion' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingcontour_noniso.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show () If we are considering a monovalent unit cell, then the Brillouin zone is half filled: Filled cell code fig , ax = plt . subplots ( 1 , 1 ) x = y = np . arange ( - np . pi / a , np . pi / a , 0.1 ) zs = np . array ( ep ( np . ravel ( X ), np . ravel ( Y ))) Z = zs . reshape ( X . shape ) maxfilled = np . sort ( zs )[ int ( len ( zs ) / 2 )] for z in Z : z [ z > round ( maxfilled )] = None cp = ax . contourf ( X , Y , Z , 11 , cmap = 'binary' ) fig . colorbar ( cp ) # Add a colorbar to a plot ax . set_title ( 'Monovalent tight binding system' ) ax . set_xlabel ( '$k_x$' ) ax . set_ylabel ( '$k_y$' ) if True : plt . savefig ( 'A-6-3-tightbindingmonovalent_noniso.svg' , facecolor = 'white' , transparent = False , bbox_inches = 'tight' ) plt . show ()","title":"Exercise 3 - Fermi surfaces"},{"location":"solutions/assignment6/#exercise-4-semiconductors-holes","text":"In the context of semiconductor physics, what is meant by a hole and why is it useful? A hole is the absence of an electron in an otherwise filled valence band. This is useful since instead of describing the dynamics of all the (many) electrons in the band, it is equivalent to describe the dynamics of just the (few) holes. An electron near the top of the valence band in a semiconductor has energy E = -10^{-37}|k|^2 where \\(E\\) is in Joules, and \\(k\\) is in \\(\\mathrm{m^{-1}}\\) . An electron is removed from a state \\(k = 2 \\times 10^8 \\mathrm{m^{-1}} \\hat{x}\\) , where \\(\\hat{x}\\) is the unit vector in the \\(x-\\) direction. For a hole, calculate (including the sign) the effective mass Effective mass \\(\\hbar^2 k^2/(2m^\u2217) = 10^{-37} k^2\\) . So \\(m^\u2217 = 5 \\times 10^{-32} \\mathrm{kg}\\) or \\(.05\\) the mass of the electron. This mass is positive in the usual convention. the energy The energy is \\(E = 10^{-37} k^2 = 4\\times 10^{-21} \\mathrm{J}\\) , or about \\(0.025\\mathrm{eV}\\) . This energy is positive (it takes energy to \"push\" the hole down into the fermi sea, like pushing a balloon under water). the velocity Getting the velocity (and momentum) right are tricky. First, note that the velocity of an eigenstate is the same whether or not the state is filled with an electron. It is always true that the velocity of an electron in a state is \\(\\nabla_k E_k/\\hbar\\) where \\(E_k\\) is the electron energy. Thus the hole velocity here is negative \\(v = -\\hbar k/m^\u2217 = -3.8 \\times 10^5 \\mathrm{m/s}\\) (i.e. the velocity is in the negative \\(\\hat{x}\\) ) direction. the momentum For momentum, since a filled band carries no (crystal) momentum, and for electrons crystal momentum is always \\(\\hbar k\\) , the removal of an electron leaves the band with net momentum \\(-\\hbar k\\) which we assign as the momentum of the hole. Thus we obtain hole momentum \\(-\\hbar k = -2.1 \\times 10^{-26} \\mathrm{kg ~ m/s}\\) which is also in the negative \\hat{x} direction (this matches well to the intuition that \\(p = mv\\) with a positive effective mass for holes). If there is a density \\(p = 10^5 \\mathrm{m^{-3}}\\) of such holes all having almost exactly this same momentum, calculate the current density and its sign. With \\(p\\) the density of such holes, the total current density is \\(p e v = -6 \\times 10^{-9} \\mathrm{A/m^2}\\) also in the negative \\hat{x} direction (noting that the charge of the hole is positive).","title":"Exercise 4 - Semiconductors: holes"},{"location":"solutions/assignment6/#exercise-5-semiconductor-devices","text":"Choose a semiconductor device of interest (a few examples are provided below, but choose anything), research it, and explain what the device is and how it functions, with an emphasis on the material covered in this course. Zener diode Laser diode Solar cell Hall effect sensor No solution provided.","title":"Exercise 5 - Semiconductor devices"},{"location":"solutions/assignments/","text":"Solutions to assignments \u00b6 Assignment 1: Debye, Drude, Sommerfeld, and chemistry \u00b6 Assignment 2: Bonding and harmonic chains \u00b6 Assignment 3: One-dimensional solids (welcome to the diatomic party) . \u00b6 Assignment 4: Crystals \u00b6 Assignment 5: the reciprocal lattice and scattering \u00b6 Assignment 6: Waves in three-dimensional solids and applications \u00b6","title":"Solutions to assignments"},{"location":"solutions/assignments/#solutions-to-assignments","text":"","title":"Solutions to assignments"},{"location":"solutions/assignments/#assignment-1-debye-drude-sommerfeld-and-chemistry","text":"","title":"Assignment 1: Debye, Drude, Sommerfeld, and chemistry"},{"location":"solutions/assignments/#assignment-2-bonding-and-harmonic-chains","text":"","title":"Assignment 2: Bonding and harmonic chains"},{"location":"solutions/assignments/#assignment-3-one-dimensional-solids-welcome-to-the-diatomic-party","text":"","title":"Assignment 3: One-dimensional solids (welcome to the diatomic party)."},{"location":"solutions/assignments/#assignment-4-crystals","text":"","title":"Assignment 4: Crystals"},{"location":"solutions/assignments/#assignment-5-the-reciprocal-lattice-and-scattering","text":"","title":"Assignment 5: the reciprocal lattice and scattering"},{"location":"solutions/assignments/#assignment-6-waves-in-three-dimensional-solids-and-applications","text":"","title":"Assignment 6: Waves in three-dimensional solids and applications"},{"location":"solutions/exerscises/","text":"Solutions to exercises \u00b6 Currently this is pretty empty!","title":"Solutions to exercises"},{"location":"solutions/exerscises/#solutions-to-exercises","text":"Currently this is pretty empty!","title":"Solutions to exercises"},{"location":"solutions/practice-exam/","text":"Practice exam \u00b6 The practice exam can be found here , and it was written to provide a flavour for the style of examination one can expect from the course as taught by me, rather than the past examinations which have followed a different course structure. Given this is pitched as a learning tool, I have included some discussion that would not be expected in an exam, but in addition to helping you achieve the best possible result on the exam, I care much more about you learning and understanding the content: hopefully this resource proves useful. Question 1 \u00b6 This question focuses on the physics of solids without considering the microscopic structure. What is the Einstein model of a solid? List both the successes and the shortcomings of the model. The Einstein model builds on the Boltzmann model for solids, which described matter as being comprised of particles interacting through a harmonic potential which was modelled using statistical mechanics. Einsein's model was to say the each particle was in an identical harmonic potential (characterised by oscillation frequency \\(\\omega\\) ), which was basically injecting a basic form of quantum mechanics. This had the effect of explaining the low-temperature behaviour of the heat capacity (name that is \"freezes out\"), but under predicts the heat capacity as there are no additional ways to store energy. State the assumptions of the Debye model of heat capacity for a solid. The Debye model remedies some of the shortcomings of the Einstein model by considering collective oscillations of particles in the solid, specifically noting that waves should exist in a solid (sound waves, or later, phonons) and these could be quantised in the same way as the light field (\u00e0 la Plank). The fundamental assumption of the model as we consider it are the system is isotropic, with 3 polarisations of sound waves which obey a linear dispersion relation. Importantly, there is also a maximum frequency up to which oscillations occur and beyond this, they no longer occur, but there is no physical grounding to this justification, rather it just makes the maths work out. Whilst the Debye model does a better job than the Einstein model, notably reproducing the \\(T^3\\) behaviour of the heat capacity at low temperature, it fails to include energy stored by electrons in the material, which the Sommerfeld/free-electron model incorporates to give a pretty good model where one is agnostic to the microscopic properties of the system. Einstein obtained an expression for the expectation value of the energy of a single oscillator at frequency \\(\\omega\\) \\( \\(\\langle E \\rangle = \\hbar\\omega\\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega) + \\frac{1}{2}\\right)\\) \\) Consider a three-dimensional solid as modelled using the framework of Debye. Write an expression for the total energy in the system for oscillators with frequencies \\(\\omega(\\mathbf{k})\\) The expression above provides the energy for a single oscillator, and we have a bunch of them, so we need to add them up! In the usual way, because of the 3 modes of polarisation (spin) there is a factor of 3 out the front, but otherwise the result follows directly from above: \\langle E \\rangle = 3 \\sum_{\\mathbf{k}} \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) What is the density of states \\(g(\\omega)\\) ? Justify the validity of the expression E = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega)~\\hbar\\omega~\\left[n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k})) + 1/2 \\right] The density of states \\(g(\\omega)\\) (as it says on tin!) tells you about the number of states per unit frequency (in this case). More succinctly, the number of states between \\(\\omega\\) and \\(\\mathrm{d}{\\omega}\\) is given by \\(g(\\omega)\\mathrm{d}{\\omega}\\) . In order to justify the expression, we will need to take the result from the previous question and show it is equivalent to that stated. To start, in the usual way we must convert the sum to an integral. Ultimately this happens as we impose periodic boundary conditions to the problem, which has the effect of discretising reciprocal space and meaning that if we want to count the number of states (or equivalently add them up) we can use the density of points in \\(k-\\) space to construct an approximation to the sum over \\(\\mathbf{k}\\) : \\[ \\langle E \\rangle \\approx 3 \\frac{L^3}{(2\\pi)^3} \\int \\mathrm{d}\\mathbf{k} \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\] We then compute move into spherical coordinates to compute this integral (or at least it to a one-dimensional integral) as the system is isotropic, so we can write \\[ \\langle E \\rangle \\approx 3 \\frac{L^3}{(2\\pi)^3} \\int_0^{\\infty} \\mathrm{d}k ~ 4\\pi k^2 ~ \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\] which is essentially in the form as requested, given we know that for sound, \\(\\omega = v_s k\\) . The only other point of note is that the integral in this case is over all \\(k\\) (or equivalently \\(\\omega\\) ), whereas that presented is up to a maximum frequency. This is a fundamental assumption of the Debye model, and the change of limit can just be imposed, but the change definitely warrants a comment! The question would have been better written combining it with the next part, but I was trying to lay out the question with bite-sized steps that could follow. You be the judge of whether that worked. Assuming linear dispersion, what is the density of states \\(g(\\omega)\\) in the above expression? Most of the heavy lifting had been done by this point, we just need to finish transforming the equation above explicitly using the relation \\(\\omega = v_s k\\) : \\[\\begin{align*} \\langle E \\rangle & \\approx 3 \\frac{L^3}{(2\\pi)^3} \\int_0^{\\infty} \\mathrm{d}k ~ 4\\pi k^2 ~ \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}}(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\\\ & = \\frac{12\\pi L^3}{(2\\pi)^3 v_s^3} \\int_0^{\\infty} \\mathrm{d}\\omega ~ \\omega^2 ~ \\hbar \\omega \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega) + \\frac{1}{2}\\right) \\\\ & = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega)~\\hbar\\omega~\\left(n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2} \\right) \\end{align*}\\] where we identify the density of states \\[ g(\\omega) = \\frac{12\\pi L^3 \\omega^2}{(2\\pi)^3 v_s^3} \\] The cutoff frequency can be evaluated by ensuring there are the correct number of modes in the system. If there are \\(N\\) oscillators, what should be the total number of modes? Justify your response. If we have \\(N\\) oscillators, there should be \\(3N\\) modes, as there are 3 degrees of freedom (three dimensions of motion) for each oscillator Compute the cutoff frequency \\(\\omega_{\\textrm{cutoff}}\\) With the response from above and the definition of the density of states \\begin{align*} 3N & = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega) \\\\ & = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega) \\frac{12\\pi L^3 \\omega^2}{(2\\pi)^3 v_s^3} & = \\frac{12\\pi L^3 \\omega^2}{3(2\\pi)^3 v_s^3} \\omega_\\textrm{cutoff}^3 \\end{align*} and therefore \\[ \\omega_\\textrm{cutoff}^3 = 6\\pi^2v_s^2\\frac{N}{L^3} = 6\\pi^2v_s^2 n \\] A triumph of Debye's theory was the explanation of the cubic dependence on temperature for the heat capacity at low temperature. Briefly explain why this behaviour occurs. Without going to town, we have an expression for the total energy in the system \\(\\langle E \\rangle\\) , so in principle we could compute the heat capacity directly through C = \\frac{\\partial <span class=\"arithmatex\">\\(\\langle E \\rangle\\)</span>}{\\partial T} When evaluated, the energy \\(\\langle E \\rangle\\) (perhaps unsurprisingly) yields an \\(E \\propto T^4\\) relation - see the Stefan-Boltzmann law here and thus the C \\propto T^3 behaviour, but physically, we have a system which is able to store more energy at low temperature than an Einstein solid. Why is this the case? Well, Einstein has independent harmonic osciallators, which are \"all or nothing\", in that for \\(E<\\hbar\\omega\\) , nothing can happen, whereas the Debye model allows for energy to be stored in the collective oscillations of the system (phonons) and thus the system still reacts at low temperature. Careful observation of the heat capacity for metals at very low temperatures shows deviation from this cubic behaviour. Provide a brief explanation for this discrepancy. This is such a natural next question: where else can I store energy? Well at really low temperature, even the collective oscillations start to freeze out, but for a system of free electrons (as is modelled in the Sommerfeld model), the system can absorb small amounts of energy through the excitation of electrons at the Fermi surface. Note that this ties in nicely with material from the latter part of the course where we spent much time looking at the origins of Fermi surfaces. Question 2 \u00b6 This question focuses on incorporating microscopic structure into the physics of solids in one dimension. Consider a one-dimensional diatomic chain, where the spring constants between neighbouring atoms are identical and equal to \\(\\kappa\\) , but neighbouring masses are different, alternating between \\(m_1\\) and \\(m_2\\) . You are going to derive the dispersion relation for this system. Sketch the system as described above, ensuring to mark the unit cell length \\(a\\) on the diagram See an image shamelessly pulled from assignment 3. Given I made it, I feel I can own \"sketching\" this: Denoting the position of the \\(n^{\\textrm{th}}\\) particle of mass \\(m_1\\) as \\(x_n\\) and the position of the \\(n^{\\textrm{th}}\\) particle of mass \\(m_2\\) as \\(y_n\\) , show that the equations of motion for the system are \\begin{align*} m_1 \\ddot{\\delta x_n} & = -\\kappa (\\delta x_n - \\delta y_{n-1}) - \\kappa (\\delta x_n - \\delta y_n) \\\\ m_2 \\ddot{\\delta y_n} & = -\\kappa (\\delta y_n - \\delta x_n) - \\kappa (\\delta y_n - \\delta x_{n+1}) \\end{align*} These equations are constructed from Newton's second law, and are best illustrated through an image (hence the requirement to sketch it above!) where one can see that the force on \\(x_n\\) in the \\(-x\\) direction will be given by \\(\\kappa\\) times the extension/compression \\(\\delta x_n - \\delta y_{n-1}\\) and the force in the \\(+x\\) direction will be given by \\(\\kappa\\) times the extension/compression \\(\\delta y_n - \\delta x_n\\) , which when combined (taking care with the signs!) yields the top equation, and the 2 \\(^\\textrm{nd}\\) equation can be constructed similarly. Solve that above set of equations for the normal modes of the system to show that \\omega^{2} =\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) As we are looking for normal modes, we look for solutions where all bodies oscillate with the same frequency \\(\\omega\\) , namely we look for wave-like solutions of the form \\[ \\begin{aligned} \\delta x_{n} &=A_{x} e^{i k a n-i \\omega t} \\\\ \\delta y_{n} &=A_{y} e^{i k a n-i \\omega t} \\end{aligned} \\] which plugged into our equations of motion gives \\[ \\begin{aligned} -m_{1} \\omega^{2} A_{x} e^{i k n a} &=-2 \\kappa A_{x} e^{i k n a}+\\kappa A_{y}\\left(e^{i k n a}+e^{i k(n-1) a}\\right) \\\\ -m_{2} \\omega^{2} A_{y} e^{i k n a} &=-2 \\kappa A_{y} e^{i k n a}+\\kappa A_{x}\\left(e^{i k n a}+e^{i k(n+1) a}\\right) \\end{aligned} \\] which can be simplified into \\[ \\begin{aligned} \\omega^{2} A_{x} &=2\\left(\\kappa / m_{1}\\right) A_{x}-\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) A_{y} \\\\ \\omega^{2} A_{y} &=2\\left(\\kappa / m_{2}\\right) A_{y}-\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) A_{x} \\end{aligned} \\] which defines an eigenvalue problem for \\(\\omega^2\\) . Therefore we must find the roots of the determinant \\[ \\left|\\begin{array}{cc} 2\\left(\\kappa / m_{1}\\right)-\\omega^{2} & -\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) \\\\ -\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) & 2\\left(\\kappa / m_{2}\\right)-\\omega^{2} \\end{array}\\right| \\] which yields the equation \\[ \\begin{aligned} &0=\\omega^{4}-\\omega^{2}\\left(2 \\kappa\\left(1 / m_{1}+1 / m_{2}\\right)\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}\\left(4-\\left(1+e^{i k a}\\right)\\left(1+e^{-i k a}\\right)\\right) \\\\ &\\left.0=\\omega^{4}-\\omega^{2}\\left(\\frac{2\\left(m_{1}+m_{2}\\right) \\kappa}{m_{1} m_{2}}\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}(2-2 \\cos (k a))\\right) \\end{aligned} \\] and ultimately \\[ \\begin{aligned} \\omega^{2} &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) \\\\ &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{\\left(m_{1}+m_{2}\\right)^{2}-4 m_{1} m_{2} \\sin ^{2}(k a / 2)}\\right) \\end{aligned} \\] as required. Find the sound velocity for the acoustic branch around \\(k=0\\) The acoustic branch(es) are those which by definition have a dispersion around \\(k=0\\) which is linear, and thus, one can immediately write \\omega = v_s k and moreover, we know that \\(\\omega = \\sqrt{\\kappa/m}\\) for harmonic potentials. But this is not really finding the velocity, just knowing what it should be! To find it, we must expand the low-energy band around \\(k=0\\) in the expression above: \\[ \\begin{aligned} \\omega^{2} &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) \\\\ & \\approx \\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} (1 - \\frac{k^2 a^2}{2})}\\right) \\\\ & = \\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm (m_1 + m_2)\\sqrt{1-\\frac{k^2 a^2 m_1 m_2}{(m_1 + m_2)^2}}\\right) \\\\ & \\approx \\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm (m_1 + m_2)\\left(1-\\frac{k^2 a^2 m_1 m_2}{2(m_1 + m_2)^2}\\right)\\right) \\end{aligned} \\] which for the low energy (acoustic) branch givens \\[ \\omega^{2} = \\kappa \\frac{k^2 a^2}{2(m_1 + m_2)} \\] which is indeed a solution of the form \\[ \\omega = v_s k \\] where \\(v_s = a\\sqrt{\\frac{\\kappa}{2(m_1 + m_2)}}\\) We now alter our one-dimensional diatomic chain to a triatomic chain. How many optical modes and how many acoustic modes would you expect? If there are 3 atoms per unit cell, we would expect 3 modes, one of which will be acoustic and two will be optical The one-dimensional chain provides an excellent model for understanding the properties of solids in one dimension. With explicit reference to covalent bonding as modelled through the linear combination of atomic orbitals, explain why it that we can use a harmonic potential to well describe the interatomic potential. If we consider two distinct atoms, with some interatomic separation \\(\\Delta x\\) , to model the electronic states of the system we must consider the influence of both nuclei and the other electron for a given electron, for which we construct a Hamiltonian \\(\\hat{H} = \\hat{V}_1 + \\hat{V}_2 + \\hat{K}\\) . In the simplest case of LCAO , we consider only the ground state for each atom and make an assumption: that the states of out new (combined) system will be a linear combination of our original states. To calculate the energy of these new states, we use the variational method (which is done in its full glory in the Chemistry section of the notes ) but the ultimate outcome is that we end up with bonding and antibonding states which have an energy determined by the interatomic spacing, as shown in the plot below: This model has not taken into account the interaction between nuclei, and thus this is not actually physical: we know that matter does not collapse into a singularity, and thus when we include a repulsive force at small atomic separations, we end up with a potential like that shown below (in this case the Lenard-Jones potential): From here is almost a mathematical exercise, in that we have a potential which has a local minimum, and thus we can approximate this local minimum to be a parabola, that is a harmonic potential. This is not always going to work well, but for low temperatures oscillations within this potential will have sufficiently small amplitude such that the potential landscape is well modelled by a parabola. A plot of the above potential with a parabolic approximation is shown below: Limitations of this approximation come in the form of high temperature behaviour, and anisotropy. The origin of this is stunningly not profound: when the potential ceases to look like a parabola, approximating it with a parabola is not a good idea. A notable example of the failure of this model is that it does not predict thermal expansion as this requires anharmonicity in the potential (see assignment two), but in many cases, it can provide a qualitative understanding of basic material properties. Moreover (and much deeper down the rabbit hole) the formulations of field theories which are centred around creation and annihilation operators have a direct link to harmonic potentials, meaning these systems have a trivial generalisation (well, a well-trodden generalisation) to more advanced formalisms. Question 3 \u00b6 This question focuses on the describing the geometry of, and the scattering from, solids. A triangular lattice has primitive lattice vectors \\(\\mathbf{a_1} = a \\hat{\\mathbf{x}}\\) and \\(\\mathbf{a_2} = (a/2) \\hat{\\mathbf{x}} + (a\\sqrt{3}/2) \\hat{\\mathbf{y}}\\) . Draw the lattice described by the above basis vectors (draw at least \\(3 \\times 3\\) lattice points) Digitial how about I do it in python ? On the lattice above, draw both the primitive unit cell as defined by the primitive lattice vectors and the Wigner-Seitz cell Coneventional cell included at no extra cost Find the primitive lattice vectors of the reciprocal lattice To compute the primitive lattice vecotrs for the reciprocal lattice, we seek vectors \\(\\mathbf{b}\\) such that \\(\\mathbf{a}_i \\cdot \\mathbf{b}_j = 2\\pi\\delta_{i,j}\\) . In three dimensions, one has the general formula \\mathbf{b}_1 = 2\\pi \\frac{\\mathbf{a}_2 \\times \\mathbf{a}_3}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} and permutations therein, with the simplest path to victory being an assignment of \\(\\mathbf{a}_3 = \\hat{\\mathbf{z}}\\) . The product \\(\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3) = a^2 \\sqrt{3}/2\\) , and then \\[\\begin{align*} \\mathbf{b}_1 & = 2\\pi \\left[ (a\\sqrt{3}/2) \\hat{\\mathbf{x}} - (a/2) \\hat{\\mathbf{y}} \\right]/a^2 \\sqrt{3}/2 = (2\\pi/a) \\left[ \\hat{\\mathbf{x}} - (\\sqrt{3}/3) \\hat{\\mathbf{y}} \\right] \\\\ \\mathbf{b}_2 & = 2\\pi a \\hat{\\mathbf{y}} / a^2 \\sqrt{3}/2 = (2\\pi/a) (2\\sqrt{3}/3) \\hat{\\mathbf{y}} \\end{align*}\\] What physical significance does the Wigner-Seitz cell of the reciprocal lattice hold? The Brillouin zone for a system described by a periodic potential in real space, that is, the volume which holds all possible unique momentum states, is given by the Wigner-Seitz cell of the reciprocal lattice. What basis could be used in combination with the above lattice to return a honeycomb structure (that is, the structure of graphene)? \\[ 1/3(\\mathbf{a_1} + \\mathbf{a_2}) \\quad \\textrm{and} \\quad 2/3(\\mathbf{a_1} + \\mathbf{a_2}) \\] Now consider the structure of CsCl: a simple cubic with the basis Cs at \\([0,0,0]\\) and Cl at \\([1/2, 1/2, 1/2]\\) What kind of bonding would you expect for this structure? CsCl is a group I element, and Cl is a group VII element, which we would suspect would be an ionic bond due the electronegativity of chlorine. As a general, if you see group VII, it is likely to be ionic, those suckers take electrons like nobody's business! Compute the structure factor \\(S\\) for X-ray scattering from CsCl with a general set of Miller indices \\((hkl)\\) The structure factor is the Fourier transform of atoms in the unit cell: S_{(hkl)} = \\sum_\\alpha f_\\alpha e^{2\\pi i(hkl)\\cdot[xyz]} where \\(f_\\alpha\\) is the scattering form factor for a given element (which technically is also a function of \\(\\mathbf{G}\\) ). So for Cs at \\([0,0,0]\\) and Cl at \\([1/2, 1/2, 1/2]\\) : \\begin{align*} S_{(hkl)} & = f_{\\mathrm{Cs}} + f_{\\mathrm{Cl}} e^{2\\pi i(h,k,l)\\cdot[1/2, 1/2, 1/2]} \\\\ & = f_{\\mathrm{Cs}} + f_{\\mathrm{Cl}} (-1)^{h+k+l} \\end{align*} Now consider the case of pure Cs, which has the same structure but with the chlorine atom replaced by a caesium atom (a simple cubic with the basis Cs at [0,0,0] and [1/2, 1/2, 1/2]). What kind of bonding would you expect for this structure? We would expect this type of system to be metallic, which in some sense is akin to covalent bonding, whereby it is energetically favourable for the electrons to be shared across the system rather than be localised on individual nuclei. Using a previous result or otherwise, compute the structure factor \\(S\\) for X-ray scattering for pure Cs with a general set of Miller indices \\((hkl)\\) From the previous question, we can make the substitution \\(f_{\\textrm{Cl}} \\rightarrow f_{\\textrm{Cs}}\\) : \\[ S_{(hkl)} = f_{\\mathrm{Cs}} \\left[1 + (-1)^{h+k+l} \\right] \\] which we can clearly identify will vanish for some values of \\((hkl)\\) , that is, a selection rule exists. Consider the case of X-ray scattering from the planes defined by the Miller indices (210). What scattered intensity would one expect in the case of CsCl versus pure Cs? We can see in the case of pure Cs, the structure factor and hence the scattered intensity will go to zero for \\(h+k+l\\) being odd, and thus for (210) no scattered intensity will be measured. In the case of CsCl, one cannot say too much without knowing the from factors \\(f_{\\mathrm{Cs}} + f_{\\mathrm{Cl}}\\) , but there will be some intensity as \\(f_{\\mathrm{Cs}} \\ne f_{\\mathrm{Cl}}\\) The sample of CsCl was accidentally mislabelled, and it turns out that it is actually CsI, which has the identical structure except with Cl ( \\(Z = 17\\) ) replaced with I ( Z = 53 ). Again, for diffraction from the planes defined by the Miller indices (210), what scattered intensity would expect from the CsI as compared to the CsCl? For reference, the atomic number of caesium is \\(Z = 55\\) . What a follow up question! Basically, in the previous question, we could not say all too much about \\(f_{\\mathrm{Cs}}\\) or \\(f_{\\mathrm{Cl}}\\) , but as a very vague general trend, \\(f \\sim Z\\) , and thus with a \\(\\Delta Z = 38\\) in the case of CsCl, the form factors will not be all that similar. In the case of CsI, \\(\\Delta Z = 2\\) and thus one would expect the form factors to be close, and thus the scattered intensity for (210) would be much supressed as compared to the CsCl case/ Question 4 \u00b6 This question focuses on band structure and its applications What is meant by the free electron model, the nearly-free electron model and the tight binding model? In what circumstances are the models appropriate? In all cases, one should consider the models as determining which momentum states exist (and hence can be occupied). In the case of the free electron model, all possible states can be occupied, they are after all free electrons, so there is no potential which enforces reciprocal space structure. The nearly-free electron model is a weak perturbation to the free electron model by a periodic potential, whereby we have a system where electrons act mostly as free electrons, except for when the wavefunction has a strong component on the length-scale/momentum scale of the perturbing periodic potential. The tight binding model (as the same suggests) arises when we consider systems where electrons are tightly bound to a parent nucleus, so in some sense one could think of this as a very strong perturbation of the free electron system, where there properties are determined solely but the periodic potential. Free electron model is appropriate for free electrons and is superseded in most in materials by the nearly-free electron model, as the strength of the perturbation due to the crystal structure can always be dialled back. But this is an important point: if a Fermi surface for a material looks like a sphere, it is going to be (or rather is) well approximated by the free electron model. On the other extreme, if the Fermi surface matches the Brillouin zone (that is, there isn't a Fermi surface) the system is well described by the tight binding model. Consider a square lattice of monovalent atoms in two dimensions. Roughly sketch the first Brillouin zone for the lattice (only the shape is important), and indicate the Fermi sea in the absence of a periodic potential The reciprocal lattice of a square lattice will also be a square lattice, and the Wigner-Seitz cell of a square lattice is a square. This question is very qualitative, but is one of the most important concepts in this course, hence its appearance here. Rather than just providing a sketch, this is a full calculation and so obviously beyond what would be expected. The dispersion relation - a surface in 2D - is shown, along with a contour plot of this surface. As each \\(k\\) state can hold 2 electrons, \\(50\\%\\) of the Brillouin zone will be filled (in this case area) with the lowest states being preferentially filled. The free-electron dispersion relationship is a parabaloid, and hence we get a circular Fermi surface, with the Fermi sea being the interior of this circle. Repeat the process above for both a weak and strong periodic potential Shown below is the dispersion surface in the tight-binding model (which you can think of as a very strong periodic potential), which in contrast to the Fermi circle of a free-electron, makes a Fermi square: A weaker periodic potential would be in-between these extremes, a circle with the points closest to the Brillouin zone boundaries filled more due to band bending. Barium ( \\(Z = 56\\) ) is a divalent atom, and the Fermi surface is shown below: Explain the features of this surface, explicitly referencing the 2D analogues from the previous section, and what statements (if any) can be made about the conductivity and specific heat of barium based upon the Fermi surface alone? Still needs to be finished , but the if we consider a square BZ, a divalent nearly-free electron system would have a Fermi surface something like a circle with the same area as the BZ, but with points outside the square, that is bits that protrude into the 2nd BZ. Think of this like the extended/reduced zone schemes in 1D: when something is in the 2nd BZ (in the extended zone) this is the same as the excited 1st branch in the reduced zone scheme: we are just seeing this is 3D. The fact that there is a Fermi surface at all mean that there are nearby states which electrons can occupy, and thus the system can absorb energy: this will be a metal, and conduct both heat and electricity. It is also Barium, which you (may) know is a metal! Consider a semiconductor quantum well: a material which is uniform Al \\(_x\\) Ga \\(_{1-x}\\) As with a thin layer of GaAs that is a material that has three regions. Recall that the energy eignestates of a quantum well have energies \\( \\(E_n = \\frac{\\hbar^2 \\pi^2 n^2}{2 m L^2}\\) \\) We can model this system as a two-dimensional electron gas. Show that the density of states for a free electron gas is g(E) = \\frac{m}{\\pi \\hbar^2} \\Theta(E) where \\(\\Theta(E)\\) is the Heaviside step function I don't know why I used in \\(E\\) in this question, but I am going to stick with the convention of the course to use \\(\\varepsilon\\) for the energy. In two dimensions, the number of states is given by \\[ N = 2 \\frac{A}{(2\\pi)^2} \\int_0^{k_F} \\mathrm{d}\\mathbf{k} \\] which evaluates to \\[ N = \\frac{A}{2\\pi} k_F^2 \\] or equivalently \\(n= N/A = k_F^2/2\\pi\\) . For a free electron: \\[ \\varepsilon = \\frac{\\hbar^2 k^2}{2m} \\] and thus \\[ n = \\frac{2m \\varepsilon_F}{2\\pi\\hbar^2} \\] By the definition of the denisty of states per unit volume, we have also that \\[ n = \\int_0^{\\varepsilon_F} g(\\varepsilon) \\mathrm{d}\\varepsilon \\] and thus \\[ g(\\varepsilon) = \\frac{m}{\\pi\\hbar^2} \\] Note using \\(g(\\varepsilon) = \\mathrm{d}n / \\mathrm{d}\\varepsilon\\) yields the same result. The inclusion of the Heaviside step function is necessary as states that have a negative energy should not be included, which is obviously clear in the case of a free electron, but when we have electrons and holes in wells, we must be much more careful! Show that the density of states for electrons in the well is given by g(E) = \\frac{m_e^*}{\\pi \\hbar^2} \\sum_{n>0} \\Theta \\left(E - E_c - \\frac{\\hbar^2 \\pi^2}{2 m_e^*} \\frac{n^2}{L^2}\\right) where \\(E_c\\) is the conduction band energy. In a quantum well, we will have the two-dimensional behaviour of the free electron plus the inclusion of the discretised states of the quantum well. We also must include the effective mass of the electron, as it is no longer a free electron. So the energy of an electron in a given state state in the well described by quantum number \\(n\\) is \\[ \\varepsilon_n = \\varepsilon_c + \\frac{\\hbar^2 \\pi^2 n^2}{2 m_e^* L^2} + \\frac{\\hbar^2 k^2}{2m_e^*} \\] where \\(\\varepsilon_c\\) is the minimum energy of the conduction band (the bottom of the well). As the conduction band energy and well energy is independent of \\(k\\) , the density of states will be the same as above, with the appropriate subsititutions and a regonition that there are no states below the ground state of the well, that is \\(\\varepsilon\\) will only be non-zero above \\(\\varepsilon_c + \\hbar^2 \\pi^2 n^2 / 2 m_e^* L^2\\) , and thus \\[ g(\\varepsilon_n) = \\frac{m_e^*}{\\pi\\hbar^2} \\Theta\\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n^2}{2 m_e^* L^2} \\right) \\] But in the usual way, this is the density for a single mode \\(n\\) , and there are many possible values of \\(n\\) , and thus we must add them all up: \\[ g(\\varepsilon) = \\sum_n g(\\varepsilon_n) = \\frac{m_e^*}{\\pi\\hbar^2} \\sum_{n=1}^{\\infty} \\Theta\\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n^2}{2 m_e^* L^2} \\right) \\] as required. What is the density of states for holes in this system? There is delightfully little to do other than \\(m_e^* \\rightarrow m_h^*\\) , replacing the conduction band energy with the valence band energy, and recogising that only states with an energy \\(\\varepsilon\\) below \\(\\varepsilon_v - \\hbar^2 \\pi^2 n^2 / 2 m_h^* L^2\\) will be non-zero, and so one can directly write \\[ g(\\varepsilon) = \\frac{m_h^*}{\\pi\\hbar^2} \\sum_{n=1}^{\\infty} \\Theta \\left(\\varepsilon_v - \\frac{\\hbar^2 \\pi^2 n^2}{2 m_h^* L^2} - \\varepsilon \\right) \\] Now consider a \"quantum wire\": a one-dimensional block of GaAs in embedded in the Al \\(_x\\) Ga \\(_{1-x}\\) As. The cross-section of the wire is an \\(L \\times L\\) square and the system is well described by a one-dimensional electron gas. Show the density of states for electrons is given by \\begin{aligned} g(E) = \\frac{\\sqrt{2 m_e^*}}{\\pi \\hbar} \\sum_{n_1, n_2 >0} & \\left(E - E_c - \\frac{\\hbar^2 \\pi^2}{2 m_e^*} \\frac{n_1^2 + n_2^2}{L^2}\\right)^{1/2} \\\\ & \\times \\Theta \\left(E - E_c - \\frac{\\hbar^2 \\pi^2}{2 m_e^*} \\frac{n_1^2 + n_2^2}{L^2}\\right) \\end{aligned} This is really the definition of rinse and repeat. We had 3D in question one, 2D in the previous section and now 1D: in exactly the same manner as above, we need to calculate the density of states in one dimension and then incorporate the now 2D square well energy spectrum. For a free electron: \\[ N = 2 \\frac{L}{2\\pi} \\int \\mathrm{d}k \\] which is one dimension is a line integral from \\(-k_F\\) to \\(k_F\\) and so \\[ n = \\frac{N}{L} = \\frac{2 k_F}{\\pi} \\] and \\(k\\) is still \\(\\sqrt{2m\\varepsilon}/\\hbar\\) , so we find that \\[ g(\\varepsilon) = \\frac{\\sqrt{2m}}{\\pi\\hbar} E^{-1/2} \\Theta (\\varepsilon) \\] Now in the semiconductor, \\(m\\rightarrow m_e^*\\) and \\[ \\varepsilon_{n_1, n_2} = \\varepsilon_c + \\frac{\\hbar^2 \\pi^2 n_1^2 + n_2^2}{2 m_e^* L^2} + \\frac{\\hbar^2 k^2}{2m_e^*} \\] as there it is a two-dimesnional well. Now we need add up all the states, so sum over both \\(n_1\\) and \\(n_2\\) : \\[ \\begin{aligned} g(\\varepsilon) & = \\sum_{n_1,n_2} g(\\varepsilon_{n_1, n_2}) & \\\\ & = \\frac{\\sqrt{2m_e^*}}{\\pi\\hbar} \\sum_{n_1=1}^{\\infty} \\sum_{n_2=1}^{\\infty} & \\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n_1^2 + n_2^2}{2 m_e^* L^2} \\right)^{-1/2} \\\\ & & \\times \\Theta \\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n_1^2 + n_2^2}{2 m_e^* L^2} \\right) \\end{aligned} \\]","title":"Practice exam"},{"location":"solutions/practice-exam/#practice-exam","text":"The practice exam can be found here , and it was written to provide a flavour for the style of examination one can expect from the course as taught by me, rather than the past examinations which have followed a different course structure. Given this is pitched as a learning tool, I have included some discussion that would not be expected in an exam, but in addition to helping you achieve the best possible result on the exam, I care much more about you learning and understanding the content: hopefully this resource proves useful.","title":"Practice exam"},{"location":"solutions/practice-exam/#question-1","text":"This question focuses on the physics of solids without considering the microscopic structure. What is the Einstein model of a solid? List both the successes and the shortcomings of the model. The Einstein model builds on the Boltzmann model for solids, which described matter as being comprised of particles interacting through a harmonic potential which was modelled using statistical mechanics. Einsein's model was to say the each particle was in an identical harmonic potential (characterised by oscillation frequency \\(\\omega\\) ), which was basically injecting a basic form of quantum mechanics. This had the effect of explaining the low-temperature behaviour of the heat capacity (name that is \"freezes out\"), but under predicts the heat capacity as there are no additional ways to store energy. State the assumptions of the Debye model of heat capacity for a solid. The Debye model remedies some of the shortcomings of the Einstein model by considering collective oscillations of particles in the solid, specifically noting that waves should exist in a solid (sound waves, or later, phonons) and these could be quantised in the same way as the light field (\u00e0 la Plank). The fundamental assumption of the model as we consider it are the system is isotropic, with 3 polarisations of sound waves which obey a linear dispersion relation. Importantly, there is also a maximum frequency up to which oscillations occur and beyond this, they no longer occur, but there is no physical grounding to this justification, rather it just makes the maths work out. Whilst the Debye model does a better job than the Einstein model, notably reproducing the \\(T^3\\) behaviour of the heat capacity at low temperature, it fails to include energy stored by electrons in the material, which the Sommerfeld/free-electron model incorporates to give a pretty good model where one is agnostic to the microscopic properties of the system. Einstein obtained an expression for the expectation value of the energy of a single oscillator at frequency \\(\\omega\\) \\( \\(\\langle E \\rangle = \\hbar\\omega\\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega) + \\frac{1}{2}\\right)\\) \\) Consider a three-dimensional solid as modelled using the framework of Debye. Write an expression for the total energy in the system for oscillators with frequencies \\(\\omega(\\mathbf{k})\\) The expression above provides the energy for a single oscillator, and we have a bunch of them, so we need to add them up! In the usual way, because of the 3 modes of polarisation (spin) there is a factor of 3 out the front, but otherwise the result follows directly from above: \\langle E \\rangle = 3 \\sum_{\\mathbf{k}} \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) What is the density of states \\(g(\\omega)\\) ? Justify the validity of the expression E = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega)~\\hbar\\omega~\\left[n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k})) + 1/2 \\right] The density of states \\(g(\\omega)\\) (as it says on tin!) tells you about the number of states per unit frequency (in this case). More succinctly, the number of states between \\(\\omega\\) and \\(\\mathrm{d}{\\omega}\\) is given by \\(g(\\omega)\\mathrm{d}{\\omega}\\) . In order to justify the expression, we will need to take the result from the previous question and show it is equivalent to that stated. To start, in the usual way we must convert the sum to an integral. Ultimately this happens as we impose periodic boundary conditions to the problem, which has the effect of discretising reciprocal space and meaning that if we want to count the number of states (or equivalently add them up) we can use the density of points in \\(k-\\) space to construct an approximation to the sum over \\(\\mathbf{k}\\) : \\[ \\langle E \\rangle \\approx 3 \\frac{L^3}{(2\\pi)^3} \\int \\mathrm{d}\\mathbf{k} \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\] We then compute move into spherical coordinates to compute this integral (or at least it to a one-dimensional integral) as the system is isotropic, so we can write \\[ \\langle E \\rangle \\approx 3 \\frac{L^3}{(2\\pi)^3} \\int_0^{\\infty} \\mathrm{d}k ~ 4\\pi k^2 ~ \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\] which is essentially in the form as requested, given we know that for sound, \\(\\omega = v_s k\\) . The only other point of note is that the integral in this case is over all \\(k\\) (or equivalently \\(\\omega\\) ), whereas that presented is up to a maximum frequency. This is a fundamental assumption of the Debye model, and the change of limit can just be imposed, but the change definitely warrants a comment! The question would have been better written combining it with the next part, but I was trying to lay out the question with bite-sized steps that could follow. You be the judge of whether that worked. Assuming linear dispersion, what is the density of states \\(g(\\omega)\\) in the above expression? Most of the heavy lifting had been done by this point, we just need to finish transforming the equation above explicitly using the relation \\(\\omega = v_s k\\) : \\[\\begin{align*} \\langle E \\rangle & \\approx 3 \\frac{L^3}{(2\\pi)^3} \\int_0^{\\infty} \\mathrm{d}k ~ 4\\pi k^2 ~ \\hbar \\omega(\\mathbf{k}) \\left(n_{\\mathrm{B}}(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\\\ & = \\frac{12\\pi L^3}{(2\\pi)^3 v_s^3} \\int_0^{\\infty} \\mathrm{d}\\omega ~ \\omega^2 ~ \\hbar \\omega \\left(n_{\\mathrm{B}} (\\beta\\hbar\\omega) + \\frac{1}{2}\\right) \\\\ & = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega)~\\hbar\\omega~\\left(n_\\mathrm{B}(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2} \\right) \\end{align*}\\] where we identify the density of states \\[ g(\\omega) = \\frac{12\\pi L^3 \\omega^2}{(2\\pi)^3 v_s^3} \\] The cutoff frequency can be evaluated by ensuring there are the correct number of modes in the system. If there are \\(N\\) oscillators, what should be the total number of modes? Justify your response. If we have \\(N\\) oscillators, there should be \\(3N\\) modes, as there are 3 degrees of freedom (three dimensions of motion) for each oscillator Compute the cutoff frequency \\(\\omega_{\\textrm{cutoff}}\\) With the response from above and the definition of the density of states \\begin{align*} 3N & = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega) \\\\ & = \\int_0^{\\omega_\\textrm{cutoff}} \\mathrm{d}\\omega~g(\\omega) \\frac{12\\pi L^3 \\omega^2}{(2\\pi)^3 v_s^3} & = \\frac{12\\pi L^3 \\omega^2}{3(2\\pi)^3 v_s^3} \\omega_\\textrm{cutoff}^3 \\end{align*} and therefore \\[ \\omega_\\textrm{cutoff}^3 = 6\\pi^2v_s^2\\frac{N}{L^3} = 6\\pi^2v_s^2 n \\] A triumph of Debye's theory was the explanation of the cubic dependence on temperature for the heat capacity at low temperature. Briefly explain why this behaviour occurs. Without going to town, we have an expression for the total energy in the system \\(\\langle E \\rangle\\) , so in principle we could compute the heat capacity directly through C = \\frac{\\partial <span class=\"arithmatex\">\\(\\langle E \\rangle\\)</span>}{\\partial T} When evaluated, the energy \\(\\langle E \\rangle\\) (perhaps unsurprisingly) yields an \\(E \\propto T^4\\) relation - see the Stefan-Boltzmann law here and thus the C \\propto T^3 behaviour, but physically, we have a system which is able to store more energy at low temperature than an Einstein solid. Why is this the case? Well, Einstein has independent harmonic osciallators, which are \"all or nothing\", in that for \\(E<\\hbar\\omega\\) , nothing can happen, whereas the Debye model allows for energy to be stored in the collective oscillations of the system (phonons) and thus the system still reacts at low temperature. Careful observation of the heat capacity for metals at very low temperatures shows deviation from this cubic behaviour. Provide a brief explanation for this discrepancy. This is such a natural next question: where else can I store energy? Well at really low temperature, even the collective oscillations start to freeze out, but for a system of free electrons (as is modelled in the Sommerfeld model), the system can absorb small amounts of energy through the excitation of electrons at the Fermi surface. Note that this ties in nicely with material from the latter part of the course where we spent much time looking at the origins of Fermi surfaces.","title":"Question 1"},{"location":"solutions/practice-exam/#question-2","text":"This question focuses on incorporating microscopic structure into the physics of solids in one dimension. Consider a one-dimensional diatomic chain, where the spring constants between neighbouring atoms are identical and equal to \\(\\kappa\\) , but neighbouring masses are different, alternating between \\(m_1\\) and \\(m_2\\) . You are going to derive the dispersion relation for this system. Sketch the system as described above, ensuring to mark the unit cell length \\(a\\) on the diagram See an image shamelessly pulled from assignment 3. Given I made it, I feel I can own \"sketching\" this: Denoting the position of the \\(n^{\\textrm{th}}\\) particle of mass \\(m_1\\) as \\(x_n\\) and the position of the \\(n^{\\textrm{th}}\\) particle of mass \\(m_2\\) as \\(y_n\\) , show that the equations of motion for the system are \\begin{align*} m_1 \\ddot{\\delta x_n} & = -\\kappa (\\delta x_n - \\delta y_{n-1}) - \\kappa (\\delta x_n - \\delta y_n) \\\\ m_2 \\ddot{\\delta y_n} & = -\\kappa (\\delta y_n - \\delta x_n) - \\kappa (\\delta y_n - \\delta x_{n+1}) \\end{align*} These equations are constructed from Newton's second law, and are best illustrated through an image (hence the requirement to sketch it above!) where one can see that the force on \\(x_n\\) in the \\(-x\\) direction will be given by \\(\\kappa\\) times the extension/compression \\(\\delta x_n - \\delta y_{n-1}\\) and the force in the \\(+x\\) direction will be given by \\(\\kappa\\) times the extension/compression \\(\\delta y_n - \\delta x_n\\) , which when combined (taking care with the signs!) yields the top equation, and the 2 \\(^\\textrm{nd}\\) equation can be constructed similarly. Solve that above set of equations for the normal modes of the system to show that \\omega^{2} =\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) As we are looking for normal modes, we look for solutions where all bodies oscillate with the same frequency \\(\\omega\\) , namely we look for wave-like solutions of the form \\[ \\begin{aligned} \\delta x_{n} &=A_{x} e^{i k a n-i \\omega t} \\\\ \\delta y_{n} &=A_{y} e^{i k a n-i \\omega t} \\end{aligned} \\] which plugged into our equations of motion gives \\[ \\begin{aligned} -m_{1} \\omega^{2} A_{x} e^{i k n a} &=-2 \\kappa A_{x} e^{i k n a}+\\kappa A_{y}\\left(e^{i k n a}+e^{i k(n-1) a}\\right) \\\\ -m_{2} \\omega^{2} A_{y} e^{i k n a} &=-2 \\kappa A_{y} e^{i k n a}+\\kappa A_{x}\\left(e^{i k n a}+e^{i k(n+1) a}\\right) \\end{aligned} \\] which can be simplified into \\[ \\begin{aligned} \\omega^{2} A_{x} &=2\\left(\\kappa / m_{1}\\right) A_{x}-\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) A_{y} \\\\ \\omega^{2} A_{y} &=2\\left(\\kappa / m_{2}\\right) A_{y}-\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) A_{x} \\end{aligned} \\] which defines an eigenvalue problem for \\(\\omega^2\\) . Therefore we must find the roots of the determinant \\[ \\left|\\begin{array}{cc} 2\\left(\\kappa / m_{1}\\right)-\\omega^{2} & -\\left(\\kappa / m_{1}\\right)\\left(1+e^{-i k a}\\right) \\\\ -\\left(\\kappa / m_{2}\\right)\\left(1+e^{i k a}\\right) & 2\\left(\\kappa / m_{2}\\right)-\\omega^{2} \\end{array}\\right| \\] which yields the equation \\[ \\begin{aligned} &0=\\omega^{4}-\\omega^{2}\\left(2 \\kappa\\left(1 / m_{1}+1 / m_{2}\\right)\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}\\left(4-\\left(1+e^{i k a}\\right)\\left(1+e^{-i k a}\\right)\\right) \\\\ &\\left.0=\\omega^{4}-\\omega^{2}\\left(\\frac{2\\left(m_{1}+m_{2}\\right) \\kappa}{m_{1} m_{2}}\\right)+\\frac{\\kappa^{2}}{m_{1} m_{2}}(2-2 \\cos (k a))\\right) \\end{aligned} \\] and ultimately \\[ \\begin{aligned} \\omega^{2} &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) \\\\ &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{\\left(m_{1}+m_{2}\\right)^{2}-4 m_{1} m_{2} \\sin ^{2}(k a / 2)}\\right) \\end{aligned} \\] as required. Find the sound velocity for the acoustic branch around \\(k=0\\) The acoustic branch(es) are those which by definition have a dispersion around \\(k=0\\) which is linear, and thus, one can immediately write \\omega = v_s k and moreover, we know that \\(\\omega = \\sqrt{\\kappa/m}\\) for harmonic potentials. But this is not really finding the velocity, just knowing what it should be! To find it, we must expand the low-energy band around \\(k=0\\) in the expression above: \\[ \\begin{aligned} \\omega^{2} &=\\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} \\cos (k a)}\\right) \\\\ & \\approx \\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm \\sqrt{m_{1}^{2}+m_{2}^{2}+2 m_{1} m_{2} (1 - \\frac{k^2 a^2}{2})}\\right) \\\\ & = \\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm (m_1 + m_2)\\sqrt{1-\\frac{k^2 a^2 m_1 m_2}{(m_1 + m_2)^2}}\\right) \\\\ & \\approx \\frac{\\kappa}{m_{1} m_{2}}\\left(m_{1}+m_{2} \\pm (m_1 + m_2)\\left(1-\\frac{k^2 a^2 m_1 m_2}{2(m_1 + m_2)^2}\\right)\\right) \\end{aligned} \\] which for the low energy (acoustic) branch givens \\[ \\omega^{2} = \\kappa \\frac{k^2 a^2}{2(m_1 + m_2)} \\] which is indeed a solution of the form \\[ \\omega = v_s k \\] where \\(v_s = a\\sqrt{\\frac{\\kappa}{2(m_1 + m_2)}}\\) We now alter our one-dimensional diatomic chain to a triatomic chain. How many optical modes and how many acoustic modes would you expect? If there are 3 atoms per unit cell, we would expect 3 modes, one of which will be acoustic and two will be optical The one-dimensional chain provides an excellent model for understanding the properties of solids in one dimension. With explicit reference to covalent bonding as modelled through the linear combination of atomic orbitals, explain why it that we can use a harmonic potential to well describe the interatomic potential. If we consider two distinct atoms, with some interatomic separation \\(\\Delta x\\) , to model the electronic states of the system we must consider the influence of both nuclei and the other electron for a given electron, for which we construct a Hamiltonian \\(\\hat{H} = \\hat{V}_1 + \\hat{V}_2 + \\hat{K}\\) . In the simplest case of LCAO , we consider only the ground state for each atom and make an assumption: that the states of out new (combined) system will be a linear combination of our original states. To calculate the energy of these new states, we use the variational method (which is done in its full glory in the Chemistry section of the notes ) but the ultimate outcome is that we end up with bonding and antibonding states which have an energy determined by the interatomic spacing, as shown in the plot below: This model has not taken into account the interaction between nuclei, and thus this is not actually physical: we know that matter does not collapse into a singularity, and thus when we include a repulsive force at small atomic separations, we end up with a potential like that shown below (in this case the Lenard-Jones potential): From here is almost a mathematical exercise, in that we have a potential which has a local minimum, and thus we can approximate this local minimum to be a parabola, that is a harmonic potential. This is not always going to work well, but for low temperatures oscillations within this potential will have sufficiently small amplitude such that the potential landscape is well modelled by a parabola. A plot of the above potential with a parabolic approximation is shown below: Limitations of this approximation come in the form of high temperature behaviour, and anisotropy. The origin of this is stunningly not profound: when the potential ceases to look like a parabola, approximating it with a parabola is not a good idea. A notable example of the failure of this model is that it does not predict thermal expansion as this requires anharmonicity in the potential (see assignment two), but in many cases, it can provide a qualitative understanding of basic material properties. Moreover (and much deeper down the rabbit hole) the formulations of field theories which are centred around creation and annihilation operators have a direct link to harmonic potentials, meaning these systems have a trivial generalisation (well, a well-trodden generalisation) to more advanced formalisms.","title":"Question 2"},{"location":"solutions/practice-exam/#question-3","text":"This question focuses on the describing the geometry of, and the scattering from, solids. A triangular lattice has primitive lattice vectors \\(\\mathbf{a_1} = a \\hat{\\mathbf{x}}\\) and \\(\\mathbf{a_2} = (a/2) \\hat{\\mathbf{x}} + (a\\sqrt{3}/2) \\hat{\\mathbf{y}}\\) . Draw the lattice described by the above basis vectors (draw at least \\(3 \\times 3\\) lattice points) Digitial how about I do it in python ? On the lattice above, draw both the primitive unit cell as defined by the primitive lattice vectors and the Wigner-Seitz cell Coneventional cell included at no extra cost Find the primitive lattice vectors of the reciprocal lattice To compute the primitive lattice vecotrs for the reciprocal lattice, we seek vectors \\(\\mathbf{b}\\) such that \\(\\mathbf{a}_i \\cdot \\mathbf{b}_j = 2\\pi\\delta_{i,j}\\) . In three dimensions, one has the general formula \\mathbf{b}_1 = 2\\pi \\frac{\\mathbf{a}_2 \\times \\mathbf{a}_3}{\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3)} and permutations therein, with the simplest path to victory being an assignment of \\(\\mathbf{a}_3 = \\hat{\\mathbf{z}}\\) . The product \\(\\mathbf{a}_1 \\cdot (\\mathbf{a}_2 \\times \\mathbf{a}_3) = a^2 \\sqrt{3}/2\\) , and then \\[\\begin{align*} \\mathbf{b}_1 & = 2\\pi \\left[ (a\\sqrt{3}/2) \\hat{\\mathbf{x}} - (a/2) \\hat{\\mathbf{y}} \\right]/a^2 \\sqrt{3}/2 = (2\\pi/a) \\left[ \\hat{\\mathbf{x}} - (\\sqrt{3}/3) \\hat{\\mathbf{y}} \\right] \\\\ \\mathbf{b}_2 & = 2\\pi a \\hat{\\mathbf{y}} / a^2 \\sqrt{3}/2 = (2\\pi/a) (2\\sqrt{3}/3) \\hat{\\mathbf{y}} \\end{align*}\\] What physical significance does the Wigner-Seitz cell of the reciprocal lattice hold? The Brillouin zone for a system described by a periodic potential in real space, that is, the volume which holds all possible unique momentum states, is given by the Wigner-Seitz cell of the reciprocal lattice. What basis could be used in combination with the above lattice to return a honeycomb structure (that is, the structure of graphene)? \\[ 1/3(\\mathbf{a_1} + \\mathbf{a_2}) \\quad \\textrm{and} \\quad 2/3(\\mathbf{a_1} + \\mathbf{a_2}) \\] Now consider the structure of CsCl: a simple cubic with the basis Cs at \\([0,0,0]\\) and Cl at \\([1/2, 1/2, 1/2]\\) What kind of bonding would you expect for this structure? CsCl is a group I element, and Cl is a group VII element, which we would suspect would be an ionic bond due the electronegativity of chlorine. As a general, if you see group VII, it is likely to be ionic, those suckers take electrons like nobody's business! Compute the structure factor \\(S\\) for X-ray scattering from CsCl with a general set of Miller indices \\((hkl)\\) The structure factor is the Fourier transform of atoms in the unit cell: S_{(hkl)} = \\sum_\\alpha f_\\alpha e^{2\\pi i(hkl)\\cdot[xyz]} where \\(f_\\alpha\\) is the scattering form factor for a given element (which technically is also a function of \\(\\mathbf{G}\\) ). So for Cs at \\([0,0,0]\\) and Cl at \\([1/2, 1/2, 1/2]\\) : \\begin{align*} S_{(hkl)} & = f_{\\mathrm{Cs}} + f_{\\mathrm{Cl}} e^{2\\pi i(h,k,l)\\cdot[1/2, 1/2, 1/2]} \\\\ & = f_{\\mathrm{Cs}} + f_{\\mathrm{Cl}} (-1)^{h+k+l} \\end{align*} Now consider the case of pure Cs, which has the same structure but with the chlorine atom replaced by a caesium atom (a simple cubic with the basis Cs at [0,0,0] and [1/2, 1/2, 1/2]). What kind of bonding would you expect for this structure? We would expect this type of system to be metallic, which in some sense is akin to covalent bonding, whereby it is energetically favourable for the electrons to be shared across the system rather than be localised on individual nuclei. Using a previous result or otherwise, compute the structure factor \\(S\\) for X-ray scattering for pure Cs with a general set of Miller indices \\((hkl)\\) From the previous question, we can make the substitution \\(f_{\\textrm{Cl}} \\rightarrow f_{\\textrm{Cs}}\\) : \\[ S_{(hkl)} = f_{\\mathrm{Cs}} \\left[1 + (-1)^{h+k+l} \\right] \\] which we can clearly identify will vanish for some values of \\((hkl)\\) , that is, a selection rule exists. Consider the case of X-ray scattering from the planes defined by the Miller indices (210). What scattered intensity would one expect in the case of CsCl versus pure Cs? We can see in the case of pure Cs, the structure factor and hence the scattered intensity will go to zero for \\(h+k+l\\) being odd, and thus for (210) no scattered intensity will be measured. In the case of CsCl, one cannot say too much without knowing the from factors \\(f_{\\mathrm{Cs}} + f_{\\mathrm{Cl}}\\) , but there will be some intensity as \\(f_{\\mathrm{Cs}} \\ne f_{\\mathrm{Cl}}\\) The sample of CsCl was accidentally mislabelled, and it turns out that it is actually CsI, which has the identical structure except with Cl ( \\(Z = 17\\) ) replaced with I ( Z = 53 ). Again, for diffraction from the planes defined by the Miller indices (210), what scattered intensity would expect from the CsI as compared to the CsCl? For reference, the atomic number of caesium is \\(Z = 55\\) . What a follow up question! Basically, in the previous question, we could not say all too much about \\(f_{\\mathrm{Cs}}\\) or \\(f_{\\mathrm{Cl}}\\) , but as a very vague general trend, \\(f \\sim Z\\) , and thus with a \\(\\Delta Z = 38\\) in the case of CsCl, the form factors will not be all that similar. In the case of CsI, \\(\\Delta Z = 2\\) and thus one would expect the form factors to be close, and thus the scattered intensity for (210) would be much supressed as compared to the CsCl case/","title":"Question 3"},{"location":"solutions/practice-exam/#question-4","text":"This question focuses on band structure and its applications What is meant by the free electron model, the nearly-free electron model and the tight binding model? In what circumstances are the models appropriate? In all cases, one should consider the models as determining which momentum states exist (and hence can be occupied). In the case of the free electron model, all possible states can be occupied, they are after all free electrons, so there is no potential which enforces reciprocal space structure. The nearly-free electron model is a weak perturbation to the free electron model by a periodic potential, whereby we have a system where electrons act mostly as free electrons, except for when the wavefunction has a strong component on the length-scale/momentum scale of the perturbing periodic potential. The tight binding model (as the same suggests) arises when we consider systems where electrons are tightly bound to a parent nucleus, so in some sense one could think of this as a very strong perturbation of the free electron system, where there properties are determined solely but the periodic potential. Free electron model is appropriate for free electrons and is superseded in most in materials by the nearly-free electron model, as the strength of the perturbation due to the crystal structure can always be dialled back. But this is an important point: if a Fermi surface for a material looks like a sphere, it is going to be (or rather is) well approximated by the free electron model. On the other extreme, if the Fermi surface matches the Brillouin zone (that is, there isn't a Fermi surface) the system is well described by the tight binding model. Consider a square lattice of monovalent atoms in two dimensions. Roughly sketch the first Brillouin zone for the lattice (only the shape is important), and indicate the Fermi sea in the absence of a periodic potential The reciprocal lattice of a square lattice will also be a square lattice, and the Wigner-Seitz cell of a square lattice is a square. This question is very qualitative, but is one of the most important concepts in this course, hence its appearance here. Rather than just providing a sketch, this is a full calculation and so obviously beyond what would be expected. The dispersion relation - a surface in 2D - is shown, along with a contour plot of this surface. As each \\(k\\) state can hold 2 electrons, \\(50\\%\\) of the Brillouin zone will be filled (in this case area) with the lowest states being preferentially filled. The free-electron dispersion relationship is a parabaloid, and hence we get a circular Fermi surface, with the Fermi sea being the interior of this circle. Repeat the process above for both a weak and strong periodic potential Shown below is the dispersion surface in the tight-binding model (which you can think of as a very strong periodic potential), which in contrast to the Fermi circle of a free-electron, makes a Fermi square: A weaker periodic potential would be in-between these extremes, a circle with the points closest to the Brillouin zone boundaries filled more due to band bending. Barium ( \\(Z = 56\\) ) is a divalent atom, and the Fermi surface is shown below: Explain the features of this surface, explicitly referencing the 2D analogues from the previous section, and what statements (if any) can be made about the conductivity and specific heat of barium based upon the Fermi surface alone? Still needs to be finished , but the if we consider a square BZ, a divalent nearly-free electron system would have a Fermi surface something like a circle with the same area as the BZ, but with points outside the square, that is bits that protrude into the 2nd BZ. Think of this like the extended/reduced zone schemes in 1D: when something is in the 2nd BZ (in the extended zone) this is the same as the excited 1st branch in the reduced zone scheme: we are just seeing this is 3D. The fact that there is a Fermi surface at all mean that there are nearby states which electrons can occupy, and thus the system can absorb energy: this will be a metal, and conduct both heat and electricity. It is also Barium, which you (may) know is a metal! Consider a semiconductor quantum well: a material which is uniform Al \\(_x\\) Ga \\(_{1-x}\\) As with a thin layer of GaAs that is a material that has three regions. Recall that the energy eignestates of a quantum well have energies \\( \\(E_n = \\frac{\\hbar^2 \\pi^2 n^2}{2 m L^2}\\) \\) We can model this system as a two-dimensional electron gas. Show that the density of states for a free electron gas is g(E) = \\frac{m}{\\pi \\hbar^2} \\Theta(E) where \\(\\Theta(E)\\) is the Heaviside step function I don't know why I used in \\(E\\) in this question, but I am going to stick with the convention of the course to use \\(\\varepsilon\\) for the energy. In two dimensions, the number of states is given by \\[ N = 2 \\frac{A}{(2\\pi)^2} \\int_0^{k_F} \\mathrm{d}\\mathbf{k} \\] which evaluates to \\[ N = \\frac{A}{2\\pi} k_F^2 \\] or equivalently \\(n= N/A = k_F^2/2\\pi\\) . For a free electron: \\[ \\varepsilon = \\frac{\\hbar^2 k^2}{2m} \\] and thus \\[ n = \\frac{2m \\varepsilon_F}{2\\pi\\hbar^2} \\] By the definition of the denisty of states per unit volume, we have also that \\[ n = \\int_0^{\\varepsilon_F} g(\\varepsilon) \\mathrm{d}\\varepsilon \\] and thus \\[ g(\\varepsilon) = \\frac{m}{\\pi\\hbar^2} \\] Note using \\(g(\\varepsilon) = \\mathrm{d}n / \\mathrm{d}\\varepsilon\\) yields the same result. The inclusion of the Heaviside step function is necessary as states that have a negative energy should not be included, which is obviously clear in the case of a free electron, but when we have electrons and holes in wells, we must be much more careful! Show that the density of states for electrons in the well is given by g(E) = \\frac{m_e^*}{\\pi \\hbar^2} \\sum_{n>0} \\Theta \\left(E - E_c - \\frac{\\hbar^2 \\pi^2}{2 m_e^*} \\frac{n^2}{L^2}\\right) where \\(E_c\\) is the conduction band energy. In a quantum well, we will have the two-dimensional behaviour of the free electron plus the inclusion of the discretised states of the quantum well. We also must include the effective mass of the electron, as it is no longer a free electron. So the energy of an electron in a given state state in the well described by quantum number \\(n\\) is \\[ \\varepsilon_n = \\varepsilon_c + \\frac{\\hbar^2 \\pi^2 n^2}{2 m_e^* L^2} + \\frac{\\hbar^2 k^2}{2m_e^*} \\] where \\(\\varepsilon_c\\) is the minimum energy of the conduction band (the bottom of the well). As the conduction band energy and well energy is independent of \\(k\\) , the density of states will be the same as above, with the appropriate subsititutions and a regonition that there are no states below the ground state of the well, that is \\(\\varepsilon\\) will only be non-zero above \\(\\varepsilon_c + \\hbar^2 \\pi^2 n^2 / 2 m_e^* L^2\\) , and thus \\[ g(\\varepsilon_n) = \\frac{m_e^*}{\\pi\\hbar^2} \\Theta\\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n^2}{2 m_e^* L^2} \\right) \\] But in the usual way, this is the density for a single mode \\(n\\) , and there are many possible values of \\(n\\) , and thus we must add them all up: \\[ g(\\varepsilon) = \\sum_n g(\\varepsilon_n) = \\frac{m_e^*}{\\pi\\hbar^2} \\sum_{n=1}^{\\infty} \\Theta\\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n^2}{2 m_e^* L^2} \\right) \\] as required. What is the density of states for holes in this system? There is delightfully little to do other than \\(m_e^* \\rightarrow m_h^*\\) , replacing the conduction band energy with the valence band energy, and recogising that only states with an energy \\(\\varepsilon\\) below \\(\\varepsilon_v - \\hbar^2 \\pi^2 n^2 / 2 m_h^* L^2\\) will be non-zero, and so one can directly write \\[ g(\\varepsilon) = \\frac{m_h^*}{\\pi\\hbar^2} \\sum_{n=1}^{\\infty} \\Theta \\left(\\varepsilon_v - \\frac{\\hbar^2 \\pi^2 n^2}{2 m_h^* L^2} - \\varepsilon \\right) \\] Now consider a \"quantum wire\": a one-dimensional block of GaAs in embedded in the Al \\(_x\\) Ga \\(_{1-x}\\) As. The cross-section of the wire is an \\(L \\times L\\) square and the system is well described by a one-dimensional electron gas. Show the density of states for electrons is given by \\begin{aligned} g(E) = \\frac{\\sqrt{2 m_e^*}}{\\pi \\hbar} \\sum_{n_1, n_2 >0} & \\left(E - E_c - \\frac{\\hbar^2 \\pi^2}{2 m_e^*} \\frac{n_1^2 + n_2^2}{L^2}\\right)^{1/2} \\\\ & \\times \\Theta \\left(E - E_c - \\frac{\\hbar^2 \\pi^2}{2 m_e^*} \\frac{n_1^2 + n_2^2}{L^2}\\right) \\end{aligned} This is really the definition of rinse and repeat. We had 3D in question one, 2D in the previous section and now 1D: in exactly the same manner as above, we need to calculate the density of states in one dimension and then incorporate the now 2D square well energy spectrum. For a free electron: \\[ N = 2 \\frac{L}{2\\pi} \\int \\mathrm{d}k \\] which is one dimension is a line integral from \\(-k_F\\) to \\(k_F\\) and so \\[ n = \\frac{N}{L} = \\frac{2 k_F}{\\pi} \\] and \\(k\\) is still \\(\\sqrt{2m\\varepsilon}/\\hbar\\) , so we find that \\[ g(\\varepsilon) = \\frac{\\sqrt{2m}}{\\pi\\hbar} E^{-1/2} \\Theta (\\varepsilon) \\] Now in the semiconductor, \\(m\\rightarrow m_e^*\\) and \\[ \\varepsilon_{n_1, n_2} = \\varepsilon_c + \\frac{\\hbar^2 \\pi^2 n_1^2 + n_2^2}{2 m_e^* L^2} + \\frac{\\hbar^2 k^2}{2m_e^*} \\] as there it is a two-dimesnional well. Now we need add up all the states, so sum over both \\(n_1\\) and \\(n_2\\) : \\[ \\begin{aligned} g(\\varepsilon) & = \\sum_{n_1,n_2} g(\\varepsilon_{n_1, n_2}) & \\\\ & = \\frac{\\sqrt{2m_e^*}}{\\pi\\hbar} \\sum_{n_1=1}^{\\infty} \\sum_{n_2=1}^{\\infty} & \\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n_1^2 + n_2^2}{2 m_e^* L^2} \\right)^{-1/2} \\\\ & & \\times \\Theta \\left(\\varepsilon - \\varepsilon_c - \\frac{\\hbar^2 \\pi^2 n_1^2 + n_2^2}{2 m_e^* L^2} \\right) \\end{aligned} \\]","title":"Question 4"},{"location":"solutions/solutions/","text":"Solutions to exercises \u00b6 Solutions for The specific heat of solids I exercises \u00b6 Preliminary provocations \u00b6 \\(C = 2k_B\\) . Exercise 1: Total heat capacity of a diatomic material \u00b6 Use the formula \\(\\omega = \\sqrt{\\frac{k}{m}}\\) . Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}(2 + 1/2) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}(4 + 1/2). Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}\\left(n_B(\\beta\\hbar\\omega_{^6Li}) + \\frac{1}{2}\\right) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}\\left(n_B(\\beta\\hbar\\omega_{^7Li}) + \\frac{1}{2}\\right). Heat capacity per atom is given by C = \\frac{N_{^6Li}}{N}C_{^6Li} + \\frac{N_{^7Li}}{N}C_{^7Li}, Solutions for The specific heat of solids II exercises \u00b6 Preliminary provocations \u00b6 The polarization is related to the direction of the amplitudes of the waves with respect to the direction of the wave. In 3D, there are only 3 different amplitude directions possible. One can convert the integral as follows: \\int k_x k_y \\rightarrow \\int_{0}^{2\\pi} \\mathrm{d} \\theta \\int_{0}^{\\infty} k \\mathrm{d} k = 2\\pi \\int_{0}^{\\infty} k \\mathrm{d} k The Debye frequency \\(\\omega_D\\) . From the definition of the Debye frequency, one can calculate that the wavelength is of the order of the interatomic spacing: \\lambda = (\\frac{4}{3}\\pi)^{1/3} a. Exercise 1: Debye model - concepts. \u00b6 It is clear that \\(n=4\\) , and thus \\(k = \\frac{2 \\pi n}{L} = \\pm \\frac{4\\pi}{L}\\) . 2. The number of states per \\(k\\) or per frequency. 4. g(\\omega) = \\frac{dN}{d\\omega} = \\frac{dN}{dk}\\frac{dk}{d\\omega} = \\frac{1}{v}\\frac{dN}{dk}. We assume that in \\(d\\) dimensions there are \\(d\\) polarizations. For 1D we have that \\(N = \\frac{L}{2\\pi}\\int_{-k}^{k} dk\\) , hence \\(g(\\omega) = \\frac{L}{\\pi v}\\) . For 2D we have that \\(N = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int d^2k = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int 2\\pi kdk\\) , hence \\(g(\\omega) = \\frac{L^2\\omega}{\\pi v^2}\\) . For 3D we have that \\(N = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int 4\\pi k^2dk\\) , hence \\(g(\\omega) = \\frac{3L^3\\omega^2}{2\\pi^2v^3}\\) . Exercise 2: Debye model in 2D. \u00b6 See lecture notes. \\[ \\begin{align} E &= \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega \\\\ &= \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^2}{e^{x} - 1}dx + C. \\end{align} \\] High temperature implies \\(\\beta \\rightarrow 0\\) , hence \\(E = \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\frac{(\\beta\\hbar\\omega_D)^2}{2} + C\\) , and then \\(C = \\frac{k_BL^2\\omega^2_D}{2\\pi v^2} = 2Nk_B\\) . We've used the value for \\(\\omega_D\\) calculated from \\(2N = \\int_{0}^{\\omega_D}g(\\omega)d\\omega\\) . In the low temperature limit we have that \\(\\beta \\rightarrow \\infty\\) , hence \\(E \\approx \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx + C = \\frac{2\\zeta(3)L^2}{\\pi v^2\\hbar^2\\beta^3} + C\\) . Finally \\(C = \\frac{6\\zeta(3)k^3_BL^2}{\\pi v^2\\hbar^2}T^2\\) . We used the fact that \\(\\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx = 2\\zeta(3)\\) where \\(\\zeta\\) is the Riemann zeta function. Exercise 3: Different oscillation modes. \u00b6 \\[ g(\\omega) = \\sum_{\\text{polarizations}}\\frac{dN}{dk}\\frac{dk}{d\\omega} = \\left(\\frac{L}{2\\pi}\\right)^3\\sum_{\\text{polarizations}}4\\pi k^2\\frac{dk}{d\\omega} = \\frac{L^3}{2\\pi^2}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\omega^2 $$ $$ E = \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega = \\frac{L^3}{2\\pi^2\\hbar^3\\beta^4}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^3}{e^{x} - 1}dx + C. \\] Note that we can get \\(\\omega_D\\) from \\(3N = \\int_{0}^{\\omega_D}g(\\omega)\\) so everything cancels as usual and we are left with the Dulong-Petit law \\(C = 3Nk_B\\) . In the low temperature limit we have that \\(C \\sim \\frac{2\\pi^2k_B^4L^3}{15\\hbar^3}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)T^3\\) . We used that \\(\\int_{0}^{\\infty}\\frac{x^3}{e^{x} - 1}dx = \\frac{\\pi^4}{15}\\) . Exercise 4: Anisotropic sound velocities. \u00b6 \\begin{align} E & = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k\\hbar\\omega(\\mathbf{k})\\left(n_B(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\\\ & = 3\\left(\\frac{L}{2\\pi}\\right)^3\\frac{1}{v_xv_yv_z}\\int d^3\\kappa\\frac{\\hbar\\kappa}{e^{\\beta\\hbar\\kappa} - 1} + C, \\end{align} where we used the substitutions \\(\\kappa_x = k_xv_x,\\kappa_y = k_yv_y, \\kappa_z = k_zv_z\\) . Finally E = \\frac{3\\hbar L^3}{2\\pi^2}\\frac{1}{v_xv_yv_z}\\int_0^{\\kappa_D} d\\kappa\\frac{\\kappa^3}{e^{\\beta\\hbar\\kappa} - 1} + C = \\frac{3L^3}{2\\pi^2\\hbar^3\\beta^4}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1} + C, hence \\(C = \\frac{\\partial E}{\\partial T} = \\frac{6k_B^4L^3T^3}{\\pi^2\\hbar^3}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1}\\) . We see that the result is similar to the one with the linear dispersion, the only difference is the factor \\(1/v_xv_yv_z\\) instead of \\(1/v^3\\) . Solutions for Electrons in metals I exercises \u00b6 Preliminary provocations \u00b6 How does the resistance of a purely 2D material depend on its size? Check that the units of mobility and the Hall coefficient are correct. (As you should always do!) Explain why the scattering times due to different types of scattering events add up in a reciprocal way. Exercise 1: Extracting quantities from basic Hall measurements \u00b6 We apply a magnetic field \\(\\bf B\\) along the \\(z\\) -direction to a planar (two-dimensional) sample that sits in the \\(xy\\) plane. The sample has width \\(W\\) in the \\(y\\) -direction, length \\(L\\) in the \\(x\\) -direction and we apply a current \\(I\\) along the \\(x\\) -direction. What is the relation between the electric field and the electric potential? \\(V_b - V_a = -\\int_{\\Gamma} \\mathbf{E} \\cdot d\\mathbf{\\ell}\\) if \\(\\Gamma\\) is a path from \\(a\\) to \\(b\\) . Suppose we measure a Hall voltage \\(V_H\\) . Express the Hall resistance \\(R_{xy} = V_H/I\\) as a function of magnetic field. Does \\(R_{xy}\\) depend on the geometry of the sample? Also express \\(R_{xy}\\) in terms of the Hall coefficient \\(R_H\\) . Hall voltage is measured across the sample width. Hence, V_H = -\\int_{0}^{W} E_ydy where \\(E_y = -v_xB\\) . \\(R_{xy}\\) = \\(-\\frac{B}{ne}\\) , so it does not depend on the sample geometry. Assuming we control the magnetic field \\(\\mathbf{B}\\) , what quantity can we extract from a measurement of the Hall resistance? Would a large or a small magnetic field give a Hall voltage that is easier to measure? If hall resistance and magnetic field are known, the charge density is calculated from \\(R_{xy} = -\\frac{B}{ne}\\) . As \\(V_x = -\\frac{I_x}{ne}B\\) , a stronger field makes Hall voltages easier to measure. Express the longitudinal resistance \\(R=V/I\\) , where \\(V\\) is the voltage difference over the sample along the \\(x\\) direction, in terms of the longitudinal resistivity \\(\u03c1_{xx}\\) . Suppose we extracted \\(n\\) from a measurement of the Hall resistance, what quantity can we extract from a measurement of the longitudinal resistance? Does the result depend on the geometry of the sample? R_{xx} = \\frac{\\rho_{xx}L}{W} where \\rho_{xx} = \\frac{m_e}{ne^2\\tau}<span class=\"arithmatex\">\\(. Therefore, scattering time (\\)</span>\\tau ) is known and \\(R_{xx}\\) depend upon the sample geometry. Exercise 2: Motion of an electron in a magnetic and an electric field \u00b6 1. m\\frac{d\\bf v}{dt} = -e(\\bf v \\times \\bf B) Magnetic field affects only the velocities along x and y, i.e., \\(v_x(t)\\) and \\(v_y(t)\\) as they are perpendicular to it. Therefore, the equations of motion for the electron are \\frac{dv_x}{dt} = -\\frac{e v_y B_z}{m} \\frac{dv_y}{dt} = \\frac{e v_x B_z}{m} We can compute \\(v_x(t)\\) and \\(v_y(t)\\) by solving the differential equations in 1. From v_x'' = -\\frac{e^2B_z^2}{m^2}v_x and the initial conditions, we find \\(v_x(t) = v_0 \\cos(\\omega_c t)\\) with \\(\\omega_c=eB_z/m\\) . From this we can derive \\(v_y(t)=v_0\\sin(\\omega_c t)\\) . We now calculate the particle position using \\(x(t)=x(0) + \\int_0^t v_x(t')dt'\\) (and similar for \\(y(t)\\) ). From this we can find a relation between the \\(x\\) - and \\(y\\) -coordinates of the particle (x(t) - x_0)^2 + (y(t) - y_0)^2 = \\frac{v_0^2}{\\omega_c^2}. This equation describes a circular motion around the point \\(x_0=x(0), y_0=y(0)+v_0/\\omega\\) , where the characteristic frequency \\(\\omega_c\\) is called the cyclotron frequency. Intuition: \\(\\frac{mv^2}{r} = evB\\) (centripetal force = Lorentz force due to magnetic field). Due to the applied electric field \\(\\bf E\\) in the \\(x\\) -direction, the equations of motion acquire an extra term: m v_x' = -e(E_x + v_yB_z). Differentiating w.r.t. time leads to the same 2nd-order D.E. for \\(v_x\\) as above. However, for \\(v_y\\) we get v_y'' = -\\omega_c^2(v_d+v_y), where we defined \\(v_d=\\frac{E_x}{B_z}\\) . The general solutions are v_y(t) = c_1\\sin(\\omega_c t)+ c_2\\cos(\\omega_c t) -v_d \\\\ v_x(t) = c_3\\sin(\\omega_c t)+ c_4\\cos(\\omega_c t). Using the initial conditions \\(v_x(0)=v_0\\) and \\(v_y(0)=0\\) and the 1st order D.E. above, we can show v_y(t) = v_0\\sin(\\omega_c t)+ v_d\\cos(\\omega_c t) -v_d \\\\ v_x(t) = v_d\\sin(\\omega_c t)+ v_0\\cos(\\omega_c t). By integrating the expressions for the velocity we find: (x(t)-x_0)^2 + (y(t) - y_0 + v_d t))^2 = \\frac{v_0^2}{\\omega_c^2}. This represents a cycloid : a circular motion around a point that moves in the \\(y\\) -direction with velocity \\(v_d=\\frac{E_x}{B_z}\\) . Exercise 3: Temperature dependence of resistance in the Drude model \u00b6 Find electron density from n_e = \\frac{Z n N_A}{W} where Z is valence of copper atom, n is density, \\(N_A\\) is Avogadro constant and W is atomic weight. Use \\(\\rho = 1/\\sigma\\) from the lecture notes to calculate scattering time. \\sigma = \\frac{n e^2 \\tau}{m} \\(\\lambda = \\langle v \\rangle\\tau\\) Scattering time \\(\\tau \\propto \\frac{1}{\\sqrt{T}}\\) ; \\(\\rho \\propto \\sqrt{T}\\) In general, \\(\\rho \\propto T\\) as the phonons in the system scales linearly with T (remember high temperature limit of Bose-Einstein factor becomes \\(\\frac{kT}{\\hbar\\omega}\\) leading to \\(\\rho \\propto T\\) ). Inability to explain this linear dependence is a failure of the Drude model. Exercise 4: The Hall conductivity matrix and the Hall coefficient \u00b6 \\(\\rho_{xx}\\) is independent of B and \\(\\rho_{xy} \\propto B\\) 2. \\sigma_{xx} = \\frac{\\rho_{xx}}{\\rho_{xx}^2 + \\rho_{xy}^2} \\sigma_{xy} = \\frac{-\\rho_{yx}}{\\rho_{xx}^2 + \\rho_{xy}^2} This describes a Lorentzian . Solutions for Electrons in metals II exercises \u00b6 Warm-up questions \u00b6 1. E = \\int \\limits_0^{\\infty} g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\varepsilon \\mathrm{d} \\varepsilon The electronic heat capacity \\(C_e\\) approaches \\(3N k_B\\) . Thermal smearing is too significant and we can not accurately approximate the fraction of the excited electron with triangles anymore. Thus the Sommerfeld expansion breaks down. Electrons. Exercise 1: potassium \u00b6 Alkali metals mostly have a spherical Fermi surface. Their energy depends only on the magnitude of the Fermi wavevector. Refer to the lecture notes. Electrons are fermions and obey the Pauli exclusion principle. As electrons cannot occupy the same state, they are forced to occupy higher energy states resulting in high Fermi energy and high Fermi temperature. 4. n = \\frac{N}{V} = \\frac{1}{3 \\pi^{2} \\hbar^{3}}\\left(2 m \\varepsilon_{F}\\right)^{3 / 2} 5. n = \\frac{\\rho N_A Z}{M}, where \\(\\rho\\) is the density, \\(N_A\\) is the Avogadro's constant, \\(M\\) is molar mass and \\(Z\\) is the valence of potassium atom. Comparing total and free electron density, only few electrons are available for conduction which is roughly 1 free electron per potassium atom. Exercise 2: a hypothetical material \u00b6 1. E = \\int_{0}^{\\infty}\\varepsilon g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\textrm{d} \\varepsilon = 2.10^{10}eV^{-\\frac{3}{2}} \\int_{0}^{\\infty}\\frac{\\varepsilon^{\\frac{3}{2}}}{e^\\frac{\\varepsilon-5.2}{k_BT}+1} \\textrm{d} \\varepsilon 2. E = \\frac{4}{5} (5.2)^{\\frac{5}{2}} 10^{10} eV 3. \\begin{align} E(T)-E(T=0) &= \\frac{\\pi^2}{6}(k_B T)^2\\frac{\\partial}{\\partial \\varepsilon}\\left(\\varepsilon g(\\varepsilon)\\right)\\bigg|_{\\varepsilon=\\varepsilon _F}\\\\ &\\approx 8.356 10^8 eV \\end{align} 5. \\(C_v = 1.6713.10^6 eV/K\\) 4, 6. mu = 5.2 kB = 8.617343e-5 T = 1000 #kelvin import numpy as np from scipy import integrate np . seterr ( over = 'ignore' ) # Fermi-Dirac distribution def f ( E , T ): return 1 / ( np . exp (( E - mu ) / ( kB * T )) + 1 ) # Density of states def g ( E ): return 2e10 * np . sqrt ( E ) #integration function def integral ( E , T ): return f ( E , T ) * g ( E ) * E ## Solve integral numerically using scipy's integrate dE = integrate . quad ( integral , 0 , 1e1 , args = ( T ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dT = 0.001 dEplus = integrate . quad ( integral , 0 , 1e1 , args = ( T + dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dEmin = integrate . quad ( integral , 0 , 1e1 , args = ( T - dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) CV = ( dEplus - dEmin ) / ( 2 * dT ); print ( f 'dE = { dE : .4e } eV' ) print ( f 'Cv = { CV : .4e } eV/K' ) Check the source code written in python for solving integral using midpoint rule. Exercise 3: graphene \u00b6 1. import numpy as np import matplotlib.pyplot as plt x = np . linspace ( - 1 , 1 , 100 ) fig , ax = plt . subplots ( figsize = ( 7 , 5 )) ax . plot ( x , x , 'b' ) ax . plot ( x , - x , 'b' ) ax . spines [ 'left' ] . set_position ( 'center' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0.0 )) # Eliminate upper and right axes ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . set_xticks ([]) ax . set_yticks ([]) ax . set_xlabel ( r '$\\mid \\vec k \\mid$' , fontsize = 14 ) ax . set_ylabel ( r '$\\varepsilon$' , fontsize = 18 , rotation = 'horizontal' ) ax . yaxis . set_label_coords ( 0.5 , 1 ) ax . xaxis . set_label_coords ( 1.0 , 0.49 ) 2.The DOS for the positive energies is given by g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{\\varepsilon}{c^2}, where \\(2_s\\) is the spin degeneracy and \\(2_v\\) is the valley degeneracy. If we account for the negative energies as well, we obtain g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{|\\varepsilon|}{c^2}. 3. \\(g(\\varepsilon)\\) vs \\(\\varepsilon\\) is a linear plot. Here, the region marked by \\(-k_B T\\) is a triangle whose area gives the number of electrons that can be excited: \\begin{align} n_{ex} &= \\frac{1}{2} g(-k_B T) k_B T\\\\ &= \\frac{L^2 k_B^2T^2}{\\pi c^2}. \\end{align} From this it follows that the energy difference is given by E(T) - E_0 = \\frac{L^2 k_B^3T^3}{\\pi c^2}. 4. C_v(T) = \\frac{\\partial E}{\\partial T} = \\frac{3L^2k_B^3T^2}{\\pi c^2} Solutions for Chemistry 101 exercises \u00b6 Exercise 1: Shell-filling model of atoms \u00b6 See lecture notes. The atomic number of Tungsten is 74: 1\\textrm{s}^2 2\\textrm{s}^2 2\\textrm{p}^6 3\\textrm{s}^23p^64s^23d^{10}4p^65s^24d^{10}5p^66s^24f^{14}5d^4 \\[ \\begin{align} \\textrm{Cu} &= [\\textrm{Ar}]4s^23d^9\\\\ \\textrm{Pd} &= [\\textrm{Kr}]5s^24d^8\\\\ \\textrm{Ag} &= [\\textrm{Kr}]5s^24d^9\\\\ \\textrm{Au} &= [\\textrm{Xe}]6s^24f^{14}5d^9 \\end{align} \\] The wheels fall off as \\(V(\\mathbf{r}) \\ne 1/|r|\\) Exercise 2: Application of the LCAO model to the delta-function potential \u00b6 \\psi(x) = \\begin{cases} &\\sqrt{\u03ba}e^{\u03ba(x-x_1)}, x<x_1\\\\ &\\sqrt{\u03ba}e^{-\u03ba(x-x_1)}, x>x_1 \\end{cases} Where \\(\u03ba = \\sqrt{\\frac{-2mE}{\u0127^2}} = \\frac{mV_0}{\u0127^2}\\) . The energy is given by \\(\u03f5_1 = \u03f5_2 = -\\frac{mV_0^2}{2\u0127^2}\\) The wave function of a single delta peak is given by \\psi_1(x) = \\frac{\\sqrt{mV_0}}{\u0127}e^{-\\frac{mV_0}{\u0127^2}|x-x_1|} \\(\\psi_2(x)\\) can be found by replacing \\(x_1\\) by \\(x_2\\) \\[ H = -\\frac{mV_0^2}{\u0127^2}\\begin{pmatrix} 1/2+\\exp(-\\frac{2mV_0}{\u0127^2}|x_2-x_1|) & \\exp(-\\frac{mV_0}{\u0127^2}|x_2-x_1|)\\\\ \\exp(-\\frac{mV_0}{\u0127^2}|x_2-x_1|) & 1/2+\\exp(-\\frac{2mV_0}{\u0127^2}|x_2-x_1|) \\end{pmatrix} \\] \u03f5_{\\pm} = \\beta(1/2+\\exp(-2\\alpha) \\pm \\exp(-\\alpha)) Where \\(\\beta = -\\frac{mV_0^2}{\u0127^2}\\) and \\(\u03b1 = \\frac{mV_0}{\u0127^2}|x_2-x_1|\\) Exercise 3: Polarization of a hydrogen molecule \u00b6 1. H_{\\mathcal{E}} = ex\\mathcal{E}, 2. \\hat{H} = \\begin{pmatrix} E_0 & -t\\\\ -t & E_0 \\end{pmatrix} +\\begin{pmatrix} \u27e81|ex\\mathcal{E}|1\u27e9 & \u27e81|ex\\mathcal{E}|2\u27e9\\\\ \u27e82|ex\\mathcal{E}|1\u27e9 & \u27e82|ex\\mathcal{E}|2\u27e9 \\end{pmatrix} = \\begin{pmatrix} E_0 - \\gamma & -t\\\\ -t & E_0 + \\gamma \\end{pmatrix}, where \\(\\gamma = e d \\mathcal{E}/2\\) and have used \\( \\(\u27e81|ex\\mathcal{E}|1\u27e9 = -e d \\mathcal{E}/2\u27e81|1\u27e9 = -e d \\mathcal{E}/2\\) \\) 3. The eigenstates of the Hamiltonian are given by: E_{\\pm} = E_0\\pm\\sqrt{t^2+\\gamma^2} The ground state wave function is: \\begin{split} |\\psi\u27e9 &= \\frac{t}{\\sqrt{(\\gamma+\\sqrt{\\gamma^2+t^2})^2+t^2}}\\begin{pmatrix} \\frac{\\gamma+\\sqrt{t^2+\\gamma^2}}{t}\\\\ 1 \\end{pmatrix}\\\\ |\\psi\u27e9 &= \\frac{\\gamma+\\sqrt{t^2+\\gamma^2}}{\\sqrt{(\\gamma+\\sqrt{\\gamma^2+t^2})^2+t^2}}|1\u27e9+\\frac{t}{\\sqrt{(\\gamma+\\sqrt{\\gamma^2+t^2})^2+t^2}}|2\u27e9 \\end{split} 4. P = -\\frac{2\\gamma^2}{\\mathcal{E}}(\\frac{1}{\\sqrt{\\gamma^2+t^2}})","title":"Solutions to exercises"},{"location":"solutions/solutions/#solutions-to-exercises","text":"","title":"Solutions to exercises"},{"location":"solutions/solutions/#solutions-for-the-specific-heat-of-solids-i-exercises","text":"","title":"Solutions for The specific heat of solids I exercises"},{"location":"solutions/solutions/#preliminary-provocations","text":"\\(C = 2k_B\\) .","title":"Preliminary provocations"},{"location":"solutions/solutions/#exercise-1-total-heat-capacity-of-a-diatomic-material","text":"Use the formula \\(\\omega = \\sqrt{\\frac{k}{m}}\\) . Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}(2 + 1/2) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}(4 + 1/2). Energy per atom is given by E = \\frac{N_{^6Li}}{N}\\hbar\\omega_{^6Li}\\left(n_B(\\beta\\hbar\\omega_{^6Li}) + \\frac{1}{2}\\right) + \\frac{N_{^7Li}}{N}\\hbar\\omega_{^7Li}\\left(n_B(\\beta\\hbar\\omega_{^7Li}) + \\frac{1}{2}\\right). Heat capacity per atom is given by C = \\frac{N_{^6Li}}{N}C_{^6Li} + \\frac{N_{^7Li}}{N}C_{^7Li},","title":"Exercise 1: Total heat capacity of a diatomic material"},{"location":"solutions/solutions/#solutions-for-the-specific-heat-of-solids-ii-exercises","text":"","title":"Solutions for The specific heat of solids II exercises"},{"location":"solutions/solutions/#preliminary-provocations_1","text":"The polarization is related to the direction of the amplitudes of the waves with respect to the direction of the wave. In 3D, there are only 3 different amplitude directions possible. One can convert the integral as follows: \\int k_x k_y \\rightarrow \\int_{0}^{2\\pi} \\mathrm{d} \\theta \\int_{0}^{\\infty} k \\mathrm{d} k = 2\\pi \\int_{0}^{\\infty} k \\mathrm{d} k The Debye frequency \\(\\omega_D\\) . From the definition of the Debye frequency, one can calculate that the wavelength is of the order of the interatomic spacing: \\lambda = (\\frac{4}{3}\\pi)^{1/3} a.","title":"Preliminary provocations"},{"location":"solutions/solutions/#exercise-1-debye-model-concepts","text":"It is clear that \\(n=4\\) , and thus \\(k = \\frac{2 \\pi n}{L} = \\pm \\frac{4\\pi}{L}\\) . 2. The number of states per \\(k\\) or per frequency. 4. g(\\omega) = \\frac{dN}{d\\omega} = \\frac{dN}{dk}\\frac{dk}{d\\omega} = \\frac{1}{v}\\frac{dN}{dk}. We assume that in \\(d\\) dimensions there are \\(d\\) polarizations. For 1D we have that \\(N = \\frac{L}{2\\pi}\\int_{-k}^{k} dk\\) , hence \\(g(\\omega) = \\frac{L}{\\pi v}\\) . For 2D we have that \\(N = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int d^2k = 2\\left(\\frac{L}{2\\pi}\\right)^2\\int 2\\pi kdk\\) , hence \\(g(\\omega) = \\frac{L^2\\omega}{\\pi v^2}\\) . For 3D we have that \\(N = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int 4\\pi k^2dk\\) , hence \\(g(\\omega) = \\frac{3L^3\\omega^2}{2\\pi^2v^3}\\) .","title":"Exercise 1: Debye model - concepts."},{"location":"solutions/solutions/#exercise-2-debye-model-in-2d","text":"See lecture notes. \\[ \\begin{align} E &= \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega \\\\ &= \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^2}{e^{x} - 1}dx + C. \\end{align} \\] High temperature implies \\(\\beta \\rightarrow 0\\) , hence \\(E = \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\frac{(\\beta\\hbar\\omega_D)^2}{2} + C\\) , and then \\(C = \\frac{k_BL^2\\omega^2_D}{2\\pi v^2} = 2Nk_B\\) . We've used the value for \\(\\omega_D\\) calculated from \\(2N = \\int_{0}^{\\omega_D}g(\\omega)d\\omega\\) . In the low temperature limit we have that \\(\\beta \\rightarrow \\infty\\) , hence \\(E \\approx \\frac{L^2}{\\pi v^2\\hbar^2\\beta^3}\\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx + C = \\frac{2\\zeta(3)L^2}{\\pi v^2\\hbar^2\\beta^3} + C\\) . Finally \\(C = \\frac{6\\zeta(3)k^3_BL^2}{\\pi v^2\\hbar^2}T^2\\) . We used the fact that \\(\\int_{0}^{\\infty}\\frac{x^2}{e^{x} - 1}dx = 2\\zeta(3)\\) where \\(\\zeta\\) is the Riemann zeta function.","title":"Exercise 2: Debye model in 2D."},{"location":"solutions/solutions/#exercise-3-different-oscillation-modes","text":"\\[ g(\\omega) = \\sum_{\\text{polarizations}}\\frac{dN}{dk}\\frac{dk}{d\\omega} = \\left(\\frac{L}{2\\pi}\\right)^3\\sum_{\\text{polarizations}}4\\pi k^2\\frac{dk}{d\\omega} = \\frac{L^3}{2\\pi^2}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\omega^2 $$ $$ E = \\int_{0}^{\\omega_D}g(\\omega)\\hbar\\omega\\left(\\frac{1}{e^{\\beta\\hbar\\omega} - 1} + \\frac{1}{2}\\right)d\\omega = \\frac{L^3}{2\\pi^2\\hbar^3\\beta^4}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)\\int_{0}^{\\beta\\hbar\\omega_D}\\frac{x^3}{e^{x} - 1}dx + C. \\] Note that we can get \\(\\omega_D\\) from \\(3N = \\int_{0}^{\\omega_D}g(\\omega)\\) so everything cancels as usual and we are left with the Dulong-Petit law \\(C = 3Nk_B\\) . In the low temperature limit we have that \\(C \\sim \\frac{2\\pi^2k_B^4L^3}{15\\hbar^3}\\left(\\frac{2}{v_\\perp^3} + \\frac{1}{v_\\parallel^3}\\right)T^3\\) . We used that \\(\\int_{0}^{\\infty}\\frac{x^3}{e^{x} - 1}dx = \\frac{\\pi^4}{15}\\) .","title":"Exercise 3: Different oscillation modes."},{"location":"solutions/solutions/#exercise-4-anisotropic-sound-velocities","text":"\\begin{align} E & = 3\\left(\\frac{L}{2\\pi}\\right)^3\\int d^3k\\hbar\\omega(\\mathbf{k})\\left(n_B(\\beta\\hbar\\omega(\\mathbf{k})) + \\frac{1}{2}\\right) \\\\ & = 3\\left(\\frac{L}{2\\pi}\\right)^3\\frac{1}{v_xv_yv_z}\\int d^3\\kappa\\frac{\\hbar\\kappa}{e^{\\beta\\hbar\\kappa} - 1} + C, \\end{align} where we used the substitutions \\(\\kappa_x = k_xv_x,\\kappa_y = k_yv_y, \\kappa_z = k_zv_z\\) . Finally E = \\frac{3\\hbar L^3}{2\\pi^2}\\frac{1}{v_xv_yv_z}\\int_0^{\\kappa_D} d\\kappa\\frac{\\kappa^3}{e^{\\beta\\hbar\\kappa} - 1} + C = \\frac{3L^3}{2\\pi^2\\hbar^3\\beta^4}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1} + C, hence \\(C = \\frac{\\partial E}{\\partial T} = \\frac{6k_B^4L^3T^3}{\\pi^2\\hbar^3}\\frac{1}{v_xv_yv_z}\\int_0^{\\beta\\hbar\\kappa_D} dx\\frac{x^3}{e^{x} - 1}\\) . We see that the result is similar to the one with the linear dispersion, the only difference is the factor \\(1/v_xv_yv_z\\) instead of \\(1/v^3\\) .","title":"Exercise 4: Anisotropic sound velocities."},{"location":"solutions/solutions/#solutions-for-electrons-in-metals-i-exercises","text":"","title":"Solutions for Electrons in metals I exercises"},{"location":"solutions/solutions/#preliminary-provocations_2","text":"How does the resistance of a purely 2D material depend on its size? Check that the units of mobility and the Hall coefficient are correct. (As you should always do!) Explain why the scattering times due to different types of scattering events add up in a reciprocal way.","title":"Preliminary provocations"},{"location":"solutions/solutions/#exercise-1-extracting-quantities-from-basic-hall-measurements","text":"We apply a magnetic field \\(\\bf B\\) along the \\(z\\) -direction to a planar (two-dimensional) sample that sits in the \\(xy\\) plane. The sample has width \\(W\\) in the \\(y\\) -direction, length \\(L\\) in the \\(x\\) -direction and we apply a current \\(I\\) along the \\(x\\) -direction. What is the relation between the electric field and the electric potential? \\(V_b - V_a = -\\int_{\\Gamma} \\mathbf{E} \\cdot d\\mathbf{\\ell}\\) if \\(\\Gamma\\) is a path from \\(a\\) to \\(b\\) . Suppose we measure a Hall voltage \\(V_H\\) . Express the Hall resistance \\(R_{xy} = V_H/I\\) as a function of magnetic field. Does \\(R_{xy}\\) depend on the geometry of the sample? Also express \\(R_{xy}\\) in terms of the Hall coefficient \\(R_H\\) . Hall voltage is measured across the sample width. Hence, V_H = -\\int_{0}^{W} E_ydy where \\(E_y = -v_xB\\) . \\(R_{xy}\\) = \\(-\\frac{B}{ne}\\) , so it does not depend on the sample geometry. Assuming we control the magnetic field \\(\\mathbf{B}\\) , what quantity can we extract from a measurement of the Hall resistance? Would a large or a small magnetic field give a Hall voltage that is easier to measure? If hall resistance and magnetic field are known, the charge density is calculated from \\(R_{xy} = -\\frac{B}{ne}\\) . As \\(V_x = -\\frac{I_x}{ne}B\\) , a stronger field makes Hall voltages easier to measure. Express the longitudinal resistance \\(R=V/I\\) , where \\(V\\) is the voltage difference over the sample along the \\(x\\) direction, in terms of the longitudinal resistivity \\(\u03c1_{xx}\\) . Suppose we extracted \\(n\\) from a measurement of the Hall resistance, what quantity can we extract from a measurement of the longitudinal resistance? Does the result depend on the geometry of the sample? R_{xx} = \\frac{\\rho_{xx}L}{W} where \\rho_{xx} = \\frac{m_e}{ne^2\\tau}<span class=\"arithmatex\">\\(. Therefore, scattering time (\\)</span>\\tau ) is known and \\(R_{xx}\\) depend upon the sample geometry.","title":"Exercise 1: Extracting quantities from basic Hall measurements"},{"location":"solutions/solutions/#exercise-2-motion-of-an-electron-in-a-magnetic-and-an-electric-field","text":"1. m\\frac{d\\bf v}{dt} = -e(\\bf v \\times \\bf B) Magnetic field affects only the velocities along x and y, i.e., \\(v_x(t)\\) and \\(v_y(t)\\) as they are perpendicular to it. Therefore, the equations of motion for the electron are \\frac{dv_x}{dt} = -\\frac{e v_y B_z}{m} \\frac{dv_y}{dt} = \\frac{e v_x B_z}{m} We can compute \\(v_x(t)\\) and \\(v_y(t)\\) by solving the differential equations in 1. From v_x'' = -\\frac{e^2B_z^2}{m^2}v_x and the initial conditions, we find \\(v_x(t) = v_0 \\cos(\\omega_c t)\\) with \\(\\omega_c=eB_z/m\\) . From this we can derive \\(v_y(t)=v_0\\sin(\\omega_c t)\\) . We now calculate the particle position using \\(x(t)=x(0) + \\int_0^t v_x(t')dt'\\) (and similar for \\(y(t)\\) ). From this we can find a relation between the \\(x\\) - and \\(y\\) -coordinates of the particle (x(t) - x_0)^2 + (y(t) - y_0)^2 = \\frac{v_0^2}{\\omega_c^2}. This equation describes a circular motion around the point \\(x_0=x(0), y_0=y(0)+v_0/\\omega\\) , where the characteristic frequency \\(\\omega_c\\) is called the cyclotron frequency. Intuition: \\(\\frac{mv^2}{r} = evB\\) (centripetal force = Lorentz force due to magnetic field). Due to the applied electric field \\(\\bf E\\) in the \\(x\\) -direction, the equations of motion acquire an extra term: m v_x' = -e(E_x + v_yB_z). Differentiating w.r.t. time leads to the same 2nd-order D.E. for \\(v_x\\) as above. However, for \\(v_y\\) we get v_y'' = -\\omega_c^2(v_d+v_y), where we defined \\(v_d=\\frac{E_x}{B_z}\\) . The general solutions are v_y(t) = c_1\\sin(\\omega_c t)+ c_2\\cos(\\omega_c t) -v_d \\\\ v_x(t) = c_3\\sin(\\omega_c t)+ c_4\\cos(\\omega_c t). Using the initial conditions \\(v_x(0)=v_0\\) and \\(v_y(0)=0\\) and the 1st order D.E. above, we can show v_y(t) = v_0\\sin(\\omega_c t)+ v_d\\cos(\\omega_c t) -v_d \\\\ v_x(t) = v_d\\sin(\\omega_c t)+ v_0\\cos(\\omega_c t). By integrating the expressions for the velocity we find: (x(t)-x_0)^2 + (y(t) - y_0 + v_d t))^2 = \\frac{v_0^2}{\\omega_c^2}. This represents a cycloid : a circular motion around a point that moves in the \\(y\\) -direction with velocity \\(v_d=\\frac{E_x}{B_z}\\) .","title":"Exercise 2: Motion of an electron in a magnetic and an electric field"},{"location":"solutions/solutions/#exercise-3-temperature-dependence-of-resistance-in-the-drude-model","text":"Find electron density from n_e = \\frac{Z n N_A}{W} where Z is valence of copper atom, n is density, \\(N_A\\) is Avogadro constant and W is atomic weight. Use \\(\\rho = 1/\\sigma\\) from the lecture notes to calculate scattering time. \\sigma = \\frac{n e^2 \\tau}{m} \\(\\lambda = \\langle v \\rangle\\tau\\) Scattering time \\(\\tau \\propto \\frac{1}{\\sqrt{T}}\\) ; \\(\\rho \\propto \\sqrt{T}\\) In general, \\(\\rho \\propto T\\) as the phonons in the system scales linearly with T (remember high temperature limit of Bose-Einstein factor becomes \\(\\frac{kT}{\\hbar\\omega}\\) leading to \\(\\rho \\propto T\\) ). Inability to explain this linear dependence is a failure of the Drude model.","title":"Exercise 3: Temperature dependence of resistance in the Drude model"},{"location":"solutions/solutions/#exercise-4-the-hall-conductivity-matrix-and-the-hall-coefficient","text":"\\(\\rho_{xx}\\) is independent of B and \\(\\rho_{xy} \\propto B\\) 2. \\sigma_{xx} = \\frac{\\rho_{xx}}{\\rho_{xx}^2 + \\rho_{xy}^2} \\sigma_{xy} = \\frac{-\\rho_{yx}}{\\rho_{xx}^2 + \\rho_{xy}^2} This describes a Lorentzian .","title":"Exercise 4: The Hall conductivity matrix and the Hall coefficient"},{"location":"solutions/solutions/#solutions-for-electrons-in-metals-ii-exercises","text":"","title":"Solutions for Electrons in metals II exercises"},{"location":"solutions/solutions/#warm-up-questions","text":"1. E = \\int \\limits_0^{\\infty} g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\varepsilon \\mathrm{d} \\varepsilon The electronic heat capacity \\(C_e\\) approaches \\(3N k_B\\) . Thermal smearing is too significant and we can not accurately approximate the fraction of the excited electron with triangles anymore. Thus the Sommerfeld expansion breaks down. Electrons.","title":"Warm-up questions"},{"location":"solutions/solutions/#exercise-1-potassium","text":"Alkali metals mostly have a spherical Fermi surface. Their energy depends only on the magnitude of the Fermi wavevector. Refer to the lecture notes. Electrons are fermions and obey the Pauli exclusion principle. As electrons cannot occupy the same state, they are forced to occupy higher energy states resulting in high Fermi energy and high Fermi temperature. 4. n = \\frac{N}{V} = \\frac{1}{3 \\pi^{2} \\hbar^{3}}\\left(2 m \\varepsilon_{F}\\right)^{3 / 2} 5. n = \\frac{\\rho N_A Z}{M}, where \\(\\rho\\) is the density, \\(N_A\\) is the Avogadro's constant, \\(M\\) is molar mass and \\(Z\\) is the valence of potassium atom. Comparing total and free electron density, only few electrons are available for conduction which is roughly 1 free electron per potassium atom.","title":"Exercise 1: potassium"},{"location":"solutions/solutions/#exercise-2-a-hypothetical-material","text":"1. E = \\int_{0}^{\\infty}\\varepsilon g(\\varepsilon) n_{F}(\\beta (\\varepsilon - \\mu)) \\textrm{d} \\varepsilon = 2.10^{10}eV^{-\\frac{3}{2}} \\int_{0}^{\\infty}\\frac{\\varepsilon^{\\frac{3}{2}}}{e^\\frac{\\varepsilon-5.2}{k_BT}+1} \\textrm{d} \\varepsilon 2. E = \\frac{4}{5} (5.2)^{\\frac{5}{2}} 10^{10} eV 3. \\begin{align} E(T)-E(T=0) &= \\frac{\\pi^2}{6}(k_B T)^2\\frac{\\partial}{\\partial \\varepsilon}\\left(\\varepsilon g(\\varepsilon)\\right)\\bigg|_{\\varepsilon=\\varepsilon _F}\\\\ &\\approx 8.356 10^8 eV \\end{align} 5. \\(C_v = 1.6713.10^6 eV/K\\) 4, 6. mu = 5.2 kB = 8.617343e-5 T = 1000 #kelvin import numpy as np from scipy import integrate np . seterr ( over = 'ignore' ) # Fermi-Dirac distribution def f ( E , T ): return 1 / ( np . exp (( E - mu ) / ( kB * T )) + 1 ) # Density of states def g ( E ): return 2e10 * np . sqrt ( E ) #integration function def integral ( E , T ): return f ( E , T ) * g ( E ) * E ## Solve integral numerically using scipy's integrate dE = integrate . quad ( integral , 0 , 1e1 , args = ( T ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dT = 0.001 dEplus = integrate . quad ( integral , 0 , 1e1 , args = ( T + dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) dEmin = integrate . quad ( integral , 0 , 1e1 , args = ( T - dT ))[ 0 ] - 0.8e10 * 5.2 ** ( 5. / 2 ) CV = ( dEplus - dEmin ) / ( 2 * dT ); print ( f 'dE = { dE : .4e } eV' ) print ( f 'Cv = { CV : .4e } eV/K' ) Check the source code written in python for solving integral using midpoint rule.","title":"Exercise 2: a hypothetical material"},{"location":"solutions/solutions/#exercise-3-graphene","text":"1. import numpy as np import matplotlib.pyplot as plt x = np . linspace ( - 1 , 1 , 100 ) fig , ax = plt . subplots ( figsize = ( 7 , 5 )) ax . plot ( x , x , 'b' ) ax . plot ( x , - x , 'b' ) ax . spines [ 'left' ] . set_position ( 'center' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0.0 )) # Eliminate upper and right axes ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . set_xticks ([]) ax . set_yticks ([]) ax . set_xlabel ( r '$\\mid \\vec k \\mid$' , fontsize = 14 ) ax . set_ylabel ( r '$\\varepsilon$' , fontsize = 18 , rotation = 'horizontal' ) ax . yaxis . set_label_coords ( 0.5 , 1 ) ax . xaxis . set_label_coords ( 1.0 , 0.49 ) 2.The DOS for the positive energies is given by g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{\\varepsilon}{c^2}, where \\(2_s\\) is the spin degeneracy and \\(2_v\\) is the valley degeneracy. If we account for the negative energies as well, we obtain g(\\varepsilon) = 2_s 2_v 2 \\pi \\left(\\frac{L}{2 \\pi}\\right)^2 \\frac{|\\varepsilon|}{c^2}. 3. \\(g(\\varepsilon)\\) vs \\(\\varepsilon\\) is a linear plot. Here, the region marked by \\(-k_B T\\) is a triangle whose area gives the number of electrons that can be excited: \\begin{align} n_{ex} &= \\frac{1}{2} g(-k_B T) k_B T\\\\ &= \\frac{L^2 k_B^2T^2}{\\pi c^2}. \\end{align} From this it follows that the energy difference is given by E(T) - E_0 = \\frac{L^2 k_B^3T^3}{\\pi c^2}. 4. C_v(T) = \\frac{\\partial E}{\\partial T} = \\frac{3L^2k_B^3T^2}{\\pi c^2}","title":"Exercise 3: graphene"},{"location":"solutions/solutions/#solutions-for-chemistry-101-exercises","text":"","title":"Solutions for Chemistry 101 exercises"},{"location":"solutions/solutions/#exercise-1-shell-filling-model-of-atoms","text":"See lecture notes. The atomic number of Tungsten is 74: 1\\textrm{s}^2 2\\textrm{s}^2 2\\textrm{p}^6 3\\textrm{s}^23p^64s^23d^{10}4p^65s^24d^{10}5p^66s^24f^{14}5d^4 \\[ \\begin{align} \\textrm{Cu} &= [\\textrm{Ar}]4s^23d^9\\\\ \\textrm{Pd} &= [\\textrm{Kr}]5s^24d^8\\\\ \\textrm{Ag} &= [\\textrm{Kr}]5s^24d^9\\\\ \\textrm{Au} &= [\\textrm{Xe}]6s^24f^{14}5d^9 \\end{align} \\] The wheels fall off as \\(V(\\mathbf{r}) \\ne 1/|r|\\)","title":"Exercise 1: Shell-filling model of atoms"},{"location":"solutions/solutions/#exercise-2-application-of-the-lcao-model-to-the-delta-function-potential","text":"\\psi(x) = \\begin{cases} &\\sqrt{\u03ba}e^{\u03ba(x-x_1)}, x<x_1\\\\ &\\sqrt{\u03ba}e^{-\u03ba(x-x_1)}, x>x_1 \\end{cases} Where \\(\u03ba = \\sqrt{\\frac{-2mE}{\u0127^2}} = \\frac{mV_0}{\u0127^2}\\) . The energy is given by \\(\u03f5_1 = \u03f5_2 = -\\frac{mV_0^2}{2\u0127^2}\\) The wave function of a single delta peak is given by \\psi_1(x) = \\frac{\\sqrt{mV_0}}{\u0127}e^{-\\frac{mV_0}{\u0127^2}|x-x_1|} \\(\\psi_2(x)\\) can be found by replacing \\(x_1\\) by \\(x_2\\) \\[ H = -\\frac{mV_0^2}{\u0127^2}\\begin{pmatrix} 1/2+\\exp(-\\frac{2mV_0}{\u0127^2}|x_2-x_1|) & \\exp(-\\frac{mV_0}{\u0127^2}|x_2-x_1|)\\\\ \\exp(-\\frac{mV_0}{\u0127^2}|x_2-x_1|) & 1/2+\\exp(-\\frac{2mV_0}{\u0127^2}|x_2-x_1|) \\end{pmatrix} \\] \u03f5_{\\pm} = \\beta(1/2+\\exp(-2\\alpha) \\pm \\exp(-\\alpha)) Where \\(\\beta = -\\frac{mV_0^2}{\u0127^2}\\) and \\(\u03b1 = \\frac{mV_0}{\u0127^2}|x_2-x_1|\\)","title":"Exercise 2: Application of the LCAO model to the delta-function potential"},{"location":"solutions/solutions/#exercise-3-polarization-of-a-hydrogen-molecule","text":"1. H_{\\mathcal{E}} = ex\\mathcal{E}, 2. \\hat{H} = \\begin{pmatrix} E_0 & -t\\\\ -t & E_0 \\end{pmatrix} +\\begin{pmatrix} \u27e81|ex\\mathcal{E}|1\u27e9 & \u27e81|ex\\mathcal{E}|2\u27e9\\\\ \u27e82|ex\\mathcal{E}|1\u27e9 & \u27e82|ex\\mathcal{E}|2\u27e9 \\end{pmatrix} = \\begin{pmatrix} E_0 - \\gamma & -t\\\\ -t & E_0 + \\gamma \\end{pmatrix}, where \\(\\gamma = e d \\mathcal{E}/2\\) and have used \\( \\(\u27e81|ex\\mathcal{E}|1\u27e9 = -e d \\mathcal{E}/2\u27e81|1\u27e9 = -e d \\mathcal{E}/2\\) \\) 3. The eigenstates of the Hamiltonian are given by: E_{\\pm} = E_0\\pm\\sqrt{t^2+\\gamma^2} The ground state wave function is: \\begin{split} |\\psi\u27e9 &= \\frac{t}{\\sqrt{(\\gamma+\\sqrt{\\gamma^2+t^2})^2+t^2}}\\begin{pmatrix} \\frac{\\gamma+\\sqrt{t^2+\\gamma^2}}{t}\\\\ 1 \\end{pmatrix}\\\\ |\\psi\u27e9 &= \\frac{\\gamma+\\sqrt{t^2+\\gamma^2}}{\\sqrt{(\\gamma+\\sqrt{\\gamma^2+t^2})^2+t^2}}|1\u27e9+\\frac{t}{\\sqrt{(\\gamma+\\sqrt{\\gamma^2+t^2})^2+t^2}}|2\u27e9 \\end{split} 4. P = -\\frac{2\\gamma^2}{\\mathcal{E}}(\\frac{1}{\\sqrt{\\gamma^2+t^2}})","title":"Exercise 3: Polarization of a hydrogen molecule"}]}